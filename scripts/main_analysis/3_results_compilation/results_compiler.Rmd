---
title: "Results Compiler - ABCD MDS Risk"
author: "Sam A. Sievertsen"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 2
    df_print: paged
    code_folding: hide
params:
  seed: 123
  link_primary: "logit"
  wave_ref: "ses-04A"
---

```{r setup, include=FALSE}

# 1. SETUP
#1.1 Libraries (load quietly; knit will continue if a package is missing)
safe_library <- function(pkg) {
  suppressWarnings({
    suppressPackageStartupMessages({
      tryCatch({
        library(pkg, character.only = TRUE)
      }, error = function(e) {
        message(sprintf("[WARN] Package '%s' not available. Some features may be skipped.", pkg))
      })
    })
  })
}

pkgs <- c(
  "ggplot2", "dplyr", "tidyr", "stringr", "tibble", "clustMixType", "here",
  "glue", "janitor", "readr", "broom", "broom.mixed", "gt", "gtsummary",
  "kableExtra", "patchwork", "cowplot", "ggtext", "scales", "mgcv", "geepack",
  "lme4", "glmmTMB", "clubSandwich", "DHARMa", "performance", "consort",
  "ggrepel", "GGally", "sf", "viridisLite", "webshot2", "purrr",
  "DiagrammeR", "DiagrammeRsvg", "rsvg", "emmeans"
)
invisible(lapply(pkgs, safe_library))

#1.2 Global options and themes
set.seed(123)
knitr::opts_chunk$set(fig.width = 8, fig.height = 5, dpi = 300, echo = TRUE,
                      message = FALSE, warning = FALSE, fig.align = "center")

if (requireNamespace("gtsummary", quietly = TRUE)) {
  gtsummary::theme_gtsummary_journal(journal = "jama")
}
theme_set(theme_minimal(base_size = 12))

#1.3 Paths (ARC tree)
#1.3.1 Project root (assumes Rmd is at repo root)
root_dir <- here::here()

#1.3.2 Data roots
data_root        <- here::here("data")
data_processed   <- here::here("data", "data_processed")
data_raw         <- here::here("data", "data_raw")

#1.3.3 Common processed subtrees
analysis_datasets <- here::here("data", "data_processed", "analysis_datasets")
kproto_results    <- here::here("data", "data_processed", "kproto_results")
stability_results <- here::here("data", "data_processed", "stability_results")
validation_results<- here::here("data", "data_processed", "validation_results")

#1.3.4 Results (model outputs) roots
results_root     <- here::here("results")
results_main     <- here::here("results", "main_analysis")
res_bd_surv      <- here::here("results", "main_analysis", "1_bd_survival")
res_bd_mixed     <- here::here("results", "main_analysis", "2_bd_mixed_logit")
res_nested_dth   <- here::here("results", "main_analysis", "3_nested_suic_dth")
res_nested_mixed <- here::here("results", "main_analysis", "4_nested_suicidality_mixed_logit")

#1.3.5 Assets (for Figure 0 schematic, etc.)
assets_dir <- here::here("assets")

#1.3.6 Export targets (per §5 filenames)
fig_dir <- here::here("results", "figures")
tab_dir <- here::here("results", "tables")

#1.4 Ensure export directories exist
for (d in c(fig_dir, tab_dir)) if (!dir.exists(d)) dir.create(d, recursive = TRUE)

#1.5 Visual options
cluster_cols <- c("#7F3C8D", "#11A579")

#1.6 Helper functions
#1.6.1 Save figure (PDF + PNG) with transparent background
save_fig <- function(plot, base_filename, width = 9, height = 8, dpi = 720) {
  pdf_path <- file.path(fig_dir, paste0(base_filename, ".pdf"))
  png_path <- file.path(fig_dir, paste0(base_filename, ".png"))
  ggplot2::ggsave(pdf_path, plot = plot, width = width, height = height, bg = "transparent")
  ggplot2::ggsave(png_path, plot = plot, width = width, height = height, dpi = dpi, bg = "transparent")
  invisible(list(pdf = pdf_path, png = png_path))
}

#1.6.2 Format CI label
ci_label <- function(lo, hi, digits = 2) sprintf("(%.2f, %.2f)", round(lo, digits), round(hi, digits))

#1.6.3 Format OR with CI
fmt_or <- function(est, lo, hi, digits = 2) sprintf("%.2f %s", round(est, digits), ci_label(lo, hi, digits))

#1.6.4 Pretty p-value
strip_p <- function(p) ifelse(is.na(p), "", ifelse(p < 0.001, "<0.001", sprintf("%.3f", p)))

#1.6.5 Patchwork legend bottom helper
legend_bottom <- function(p) p + patchwork::plot_layout(guides = "collect") & theme(legend.position = "bottom")

#1.6.6 Panel tag helper
panel_tag <- function(p, tag = "A") p + ggplot2::labs(tag = tag) + theme(plot.tag = element_text(face = "bold", size = 12))

#1.6.7 GT save helper (HTML/PNG/RTF) with fallbacks
save_gt <- function(gt_tbl, base_filename) {
  html_path <- file.path(tab_dir, paste0(base_filename, ".html"))
  png_path  <- file.path(tab_dir, paste0(base_filename, ".png"))
  rtf_path  <- file.path(tab_dir, paste0(base_filename, ".rtf"))

  gt::gtsave(gt_tbl, html_path)
  if (requireNamespace("webshot2", quietly = TRUE)) {
    # On headless ARC nodes, webshot2 should still work; PNG save is best-effort
    try(gt::gtsave(gt_tbl, png_path), silent = TRUE)
  }
  try(gt::gtsave(gt_tbl, rtf_path), silent = TRUE)
  invisible(list(html = html_path, png = png_path, rtf = rtf_path))
}

#1.6.8 Safe read: CSV or RDS; if missing, return NULL
safe_read <- function(path) {
  if (file.exists(path)) {
    ext <- tolower(tools::file_ext(path))
    if (ext == "rds") return(readRDS(path))
    if (ext %in% c("csv", "tsv")) return(readr::read_csv(path, show_col_types = FALSE))
  }
  return(NULL)
}

#1.6.9 Read or TK placeholder by expected columns
read_or_tk <- function(path, tk_cols, tk_n = 10) {
  df <- safe_read(path)
  if (!is.null(df)) return(df)
  out <- tibble::tibble(.rows = tk_n)
  for (nm in tk_cols) out[[nm]] <- NA
  out <- janitor::remove_empty(out, which = c("rows", "cols"))
  attr(out, "TK") <- TRUE
  out
}

#1.6.10 Small utility to detect TK data
is_tk <- function(df) isTRUE(isTRUE(attr(df, "TK")))

#1.6.11 CONSORT helper to safely label TK captions
tk_caption <- function(base) paste0(base, ifelse(grepl("TK", base, fixed=TRUE) ||
                                                grepl("TK", paste(capture.output(str(base)), collapse=" "), fixed=TRUE),
                                                " (TK)", ""))

#1.6.12 Convenience: quick path joiners for later sections
#      These keep the Inputs chunk simple when pointing to ARC outputs.
p_data   <- function(...) file.path(data_root, ...)
p_proc   <- function(...) file.path(data_processed, ...)
p_anal   <- function(...) file.path(analysis_datasets, ...)
p_kproto <- function(...) file.path(kproto_results, ...)
p_stab   <- function(...) file.path(stability_results, ...)
p_valid  <- function(...) file.path(validation_results, ...)
p_res    <- function(...) file.path(results_root, ...)
p_main   <- function(...) file.path(results_main, ...)
p_bd_surv<- function(...) file.path(res_bd_surv, ...)
p_bd_mix <- function(...) file.path(res_bd_mixed, ...)
p_ns_dth <- function(...) file.path(res_nested_dth, ...)
p_ns_mix <- function(...) file.path(res_nested_mixed, ...)

# Normalize BD outcome names to {BDI, BDII, BSD, BDNOS} (if present)
norm_bd_outcome <- function(x) {
  dplyr::case_when(
    stringr::str_detect(x, stringr::regex("bipolar[_-]?ii", ignore_case = TRUE)) ~ "BDII",
    stringr::str_detect(x, stringr::regex("bipolar[_-]?i(?!i)", ignore_case = TRUE)) ~ "BDI",
    stringr::str_detect(x, stringr::regex("any[_-]?bsd|\\bbd?s?d\\b", ignore_case = TRUE)) ~ "BSD",
    stringr::str_detect(x, stringr::regex("bd[_-]?nos", ignore_case = TRUE)) ~ "BDNOS",
    TRUE ~ x
  )
}

# Safer directory stacker: only stack CSVs (or DFs); skip list/vec RDS
stack_dir <- function(dir, pattern, mutate_f = NULL) {
  if (!dir.exists(dir)) return(NULL)
  fs <- list.files(dir, pattern = pattern, full.names = TRUE)
  if (!length(fs)) return(NULL)
  out <- purrr::map(fs, function(f) {
    df <- safe_read(f)
    # Skip non-data-frame objects
    if (is.null(df) || !is.data.frame(df)) return(NULL)
    df$file <- basename(f)
    df
  })
  out <- purrr::compact(out)
  if (!length(out)) return(NULL)
  res <- dplyr::bind_rows(out)
  if (!is.null(mutate_f)) res <- mutate_f(res)
  res
}

# Helper: read val_robust_silhouette_k*.rds into a tidy DF if possible
read_val_sil_perk <- function(dir) {
  if (!dir.exists(dir)) return(NULL)
  fs <- list.files(dir, pattern = "^val_robust_silhouette_k[0-9]+\\.rds$", full.names = TRUE)
  if (!length(fs)) return(NULL)
  purrr::map_dfr(fs, function(f) {
    obj <- safe_read(f)
    k   <- suppressWarnings(as.integer(stringr::str_match(basename(f), "k(\\d+)")[,2]))
    if (is.data.frame(obj) && "silhouette" %in% names(obj)) {
      tibble::tibble(k = k, scaling = "robust_iqr", silhouette = mean(obj$silhouette, na.rm = TRUE))
    } else if (is.numeric(obj)) {
      tibble::tibble(k = k, scaling = "robust_iqr", silhouette = mean(obj, na.rm = TRUE))
    } else if (is.list(obj)) {
      tibble::tibble(k = k, scaling = "robust_iqr", silhouette = mean(unlist(obj), na.rm = TRUE))
    } else {
      NULL
    }
  })
}

# Coerce ID name
ensure_participant_id <- function(df) {
  if (is.null(df)) return(df)
  nm <- names(df)
  if ("participant_id" %in% nm) return(df)
  if ("participant_id" %in% nm) {
    names(df)[match("participant_id", nm)] <- "participant_id"
  }
  df
}

# Null-coalescing helper
`%||%` <- function(x, y) if (is.null(x) || (is.data.frame(x) && nrow(x) == 0)) y else x

```

## Overview and Inputs

This document compiles all manuscript-ready figures and tables for the ABCD MDS Risk project. It is designed to **knit immediately** using TK placeholder data if any source files are missing. Wherever TK placeholders appear, captions are explicitly marked *(TK)* so you can swap in final CSV/RDS files without editing code.

```{r input-config}
#2. INPUTS ---------------------------------------------------------------------
#2.0 Small helpers (file discovery) -------------------------------------------
first_existing <- function(...) {
  xs <- c(...)
  for (p in xs) if (!is.null(p) && nzchar(p) && file.exists(p)) return(p)
  return("")
}

#2.1 CORE DATASETS -------------------------------------------------------------
risk_vars <- read_or_tk(
  first_existing(
    p_proc("risk_variable_data.csv"),
    p_proc("risk_variable_data.rds")
  ),
  tk_cols = c("participant_id","variable","value","domain","stage","cluster")
) %>% ensure_participant_id()

outcome_vars <- read_or_tk(
  first_existing(
    p_proc("outcome_variable_data.csv"),
    p_proc("outcome_variable_data.rds")
  ),
  tk_cols = c("participant_id","age","sex","site","wave","bd_any","si_passive","si_active","sa","nssi")
) %>% ensure_participant_id()

cluster_labels <- read_or_tk(
  first_existing(
    p_anal("cluster_labels_k2_robust.csv"),
    p_anal("cluster_labels_k2_robust.rds")
  ),
  tk_cols = c("participant_id","cluster")
) %>% ensure_participant_id()

# Map C1/C2 to manuscript labels (C1 = Higher; C2 = Lower)
coerce_cluster <- function(x) {
  dplyr::recode(as.character(x),
    "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
    "C2"="Lower-Risk","2"="Lower-Risk","low"="Lower-Risk","lower"="Lower-Risk",
    .default = x
  )
}

# Immediately coerce cluster labels where available
if (!is.null(cluster_labels) && nrow(cluster_labels)) {
  cluster_labels <- cluster_labels %>%
    dplyr::mutate(cluster = coerce_cluster(cluster))
}

bd_panel <- read_or_tk(first_existing(
  p_anal("bd_panel_k2_robust.csv"),
  p_anal("bd_panel_k2_robust.rds")
), tk_cols = c("participant_id","wave","age","cluster","any_bsd","bipolar_I","bipolar_II","bd_nos")) %>% ensure_participant_id()

bd_pp <- read_or_tk(first_existing(
  p_anal("bd_person_period_k2_robust.csv"),
  p_anal("bd_person_period_k2_robust.rds")
), tk_cols = c("participant_id","wave","age","interval_id","cluster","event_any_bsd","event_bipolar_I","event_bipolar_II","event_bd_nos")) %>% ensure_participant_id()

nested_panel <- read_or_tk(first_existing(
  p_anal("nested_suic_panel_k2_robust.csv"),
  p_anal("nested_suic_panel_k2_robust.rds")
), tk_cols = c("participant_id","wave","age","cluster","ever_bd","si_passive","si_active","sa","nssi")) %>% ensure_participant_id()

nested_pp <- read_or_tk(first_existing(
  p_anal("nested_suic_person_period_k2_robust.csv"),
  p_anal("nested_suic_person_period_k2_robust.rds")
), tk_cols = c("participant_id","wave","age","interval_id","cluster","ever_bd","event_si_passive","event_si_active","event_sa","event_nssi")) %>% ensure_participant_id()

#2.2 CLUSTERING / VALIDATION ---------------------------------------------------
val_sil_all <- safe_read(first_existing(
  p_valid("val_robust_silhouette.rds")
))

# Robust reader for per-k files (skips non-DF RDS)
val_sil_perk <- read_val_sil_perk(p_valid("partial_results_in_progress"))

# Optional other scalings (may be non-DF; used only if DF)
val_sil_z      <- safe_read(first_existing(p_valid("val_z_score_silhouette.rds")))
val_sil_none   <- safe_read(first_existing(p_valid("val_none_silhouette.rds")))
val_sil_minmax <- safe_read(first_existing(p_valid("val_min_max_silhouette.rds")))
val_sil_pct    <- safe_read(first_existing(p_valid("val_percentile_silhouette.rds")))
val_sil_abs    <- safe_read(first_existing(p_valid("val_max_absolute_silhouette.rds")))
val_cindex_all <- safe_read(first_existing(p_valid("val_robust_cindex.rds"), p_valid("val_robust_cindex.csv")))

cluster_stability_raw <- read_or_tk(
  first_existing(
    p_stab("stability_robust_k2_nb1000.csv"),
    p_stab("stability_robust_k2_nb1000.rds")
  ),
  tk_cols = c("metric","value","percentile","notes")
)

umap_embed <- read_or_tk(
  first_existing(
    p_valid("umap_embedding_k2.csv"),
    p_valid("umap_embedding_k2.rds")
  ),
  tk_cols = c("x","y","cluster")
)

#2.3 DTH - BD FIRST-ONSET ------------------------------------------------------
bd_hazard_by_wave <- read_or_tk(
  p_bd_surv("bd_dth_abs_hazard_by_wave.csv"),
  tk_cols = c("outcome","wave","cluster","hazard","conf.low","conf.high")
)

bd_cumrisk_by_wave <- read_or_tk(
  p_bd_surv("bd_dth_cumrisk_by_wave.csv"),
  tk_cols = c("outcome","wave","cluster","cumrisk","conf.low","conf.high")
)

bd_preds_by_age <- read_or_tk(
  first_existing(
    p_bd_surv("bd_dth_preds_by_age_aligned.csv"),
    p_bd_surv("bd_dth_preds_by_age_fixed_wave.csv")
  ),
  tk_cols = c("age","cluster","outcome","fit","conf.low","conf.high")
)

bd_dth_wald      <- read_or_tk(p_bd_surv("bd_dth_wald.csv"),
                               tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value"))
bd_dth_wald_full <- read_or_tk(p_bd_surv("bd_dth_wald_full.csv"),
                               tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value"))
bd_dth_cr2       <- read_or_tk(p_bd_surv("bd_dth_cr2.csv"),
                               tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","se_method"))
bd_wave_age_medians <- read_or_tk(
  p_bd_surv("wave_age_medians.csv"),
  tk_cols = c("wave","age_median")
)

#2.4 BD PREVALENCE - GEE/GLMM/glmmTMB + GAMM preds -----------------------------
gee_by_wave_bd <- stack_dir(
  p_bd_mix("csv"),
  pattern = "GEE_(AR1|EXC)(_INT)?_cluster_OR_by_wave\\.csv$",
  mutate_f = function(df) {
    df %>%
      janitor::clean_names() %>%
      dplyr::mutate(outcome = norm_bd_outcome(file),
                    model = dplyr::case_when(
                      stringr::str_detect(file, "GEE_AR1") ~ "GEE_AR1",
                      stringr::str_detect(file, "GEE_EXC") ~ "GEE_EXC",
                      TRUE ~ "GEE"
                    )) %>%
      dplyr::select(-file)
  }
)

gee_fixed_bd <- stack_dir(
  p_bd_mix("csv"),
  pattern = "GEE_(AR1|EXC)(_INT)?_fixed(.*)\\.csv$",
  mutate_f = function(df) {
    df %>%
      janitor::clean_names() %>%
      dplyr::mutate(outcome = norm_bd_outcome(file),
                    model = dplyr::case_when(
                      stringr::str_detect(file, "GEE_AR1") ~ "GEE_AR1",
                      stringr::str_detect(file, "GEE_EXC") ~ "GEE_EXC",
                      TRUE ~ "GEE"
                    )) %>%
      dplyr::select(-file)
  }
)

glmm_fixed_bd <- stack_dir(
  p_bd_mix("csv"),
  pattern = "GLMM.*fixed_ORs\\.csv$",
  mutate_f = function(df) {
    df %>% janitor::clean_names() %>%
      dplyr::mutate(outcome = norm_bd_outcome(file), model = "GLMM") %>%
      dplyr::select(-file)
  }
)

tmb_fixed_bd <- stack_dir(
  p_bd_mix("csv"),
  pattern = "glmmTMB.*fixed_ORs\\.csv$",
  mutate_f = function(df) {
    df %>% janitor::clean_names() %>%
      dplyr::mutate(outcome = norm_bd_outcome(file), model = "glmmTMB") %>%
      dplyr::select(-file)
  }
)

bd_gamm_preds <- stack_dir(
  p_bd_mix("pred_csv"),
  pattern = "_GAMM_age_predictions\\.csv$",
  mutate_f = function(df) {
    df %>% janitor::clean_names() %>%
      dplyr::mutate(outcome = norm_bd_outcome(file)) %>%
      dplyr::select(-file)
  }
)

#2.5 NESTED SUICIDALITY - DTH --------------------------------------------------
su_hazard_by_wave <- read_or_tk(
  p_ns_dth("su_dth_hazard_by_wave_by_bd.csv"),
  tk_cols = c("outcome","wave","cluster","ever_bd","hazard","conf.low","conf.high")
)

su_preds_by_age <- read_or_tk(
  p_ns_dth("su_dth_preds_by_age_by_bd.csv"),
  tk_cols = c("age","outcome","cluster","ever_bd","fit","conf.low","conf.high")
)

su_dth_wald <- read_or_tk(
  p_ns_dth("su_dth_wald.csv"),
  tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value")
)

su_dth_cr2 <- read_or_tk(
  p_ns_dth("su_dth_cr2.csv"),
  tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","se_method")
)

su_wave_age_medians <- read_or_tk(
  p_ns_dth("wave_age_medians.csv"),
  tk_cols = c("wave","age_median")
)

#2.6 NESTED SUICIDALITY - PREVALENCE ------------------------------------------
gee_by_wave_su <- stack_dir(
  p_ns_mix("csv"),
  pattern = "GEE_(AR1|EXC)(_INT)?_cluster_OR_by_wave\\.csv$",
  mutate_f = function(df) df %>% janitor::clean_names() %>% dplyr::select(-file)
)

gee_fixed_su <- stack_dir(
  p_ns_mix("csv"),
  pattern = "GEE_(AR1|EXC)(_INT)?_fixed\\.csv$",
  mutate_f = function(df) df %>% janitor::clean_names() %>% dplyr::select(-file)
)

glmm_fixed_su <- stack_dir(
  p_ns_mix("csv"),
  pattern = "GLMM.*fixed_ORs\\.csv$",
  mutate_f = function(df) df %>% janitor::clean_names() %>% dplyr::select(-file)
)

tmb_fixed_su <- stack_dir(
  p_ns_mix("csv"),
  pattern = "glmmTMB.*fixed_ORs\\.csv$",
  mutate_f = function(df) df %>% janitor::clean_names() %>% dplyr::select(-file)
)

su_gamm_preds <- stack_dir(
  p_ns_mix("pred_csv"),
  pattern = "_GAMM_age_predictions\\.csv$",
  mutate_f = function(df) df %>% janitor::clean_names() %>% dplyr::select(-file)
)

#2.7 risk_long for GGally panel (auto-build from risk_vars if needed) ----------
risk_long <- if (!is_tk(risk_vars) && all(c("participant_id","variable","value") %in% names(risk_vars))) {
  rv <- risk_vars
  if (!"cluster" %in% names(rv) && !is_tk(cluster_labels)) {
    rv <- rv %>% dplyr::left_join(cluster_labels, by = "participant_id")
  }
  rv %>% dplyr::select(subject = participant_id, variable, value, cluster)
} else {
  read_or_tk("", tk_cols = c("subject","variable","value","cluster"), tk_n = 100)
}

#2.8 CONSORT counts (optional explicit file; else derived later) ----------------
consort_counts <- read_or_tk(
  first_existing(
    p_res("consort_counts.csv"),
    p_res("main_analysis","consort_counts.csv")
  ),
  tk_cols = c("stage","label","n","wave","cluster")
)

#2.9 Coerce common shapes for downstream code ----------------------------------

# Helper to standardize stats frames: ensure expected columns exist and
# normalize names (conf_low -> conf.low, p_value -> p.value, etc.)
standardize_stats_df <- function(df) {
  if (is.null(df) || is_tk(df)) return(df)
  df <- janitor::clean_names(df)

  # Ensure presence of expected columns (create as NA if missing)
  need <- c("outcome","term","estimate","conf_low","conf_high","p_value","se_method","link")
  for (nm in need) if (!nm %in% names(df)) df[[nm]] <- NA

  # Rename to dot-style for consistency with downstream code
  df <- dplyr::rename(
    df,
    conf.low = dplyr::any_of("conf_low"),
    conf.high = dplyr::any_of("conf_high"),
    p.value = dplyr::any_of("p_value")
  )

  df
}

# ---- BD DTH ----
bd_dth_cr2_std <- if (!is_tk(bd_dth_cr2)) standardize_stats_df(bd_dth_cr2) else NULL
bd_dth_wald_std <- if (!is_tk(bd_dth_wald)) standardize_stats_df(bd_dth_wald) else NULL

bd_dth_sum <- if (!is.null(bd_dth_cr2_std)) {
  bd_dth_cr2_std %>%
    dplyr::mutate(
      se_method = dplyr::coalesce(se_method, "CR2"),
      # infer link if not provided
      link = dplyr::coalesce(
        link,
        dplyr::if_else(stringr::str_detect(term, stringr::regex("cloglog|hazard", ignore_case = TRUE)), "cloglog", "logit")
      ),
      outcome = norm_bd_outcome(dplyr::coalesce(.data$outcome, ""))
    )
} else if (!is.null(bd_dth_wald_std)) {
  bd_dth_wald_std %>%
    dplyr::mutate(
      se_method = dplyr::coalesce(se_method, "model-based"),
      link = dplyr::coalesce(
        link,
        dplyr::if_else(stringr::str_detect(term, stringr::regex("cloglog|hazard", ignore_case = TRUE)), "cloglog", "logit")
      ),
      outcome = norm_bd_outcome(dplyr::coalesce(.data$outcome, ""))
    )
} else {
  # TK placeholder if neither file available
  read_or_tk("",
             tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","model","se_method","link"))
}

# ---- BD PREVALENCE (unchanged) ----
bd_gee  <- gee_fixed_bd %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
bd_glmm <- glmm_fixed_bd %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
bd_tmb  <- tmb_fixed_bd  %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
bd_gam  <- bd_gamm_preds %||% read_or_tk("", tk_cols = c("age","cluster","fit","se_fit","outcome"))

# ---- Nested suicidality DTH ----
su_dth_cr2_std  <- if (!is_tk(su_dth_cr2))  standardize_stats_df(su_dth_cr2)  else NULL
su_dth_wald_std <- if (!is_tk(su_dth_wald)) standardize_stats_df(su_dth_wald) else NULL

nested_dth_sum <- if (!is.null(su_dth_cr2_std)) {
  su_dth_cr2_std %>%
    dplyr::mutate(
      se_method = dplyr::coalesce(se_method, "CR2"),
      link = dplyr::coalesce(
        link,
        dplyr::if_else(stringr::str_detect(term, stringr::regex("cloglog|hazard", ignore_case = TRUE)), "cloglog", "logit")
      )
    )
} else if (!is.null(su_dth_wald_std)) {
  su_dth_wald_std %>%
    dplyr::mutate(
      se_method = dplyr::coalesce(se_method, "model-based"),
      link = dplyr::coalesce(
        link,
        dplyr::if_else(stringr::str_detect(term, stringr::regex("cloglog|hazard", ignore_case = TRUE)), "cloglog", "logit")
      )
    )
} else {
  read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","model","se_method","link"))
}

# ---- Nested suicidality prevalence (unchanged) ----
nested_gee  <- gee_fixed_su %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
nested_glmm <- glmm_fixed_su %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
nested_tmb  <- tmb_fixed_su  %||% read_or_tk("", tk_cols = c("outcome","term","estimate","conf.low","conf.high","p.value","converged"))
nested_gam  <- su_gamm_preds %||% read_or_tk("", tk_cols = c("age","cluster","fit","se_fit","outcome"))

# ---- Hazard prediction frames (unchanged) ----
bd_dth_preds     <- if (!is_tk(bd_preds_by_age)) bd_preds_by_age else read_or_tk("", tk_cols = c("age","cluster","outcome","fit","conf.low","conf.high"), tk_n = 60)
nested_dth_preds <- if (!is_tk(su_preds_by_age)) su_preds_by_age else read_or_tk("", tk_cols = c("age","cluster","outcome","fit","conf.low","conf.high"), tk_n = 60)


#2.10 Seed TKs minimally if nothing found --------------------------------------
seed_if_needed <- function() {

  # -- k_sil: either from val_sil_perk, or a TK elbow if nothing usable --------
  if (is.null(val_sil_all) && (is.null(val_sil_perk) || !is.data.frame(val_sil_perk) || nrow(val_sil_perk) == 0)) {
    k_sil_df <- tidyr::expand_grid(k = 2:8, scaling = c("robust_iqr","zscore","none")) %>%
      dplyr::mutate(silhouette = dplyr::case_when(
        scaling == "robust_iqr" ~ dplyr::case_when(k == 2 ~ 0.48, k == 3 ~ 0.43, k == 4 ~ 0.41, TRUE ~ 0.38),
        scaling == "zscore"     ~ 0.35 - 0.01*(k-2),
        TRUE                    ~ 0.30 - 0.015*(k-2)
      ))
  } else if (is.data.frame(val_sil_perk) && nrow(val_sil_perk) > 0) {
    k_sil_df <- val_sil_perk
  } else {
    # Fallback TK if val_sil_all is present but not tidy
    k_sil_df <- tidyr::expand_grid(k = 2:8, scaling = c("robust_iqr","zscore","none")) %>%
      dplyr::mutate(silhouette = 0.4 - 0.01*(k-2))
  }
  assign("k_sil", k_sil_df, envir = .GlobalEnv)

  # -- k_wss: simple TK curve ---------------------------------------------------
  k_wss_df <- tidyr::expand_grid(k = 2:8, scaling = c("robust_iqr","zscore","none")) %>%
    dplyr::group_by(scaling) %>%
    dplyr::mutate(
      wss = 1000/(k-1) + dplyr::case_when(
        scaling == "robust_iqr" ~ 0,
        scaling == "zscore"     ~ 50,
        TRUE                    ~ 100
      )
    ) %>%
    dplyr::ungroup()
  assign("k_wss", k_wss_df, envir = .GlobalEnv)

  # -- UMAP: TK cloud if needed -------------------------------------------------
  if (is.null(umap_embed) || is_tk(umap_embed) || !all(c("x","y","cluster") %in% names(umap_embed))) {
    set.seed(123)
    assign("umap_embed",
           tibble::tibble(
             x = c(rnorm(500,-2,1), rnorm(500, 2,1)),
             y = c(rnorm(500, 0,1), rnorm(500, 0,1)),
             cluster = rep(c("C1","C2"), each = 500)
           ),
           envir = .GlobalEnv)
  }

  # -- CONSORT counts: TK scaffold only if still missing ------------------------
  if (is.null(consort_counts) || is_tk(consort_counts)) {
    assign("consort_counts",
           tibble::tribble(
             ~stage,  ~label,                               ~n,    ~wave, ~cluster,
             "start", "ABCD baseline consented",            11878, NA,    NA,
             "filter","Eligible (age/QC)",                  11500, NA,    NA,
             "filter","Complete risk variables",             9800,  NA,    NA,
             "filter","Complete outcomes & covariates",      9500,  NA,    NA,
             "filter","Excluded per pre-spec (22.55%)",      2676,  NA,    NA,
             "end",   "Included in risk clustering",          9193,  NA,    NA
           ),
           envir = .GlobalEnv)
  }
}

seed_if_needed()

```

## 1. CONSORT / Analytic Flow (Figure 1)

We construct a CONSORT-style flow using the **consort** package. Boxes summarize attrition for the clustered sample and each analysis set (BD DTH; BD prevalence GEE/GLMM/glmmTMB; nested suicidality DTH; nested suicidality prevalence). If required inputs are unavailable, TK text is shown so the document still knits.

```{r fig1-consort}

#4. FIGURE 1 -------------------------------------------------------------------
#4.1 Helpers -------------------------------------------------------------------
# Pretty wave labels for CONSORT bullets/boxes
wave_pretty_map <- c(
  "ses-00A" = "Baseline",
  "ses-02A" = "Year-2",
  "ses-04A" = "Year-4",
  "ses-06A" = "Year-6")
wave_lab <- function(w) {
  s <- as.character(w)
  out <- ifelse(s %in% names(wave_pretty_map), wave_pretty_map[s], s)
  unname(out)
}
wave_order_pretty <- c("Baseline","Year-2","Year-4","Year-6")
order_waves <- function(df, col = "wave") {
  if (!col %in% names(df)) return(df)
  df %>%
    dplyr::mutate(
      !!col := factor(.data[[col]], levels = wave_order_pretty[wave_order_pretty %in% unique(.data[[col]])])
    ) %>%
    dplyr::arrange(.data[[col]]) %>%
    dplyr::mutate(!!col := as.character(.data[[col]]))
}

has_any  <- function(df, cols) any(cols %in% names(df))
present  <- function(df, cols) intersect(cols, names(df))

pick_wave_col <- function(df) {
  cands <- c("wave","end_wave","session_id")
  w <- intersect(cands, names(df))
  if (length(w)) w[[1]] else NA_character_
}

# Row-wise NA check
row_any_na <- function(df_cols) {
  if (is.null(df_cols) || ncol(df_cols) == 0) return(rep(FALSE, ifelse(is.null(df_cols), 0L, nrow(df_cols))))
  rowSums(is.na(df_cols)) > 0
}

# Keep only participant_id; if only subject_id exists, rename -> participant_id
ensure_ids <- function(df) {
  if (is.null(df)) return(df)
  nms <- names(df)
  if (!"participant_id" %in% nms && "subject_id" %in% nms) {
    names(df)[match("subject_id", nms)] <- "participant_id"
  }
  # Drop any lingering subject_id to avoid accidental use
  df <- dplyr::select(df, -dplyr::any_of("subject_id"))
  df
}

bd_pp         <- ensure_ids(bd_pp)
bd_panel      <- ensure_ids(bd_panel)
nested_pp     <- ensure_ids(nested_pp)
nested_panel  <- ensure_ids(nested_panel)
cluster_labels<- ensure_ids(cluster_labels)

# Always coalesce cluster from labels using participant_id only
ensure_cluster <- function(df) {
  if (is.null(df) || is_tk(cluster_labels)) return(df)
  if (!all(c("participant_id","cluster") %in% names(cluster_labels))) return(df)
  df %>%
    dplyr::left_join(
      cluster_labels %>% dplyr::select(participant_id, cluster_lbl = cluster),
      by = "participant_id"
    ) %>%
    dplyr::mutate(cluster = dplyr::coalesce(.data$cluster, .data$cluster_lbl)) %>%
    dplyr::select(-dplyr::any_of("cluster_lbl"))
}

# flexible subset normalizer (expr / quosure / formula / string)
as_quosure_or_null <- function(expr) {
  if (is.null(expr)) return(NULL)
  if (rlang::is_quosure(expr)) return(expr)
  if (inherits(expr, "formula")) return(rlang::as_quosure(rlang::f_rhs(expr), env = rlang::caller_env()))
  if (is.character(expr) && length(expr) == 1L) return(rlang::parse_quo(expr, env = rlang::caller_env()))
  rlang::as_quosure(expr, env = rlang::caller_env())
}

# Summarize flow + related functions
`%||%` <- function(x, y) if (is.null(x) || (is.data.frame(x) && nrow(x) == 0)) y else x
fmtN <- function(x) format(x, big.mark = ",")
summarize_flow <- function(df,
                           outcome_cols,
                           covar_candidates = c("age","age_years","age_end","age_wave","sex","sex_at_birth"),
                           subset_expr = NULL,
                           wave_col = NULL,
                           completeness = c("union","intersection"),
                           censor_after_first = FALSE) {
  
  completeness <- match.arg(completeness)
  
  # ---- guards ----
  if (is_tk(df) || is.null(df) || !"participant_id" %in% names(df)) {
    return(list(
      text_available      = "TK - analysis dataset not available.",
      text_details        = "",
      waves               = NULL,
      included_by_outcome = tibble::tibble(),
      per_outcome         = tibble::tibble()
    ))
  }
  
  dd <- ensure_cluster(ensure_ids(df))
  
  # optional subset
  if (!is.null(subset_expr)) {
    q <- as_quosure_or_null(subset_expr)
    if (!is.null(q)) dd <- dplyr::filter(dd, !!q)
  }
  
  # wave column
  wcol <- wave_col %||% pick_wave_col(dd)
  if (is.na(wcol)) {
    return(list(
      text_available      = "TK - no wave/timepoint column detected.",
      text_details        = "",
      waves               = NULL,
      included_by_outcome = tibble::tibble(),
      per_outcome         = tibble::tibble()
    ))
  }
  
  # choose covariates present
  age_var <- intersect(c("age_end","age_wave"), names(dd))
  age_var <- if (length(age_var)) age_var[[1]] else NA_character_
  sex_var <- intersect(c("sex"), names(dd))
  sex_var <- if (length(sex_var)) sex_var[[1]] else NA_character_
  
  # event/status column (for LONG DTH)
  event_col <- intersect(c("event","status"), names(dd))
  event_col <- if (length(event_col)) event_col[[1]] else NA_character_
  
  # detect shapes
  looks_long <- "outcome" %in% names(dd) && !is.na(event_col)
  outs_in_long <- if (looks_long) intersect(outcome_cols, unique(dd$outcome)) else character(0)
  is_long <- looks_long && length(outs_in_long) > 0
  
  # detect WIDE-DTH event columns if not long
  # map each requested outcome -> the first matching column present
  find_event_col <- function(nm) {
    cands <- c(paste0("event_", nm), paste0("status_", nm))
    hit <- cands[cands %in% names(dd)]
    if (length(hit)) hit[[1]] else NA_character_
  }
  wide_event_map <- setNames(purrr::map_chr(outcome_cols, find_event_col), outcome_cols)
  has_wide_events <- any(!is.na(wide_event_map))
  
  # ---- DTH censoring (long only) ----
  if (is_long && censor_after_first) {
    ord_col <- if ("interval_index" %in% names(dd)) "interval_index" else wcol
    dd <- dd %>%
      dplyr::group_by(.data$participant_id, .data$outcome) %>%
      dplyr::arrange(.data[[ord_col]], .by_group = TRUE) %>%
      dplyr::mutate(
        first_event_flag  = dplyr::coalesce(.data[[event_col]] == 1, FALSE),
        at_or_after_first = base::cummax(first_event_flag) > 0,
        after_first       = dplyr::lag(at_or_after_first, default = FALSE)
      ) %>%
      dplyr::filter(!after_first) %>%
      dplyr::ungroup()
  }
  
  included_by_outcome <- tibble::tibble()
  
  if (is_long) {
    # keep only requested outcomes
    dd <- dd %>% dplyr::filter(.data$outcome %in% outs_in_long)
    
    # flags per id x wave
    cl_df <- dd %>%
      dplyr::group_by(.data$participant_id, .data[[wcol]]) %>%
      dplyr::summarise(no_cluster = !any(!is.na(.data$cluster)), .groups = "drop")
    
    age_df <- if (!is.na(age_var)) {
      dd %>% dplyr::group_by(.data$participant_id, .data[[wcol]]) %>%
        dplyr::summarise(miss_age = any(is.na(.data[[age_var]])), .groups = "drop")
    } else dd %>% dplyr::distinct(.data$participant_id, .data[[wcol]]) %>% dplyr::mutate(miss_age = FALSE)
    
    sex_df <- if (!is.na(sex_var)) {
      dd %>% dplyr::group_by(.data$participant_id, .data[[wcol]]) %>%
        dplyr::summarise(miss_sex = any(is.na(.data[[sex_var]])), .groups = "drop")
    } else dd %>% dplyr::distinct(.data$participant_id, .data[[wcol]]) %>% dplyr::mutate(miss_sex = FALSE)
    
    # presence (non-NA event) without pivot: per id x wave x outcome
    present_long <- dd %>%
      dplyr::group_by(.data$participant_id, .data[[wcol]], .data$outcome) %>%
      dplyr::summarise(has_outcome = any(!is.na(.data[[event_col]])), .groups = "drop")
    
    # any/all across requested outcomes
    present_anyall <- present_long %>%
      dplyr::group_by(.data$participant_id, .data[[wcol]]) %>%
      dplyr::summarise(
        any_present = any(.data$has_outcome),
        all_present = all(.data$has_outcome),
        .groups = "drop"
      )
    
    base <- cl_df %>%
      dplyr::left_join(age_df,  by = c("participant_id", wcol)) %>%
      dplyr::left_join(sex_df,  by = c("participant_id", wcol)) %>%
      dplyr::left_join(present_anyall, by = c("participant_id", wcol)) %>%
      dplyr::mutate(
        miss_cov     = miss_age | miss_sex,
        wave_pretty = wave_lab(.data[[wcol]]),
        miss_outcome = if (completeness == "union")
          !dplyr::coalesce(.data$any_present, FALSE) else
            !dplyr::coalesce(.data$all_present, FALSE)
      )
    
    # elig for per-outcome counts
    # ---- Build a single robust join key and eligibility ----
    base <- base %>%
      dplyr::mutate(.key = paste0(.data$participant_id, "||", .data[[wcol]]))
    present_long <- present_long %>%
      dplyr::mutate(.key = paste0(.data$participant_id, "||", .data[[wcol]]))
    
    elig_df <- base %>%
      dplyr::transmute(.key, .elig = !.data$no_cluster & !.data$miss_cov)
    
    # ---- Included-by-outcome counts (now join by the single key) ----
    included_by_outcome <- present_long %>%
      dplyr::left_join(elig_df, by = ".key") %>%
      dplyr::filter(.data$.elig & .data$has_outcome) %>%
      dplyr::mutate(wave = wave_lab(.data[[wcol]])) %>%
      dplyr::group_by(wave, outcome = .data$outcome) %>%
      dplyr::summarise(n = dplyr::n_distinct(.data$participant_id), .groups = "drop") %>%
      order_waves("wave")
    
    outcomes_list <- outs_in_long
    
    # helper: get has_out for a single outcome (LONG) without using dynamic columns
    get_has_outcome <- function(target_outcome) {
      pw <- present_long %>%
        dplyr::filter(.data$outcome == target_outcome) %>%
        dplyr::select(.key, has_out = has_outcome)
      base %>%
        dplyr::left_join(pw, by = ".key") %>%
        dplyr::mutate(has_out = dplyr::coalesce(.data$has_out, FALSE))
    }
    
    if (nrow(included_by_outcome) == 0L) {
      message("[diag] present_long rows: ", nrow(present_long))
      message("[diag] base rows: ", nrow(base))
      print(
        present_long %>%
          dplyr::left_join(elig_df, by = ".key") %>%
          dplyr::mutate(wave = wave_lab(.data[[wcol]])) %>%
          dplyr::count(outcome, wave, has_outcome, .elig) %>%
          dplyr::arrange(outcome, wave)
      )
    }
    
  } else {
    # ---- WIDE (panel) or WIDE-DTH (event_* / status_*) ----
    base0 <- dd %>%
      dplyr::distinct(participant_id, .data[[wcol]], .keep_all = TRUE) %>%
      dplyr::rename(.wave = !!rlang::sym(wcol)) %>%
      dplyr::mutate(wave = wave_lab(.wave))
    
    # two possibilities:
    # A) classic panel wide: outcome columns exist by their names
    outs_in_wide <- intersect(outcome_cols, names(base0))
    
    # B) WIDE-DTH: map outcomes to event_* / status_* columns
    wide_map <- if (length(outs_in_wide)) {
      setNames(outs_in_wide, outs_in_wide)  # identity map
    } else if (has_wide_events) {
      purrr::keep(wide_event_map, ~ !is.na(.x))
    } else {
      character(0)
    }
    
    # compute any/all present across requested outcomes
    if (length(wide_map)) {
      sel <- dplyr::select(base0, dplyr::all_of(unname(wide_map)))
      # for panel: present = !is.na(value); for event_*: present = !is.na(event col)
      mat <- as.matrix(!is.na(sel))
      any_present <- rowSums(mat) > 0
      all_present <- rowSums(!mat) == 0
    } else {
      any_present <- rep(FALSE, nrow(base0))
      all_present <- rep(FALSE, nrow(base0))
    }
    
    base <- base0 %>%
      dplyr::mutate(
        no_cluster   = is.na(.data$cluster),
        miss_age     = if (!is.na(age_var)) is.na(.data[[age_var]]) else FALSE,
        miss_sex     = if (!is.na(sex_var)) is.na(.data[[sex_var]]) else FALSE,
        miss_cov     = miss_age | miss_sex,
        miss_outcome = if (completeness == "union") !any_present else !all_present
      )
    
    # per-outcome included counts
    if (length(wide_map)) {
      included_by_outcome <- purrr::map_dfr(names(wide_map), function(o) {
        col <- wide_map[[o]]
        base %>%
          dplyr::filter(!no_cluster, !miss_cov, !is.na(.data[[col]])) %>%
          dplyr::group_by(wave) %>%
          dplyr::summarise(n = dplyr::n_distinct(participant_id), .groups = "drop") %>%
          dplyr::mutate(outcome = o, .before = 1)
      })
    } else {
      included_by_outcome <- tibble::tibble(wave = character(), outcome = character(), n = integer())
    }
    
    outcomes_list <- names(wide_map)
    
    # helper: get has_out for a single outcome (WIDE), using map to actual column
    get_has_outcome <- function(target_outcome) {
      if (!target_outcome %in% names(wide_map)) {
        return(base %>% dplyr::mutate(has_out = FALSE))
      }
      col <- wide_map[[target_outcome]]
      base %>% dplyr::mutate(has_out = !is.na(.data[[col]]))
    }
  }
  
  # Ensure a pretty display column named 'wave' without breaking joins above
  if ("wave_pretty" %in% names(base)) {
    base <- base %>% dplyr::mutate(wave = .data$wave_pretty)
  }
  
  # wave summary for overview
  wave_summ <- base %>%
    dplyr::group_by(wave) %>%
    dplyr::summarise(
      start_n      = dplyr::n_distinct(participant_id),
      no_cluster   = dplyr::n_distinct(participant_id[no_cluster]),
      miss_sex     = dplyr::n_distinct(participant_id[miss_sex]),
      miss_age     = dplyr::n_distinct(participant_id[miss_age]),
      miss_outcome = dplyr::n_distinct(participant_id[miss_outcome]),
      final_n      = dplyr::n_distinct(participant_id[!no_cluster & !miss_cov & !miss_outcome]),
      .groups = "drop"
    ) %>%
    dplyr::arrange(wave) %>%
    dplyr::mutate(removed = start_n - final_n)
  wave_summ <- wave_summ %>% order_waves("wave")
  
  
  # ----- Overview box: "Available for analysis" (cluster + covars present) -----
  available_by_wave <- base %>%
    dplyr::group_by(wave) %>%
    dplyr::summarise(
      available_n = dplyr::n_distinct(participant_id[!no_cluster & !miss_cov]),
      .groups = "drop"
    ) %>% dplyr::arrange(wave)
  
  text_available <- paste(
    "Available for Analysis:",
    paste0("    ",
           paste0(available_by_wave$wave, ": ", format(available_by_wave$available_n, big.mark=",")),
           collapse = "\n"),
    sep = "\n"
  )
  
  # ----- Per-outcome breakdown (by wave): included + reasons (fixed) -----
  per_outcome_df <- if (length(outcomes_list)) {
    purrr::map_dfr(outcomes_list, function(o) {
      df_o <- get_has_outcome(o)
      
      df_o %>%
        dplyr::group_by(wave) %>%
        dplyr::summarise(
          included      = dplyr::n_distinct(participant_id[!no_cluster & !miss_cov &  has_out]),
          miss_outcome  = dplyr::n_distinct(participant_id[!no_cluster & !miss_cov & !has_out]),
          miss_cluster  = dplyr::n_distinct(participant_id[ no_cluster ]),
          # KEY FIX: covariate exclusion as a union (not age + sex)
          miss_cov      = dplyr::n_distinct(participant_id[ !no_cluster &  miss_cov ]),
          # keep these if you still want to report them elsewhere
          miss_sex      = dplyr::n_distinct(participant_id[ miss_sex ]),
          miss_age      = dplyr::n_distinct(participant_id[ miss_age ]),
          .groups = "drop"
        ) %>%
        dplyr::arrange(wave) %>%
        dplyr::mutate(outcome = o, .before = 1)
    })
  } else {
    tibble::tibble(outcome = character(), wave = character(),
                   included = integer(), miss_outcome = integer(),
                   miss_cluster = integer(), miss_cov = integer(),
                   miss_sex = integer(), miss_age = integer())
  }
  
  detail_lines <- purrr::map_chr(unique(base$wave), function(w) {
    rows <- per_outcome_df %>% dplyr::filter(.data$wave == w)
    if (nrow(rows) == 0) return(paste0("  ", w, ": (no requested outcomes present)"))
    inner <- paste0(
      "    ",
      paste0(
        rows$outcome, ": ",
        "included=",     format(rows$included, big.mark=","),  "; ",
        "miss outcome=", format(rows$miss_outcome, big.mark=","), "; ",
        "cluster=",      format(rows$miss_cluster, big.mark=","), "; ",
        "sex=",          format(rows$miss_sex, big.mark=","), "; ",
        "age=",          format(rows$miss_age, big.mark=",")
      ),
      collapse = "\n    "
    )
    paste0("  ", w, ":\n", inner)
  })
  
  text_details <- paste(
    "Per-outcome breakdown (by wave):",
    paste0(detail_lines, collapse = "\n"),
    sep = "\n"
  )
  
  list(
    text_available       = text_available,
    text_details         = text_details,
    waves                = wave_summ,
    included_by_outcome  = included_by_outcome,
    per_outcome          = per_outcome_df
  )
}

#4.4 Per-analysis summaries (explicit & robust) ---------------------------------
nested_dth_subset  <- if ("ever_bd" %in% names(nested_pp))    "ever_bd == TRUE" else NULL
nested_prev_subset <- if ("ever_bd" %in% names(nested_panel)) "ever_bd == TRUE" else NULL

bd_dth_summary <- summarize_flow(
  df = bd_pp,
  outcome_cols = c("any_bsd","bipolar_I","bipolar_II","bd_nos"),
  covar_candidates = c("age_end","sex"),
  wave_col = "end_wave",
  completeness = "union",
  censor_after_first = TRUE
)

su_dth_summary <- summarize_flow(
  df = nested_pp,
  outcome_cols = c("si_passive","si_active","sa","nssi"),
  covar_candidates = c("age_end","sex"),
  subset_expr = nested_dth_subset,
  wave_col = "end_wave",
  completeness = "union",
  censor_after_first = TRUE
)

bd_prev_summary <- summarize_flow(
  df = bd_panel,
  outcome_cols = c("any_bsd","bipolar_I","bipolar_II","bd_nos"),
  covar_candidates = c("age_wave","sex"),
  completeness = "union"
)

# keep only Y2/Y4 for nested suicidality PREVALENCE (no Y6)
.su_prev_keep_waves <- c("ses-02A","ses-04A")
.su_prev_subset_expr <- paste0(
  "(", pick_wave_col(nested_panel), " %in% c('", paste(.su_prev_keep_waves, collapse="','"), "'))",
  if (!is.null(nested_prev_subset)) paste0(" & (", nested_prev_subset, ")") else ""
)

su_prev_summary <- summarize_flow(
  df = nested_panel,
  outcome_cols = c("si_passive","si_active","sa","nssi"),
  covar_candidates = c("age_wave","sex"),
  subset_expr = .su_prev_subset_expr,  # <— apply Y2/Y4-only filter (plus ever_bd if present)
  completeness = "union"
)

# --- Fix: robust baseline & cluster counts for CONSORT top row ----

# 1) Baseline N (prefer any available roster-like table; else max over known frames)
if (!exists("baseline_n", inherits = FALSE) || !is.finite(suppressWarnings(baseline_n))) {
  distinct_n <- function(df) if (!is.null(df) && "participant_id" %in% names(df)) dplyr::n_distinct(df$participant_id) else NA_integer_
  baseline_n <- suppressWarnings(max(c(
    distinct_n(risk_vars),
    distinct_n(outcome_vars),
    distinct_n(cluster_labels),
    distinct_n(bd_panel),
    distinct_n(bd_pp),
    distinct_n(nested_panel),
    distinct_n(nested_pp)
  ), na.rm = TRUE))
  if (!is.finite(baseline_n)) baseline_n <- 11878L  # ABCD scale safety cap
}

# 2) Clustered counts (distinct IDs; accept multiple label conventions)
norm_cluster <- function(x) {
  x <- tolower(as.character(x))
  dplyr::case_when(
    x %in% c("c1","1","high","higher","higher-risk","higher risk","hr") ~ "C1",
    x %in% c("c2","2","low","lower","lower-risk","lower risk","lr")      ~ "C2",
    TRUE ~ NA_character_
  )
}

get_cluster_counts <- function() {
  cand <- list(cluster_labels, bd_panel, bd_pp, nested_panel, nested_pp)
  cl_raw <- purrr::compact(purrr::map(cand, \(d) {
    if (is.null(d)) return(NULL)
    if (!all(c("participant_id","cluster") %in% names(d))) return(NULL)
    d %>% dplyr::select(participant_id, cluster) %>% dplyr::filter(!is.na(cluster))
  })) %>% dplyr::bind_rows()
  if (nrow(cl_raw) == 0) return(list(c1 = NA_integer_, c2 = NA_integer_))
  cl_once <- cl_raw %>%
    dplyr::mutate(clu = norm_cluster(cluster)) %>%
    dplyr::filter(!is.na(clu)) %>%
    dplyr::distinct(participant_id, .keep_all = TRUE)
  list(
    c1 = sum(cl_once$clu == "C1"),
    c2 = sum(cl_once$clu == "C2")
  )
}

cc <- get_cluster_counts()
c1_n <- cc$c1; c2_n <- cc$c2

inc_total <- sum(c(c1_n, c2_n), na.rm = TRUE)
excl_pre_cluster <- max(baseline_n - inc_total, 0L)

# Pretty labels (unchanged; keep this where it is)
pretty_outcome_label <- function(x) dplyr::recode(
  x,
  "any_bsd"   = "Any BSD",
  "bipolar_I" = "BD I",
  "bipolar_II"= "BD II",
  "bd_nos"    = "BD NOS",
  "si_passive"= "Passive SI",
  "si_active" = "Active SI",
  "sa"        = "SA",
  "nssi"      = "NSSI",
  .default = x
)

# --- helper: body-only strings per outcome, one line per wave, with hanging indent
build_ex_inc_blocks <- function(sum_obj, wanted) {
  df <- sum_obj$per_outcome
  ex  <- rep("  (no waves)", length(wanted))
  inc <- rep("  (no waves)", length(wanted))
  names(ex) <- names(inc) <- wanted
  
  if (!is.null(df) && nrow(df) > 0) {
    for (o in intersect(wanted, unique(df$outcome))) {
      d <- df %>% dplyr::filter(.data$outcome == o) %>% dplyr::arrange(wave)
      
      ex_lines <- sprintf("%s: Cl=%s, Cov=%s, Out=%s",
                          d$wave, fmtN(d$miss_cluster),
                          fmtN(d$miss_cov),               # <- use the union, not age+sex
                          fmtN(d$miss_outcome))
      inc_lines <- sprintf("%s: %s", d$wave, fmtN(d$included))
      
      ex[o]  <- paste0("  ", paste(ex_lines,  collapse = "\n  "))
      inc[o] <- paste0("  ", paste(inc_lines, collapse = "\n  "))
    }
  }
  list(ex = unname(ex[wanted]), inc = unname(inc[wanted]))
}

# ---- CONSORT tuning knobs (easy to tweak) ------------------------------------
CONSORT_KNOBS <- list(
  text_cex     = 0.82,   # ↑ for larger text; ↓ for smaller
  lineheight   = 0.8,   # a bit more breathing room
  width_scale  = 1.15,   # multiplies all text_width values (try 1.10-1.35)
  top_width    = 36,     # baseline widths (pre-scale) for top row boxes
  side_width   = 34,
  cluster_width= 34,
  split_width  = 36,     # split titles row
  avail_width  = 40,     # "Available for analysis" row
  branch_width = 44      # EXCLUDED / INCLUDED branch boxes
)
.w <- function(x) ceiling(x * CONSORT_KNOBS$width_scale)  # width helper

#4.5 Build CONSORT (manual API) -------------------------------------------------
if (requireNamespace("consort", quietly = TRUE)) {
  # Use the knobs above for fast iteration
  tiny_gp <- grid::gpar(
    cex        = CONSORT_KNOBS$text_cex,
    lineheight = CONSORT_KNOBS$lineheight
  )
  
  root_txt <- glue::glue(
    "ABCD Baseline Participants\nn = {format(baseline_n, big.mark=',')}"
  )
  excl_txt <- glue::glue(
    "Excluded before clustering\nn = {format(excl_pre_cluster, big.mark=',')}\n(Missing Risk Variables)"
  )
  clus_txt <- glue::glue(
    "Clustered\nN = {format(inc_total, big.mark=',')}\nHigher-Risk = {format(c1_n, big.mark=',')};  Lower-Risk = {format(c2_n, big.mark=',')}"
  )
  
  # Top row (use adjustable widths)
  g <- consort::add_box(txt = root_txt, text_width = .w(CONSORT_KNOBS$top_width), txt_gp = tiny_gp)
  g <- consort::add_side_box(g, txt = excl_txt, side = "right",
                             text_width = .w(CONSORT_KNOBS$side_width), txt_gp = tiny_gp)
  g <- consort::add_box(g, txt = clus_txt, text_width = .w(CONSORT_KNOBS$cluster_width), txt_gp = tiny_gp)
  
  # Four main analyses
  split_titles <- c(
    "BD First-Onset (DTH)",
    "BD Prevalence (GEE)",
    "Suicidality First-Onset (Ever-BD; DTH)",
    "Suicidality Prevalence (Ever-BD; GEE)"
  )
  g <- consort::add_split(g, txt = split_titles,
                          text_width = .w(CONSORT_KNOBS$split_width), txt_gp = tiny_gp)
  
  # "Available for analysis"
  avail_vec <- c(
    bd_dth_summary$text_available,
    bd_prev_summary$text_available,
    su_dth_summary$text_available,
    su_prev_summary$text_available
  )
  g <- consort::add_box(g, txt = avail_vec,
                        text_width = .w(CONSORT_KNOBS$avail_width), txt_gp = tiny_gp)
  
  # Outcomes (fixed order)
  bd_outcomes <- c("any_bsd","bipolar_I","bipolar_II","bd_nos")
  su_outcomes <- c("si_passive","si_active","sa","nssi")
  
  # Build body-only blocks per outcome (reuses your helpers)
  bd_dth_blocks  <- build_ex_inc_blocks(bd_dth_summary,  bd_outcomes)
  bd_prev_blocks <- build_ex_inc_blocks(bd_prev_summary, bd_outcomes)
  su_dth_blocks  <- build_ex_inc_blocks(su_dth_summary,  su_outcomes)
  su_prev_blocks <- build_ex_inc_blocks(su_prev_summary, su_outcomes)
  
  pretty_outcome_label <- function(x) dplyr::recode(
    x, any_bsd="Any BSD", bipolar_I="BD-I", bipolar_II="BD-II", bd_nos="BD-NOS",
    si_passive="Passive SI", si_active="Active SI", sa="SA", nssi="NSSI", .default=x)
  
  branch_bullets <- function(wanted, ex_vec, inc_vec) {
    ex_bul <- paste(purrr::map2(pretty_outcome_label(wanted), ex_vec,
                                ~ paste0("• ", .x, "\n", .y)), collapse = "\n")
    inc_bul<- paste(purrr::map2(pretty_outcome_label(wanted), inc_vec,
                                ~ paste0("• ", .x, "\n", .y)), collapse = "\n")
    list(
      ex  = paste0("Excluded by wave:\n", ex_bul),
      inc = paste0("Included by wave:\n", inc_bul)
    )
  }
  
  bd_dth_p  <- branch_bullets(bd_outcomes, bd_dth_blocks$ex,  bd_dth_blocks$inc)
  bd_prev_p <- branch_bullets(bd_outcomes, bd_prev_blocks$ex, bd_prev_blocks$inc)
  su_dth_p  <- branch_bullets(su_outcomes, su_dth_blocks$ex,  su_dth_blocks$inc)
  su_prev_p <- branch_bullets(su_outcomes, su_prev_blocks$ex, su_prev_blocks$inc)
  
  # Row: EXCLUDED per branch
  g <- consort::add_box(
    g,
    txt = c(bd_dth_p$ex, bd_prev_p$ex, su_dth_p$ex, su_prev_p$ex),
    text_width = .w(CONSORT_KNOBS$branch_width),
    txt_gp = tiny_gp
  )
  
  # Row: INCLUDED per branch
  g <- consort::add_box(
    g,
    txt = c(bd_dth_p$inc, bd_prev_p$inc, su_dth_p$inc, su_prev_p$inc),
    text_width = .w(CONSORT_KNOBS$branch_width),
    txt_gp = tiny_gp
  )
  
  # Export (unchanged)
  grid_obj <- consort::build_grid(g)
  ggplot2::ggsave(file.path(fig_dir, "Figure_01_CONSORT.pdf"), plot = grid_obj,
                  width = 13.3, height = 13.2, bg = "transparent")
  ggplot2::ggsave(file.path(fig_dir, "Figure_01_CONSORT.png"), plot = grid_obj,
                  width = 13.1, height = 13.2, dpi = 720, bg = "transparent")
  grid_obj
  
} else {
  message("[WARN] Package 'consort' not available; falling back to TK bar.")
  df <- tibble::tibble(stage = c("Excluded pre-cluster","Clustered"),
                       n = c(excl_pre_cluster, inc_total))
  p_consort <- ggplot(df, aes(stage, n, fill = stage)) +
    geom_col(width = 0.6) +
    scale_fill_manual(values = c("Excluded pre-cluster"="#cccccc", "Clustered"="#444444")) +
    labs(title = "CONSORT (TK)", x = NULL, y = "N") +
    theme(legend.position = "none")
  save_fig(p_consort, "Figure_01_CONSORT", width = 11, height = 8.5)
  p_consort
}

```

## Table 2 - Baseline Characteristics of the Clustered Sample

```{r table 2}

## 2. TABLE 2: Baseline characteristics of the clustered sample ---------------

# --- strict columns from raw dataset.csv
DEM_COLS <- list(
  id      = "participant_id",
  session = "session_id",
  age     = "ab_g_dyn__visit_age",
  sex     = "ab_g_stc__cohort_sex"  # 1=Male, 2=Female
)

read_demographics_strict <- function() {
  dem_path <- first_existing(
    p_data("data_raw", "dataset.csv"),
    "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/data/data_raw/dataset.csv"
  )
  dem <- safe_read(dem_path)
  need <- unlist(DEM_COLS, use.names = FALSE)
  miss <- setdiff(need, names(dem))
  if (length(miss)) stop("Missing required columns in raw dataset: ", paste(miss, collapse=", "))

  dem %>%
    dplyr::select(
      participant_id = !!DEM_COLS$id,
      session_id     = !!DEM_COLS$session,
      age            = !!DEM_COLS$age,
      sex_code       = !!DEM_COLS$sex
    ) %>%
    dplyr::group_by(participant_id) %>%
    dplyr::arrange(session_id, .by_group = TRUE) %>%
    dplyr::slice(1) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(
      sex = dplyr::case_when(
        sex_code %in% c(1,"1") ~ "Male",
        sex_code %in% c(2,"2") ~ "Female",
        TRUE ~ NA_character_
      )
    ) %>%
    dplyr::select(participant_id, age, sex)
}

# --- baseline outcomes (exact columns from outcome_vars, earliest session_id)
DIAG_COLS <- c("any_bsd","bipolar_I","bipolar_II","bd_nos","si_passive","si_active","sa","nssi")

baseline_outcomes <- function(ov) {
  need <- c("participant_id","session_id", DIAG_COLS)
  miss <- setdiff(need, names(ov))
  if (length(miss)) stop("Missing required columns in outcome_vars: ", paste(miss, collapse=", "))

  ov %>%
    dplyr::select(dplyr::all_of(need)) %>%
    dplyr::group_by(participant_id) %>%
    dplyr::arrange(session_id, .by_group = TRUE) %>%
    dplyr::slice(1) %>%
    dplyr::ungroup()
}

# --- build Table 2 dataset restricted to clustered sample
demographics_df <- read_demographics_strict()
ov_base         <- baseline_outcomes(outcome_vars)

tbl2_df <- cluster_labels %>%
  dplyr::select(participant_id, cluster) %>%
  dplyr::left_join(demographics_df, by = "participant_id") %>%
  dplyr::left_join(ov_base,        by = "participant_id") %>%
  dplyr::mutate(cluster = factor(cluster, levels = c("Higher-Risk","Lower-Risk")))

# labels for display
label_list <- list(
  age ~ "Age (years)",
  sex ~ "Sex at birth",
  any_bsd    ~ "Any BSD diagnosis",
  bipolar_I  ~ "BD I diagnosis",
  bipolar_II ~ "BD II diagnosis",
  bd_nos     ~ "BD NOS diagnosis",
  si_passive ~ "Passive suicidal ideation",
  si_active  ~ "Active suicidal ideation",
  sa         ~ "Suicide attempt",
  nssi       ~ "NSSI"
)

tbl2_caption <- glue::glue(
  "**Table 2. Baseline characteristics of the clustered sample**  \n",
  "Participants included in clustering (n={scales::comma(dplyr::n_distinct(tbl2_df$participant_id))})."
)

to_yesno <- function(x) {
  if (is.numeric(x) || is.logical(x)) {
    factor(dplyr::case_when(
      is.na(x) ~ NA_character_,
      as.numeric(x) == 1 ~ "Yes",
      TRUE ~ "No"
    ), levels = c("No","Yes"))
  } else x
}

tbl2_disp <- tbl2_df %>%
  dplyr::mutate(dplyr::across(dplyr::all_of(DIAG_COLS), to_yesno),
                sex = factor(sex, levels = c("Male","Female")))

if (requireNamespace("gtsummary", quietly = TRUE)) {
  # build the base table with Overall column
  tbl2_gts <-
    gtsummary::tbl_summary(
      data      = tbl2_disp %>% dplyr::select(cluster, age, sex, dplyr::all_of(DIAG_COLS)),
      by        = cluster,
      type      = list(age ~ "continuous"),
      statistic = list(
        age ~ "{mean} ({sd})",
        gtsummary::all_categorical() ~ "{n} ({p}%)"
      ),
      missing   = "no",
      label     = label_list
    ) %>%
    gtsummary::add_overall() %>%
    # clean headers to show only the level names (no N in headers)
    gtsummary::modify_header(all_stat_cols() ~ "**{level}**") %>%
    # insert a top "N" row with counts per column (Overall + each cluster)
    gtsummary::modify_table_body(~{
      tb <- .
      # counts in the same column order as the stats columns:
      # stat_0 = Overall, stat_1 = Higher-Risk, stat_2 = Lower-Risk (given factor levels)
      n_overall <- dplyr::n_distinct(tbl2_df$participant_id)
      n_by <- tbl2_df %>%
        dplyr::count(cluster, name = "n") %>%
        dplyr::arrange(factor(cluster, levels = c("Higher-Risk","Lower-Risk"))) %>%
        dplyr::pull(n)
      n_by <- c(n_by, rep(NA_integer_, max(0, 2 - length(n_by))))  # safety pad

      n_row <- tibble::tibble(
        variable  = ".N_row",           # dummy id
        var_type  = NA_character_,
        var_label = "N",
        row_type  = "label",
        label     = "N",
        stat_0    = scales::comma(n_overall),
        stat_1    = scales::comma(n_by[1]),
        stat_2    = scales::comma(n_by[2])
      )

      dplyr::bind_rows(n_row, tb)
    }) %>%
    gtsummary::modify_caption(tbl2_caption) %>%
    gtsummary::as_gt()

  save_gt(tbl2_gts, "Table_02_Baseline_Characteristics")
  tbl2_gts
} else {
  # fallback unchanged
  mini <- tbl2_df %>%
    dplyr::count(cluster, name = "n") %>%
    dplyr::mutate(pct = 100 * n / sum(n)) %>%
    dplyr::arrange(cluster)

  mini_gt <- gt::gt(mini) %>%
    gt::fmt_number(columns = "pct", decimals = 1) %>%
    gt::cols_label(cluster = "Cluster", n = "n", pct = "Percent") %>%
    gt::tab_caption(paste0(tbl2_caption, "  (limited: gtsummary not available)."))

  save_gt(mini_gt, "Table_02_Baseline_Characteristics_minimal")
  mini_gt
}

```

## Figure 3 - Internal Validation of Optimal k (silhouette, UMAP, elbow)

```{r fig3-umap-profiles}

## 3. FIGURE 3: Internal validation (silhouette • UMAP • elbow) ---------------

# replace your current helper with this:
axes_only_theme <- function(base_size = 11, axis_text_size = 9, axis_title_size = 10) {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.line = element_blank(),
      axis.line.x.bottom = element_line(color = "black"),
      axis.line.y.left   = element_line(color = "black"),
      axis.ticks = element_line(color = "black"),
      axis.ticks.x.top = element_blank(),
      axis.ticks.y.right = element_blank(),
      axis.text  = element_text(size = axis_text_size),
      axis.title.x = element_text(size = axis_title_size),
      axis.title.y = element_text(size = axis_title_size)
    )
}

# Cluster label mapping (C1/1/high/higher/Higher-Risk -> "1"; C2/2/low/lower/Lower-Risk -> "2")
coerce_cluster_digits <- function(x) {
  x_chr <- as.character(x)
  out <- dplyr::case_when(
    x_chr %in% c("C1","1","high","higher","Higher-Risk") ~ "1",
    x_chr %in% c("C2","2","low","lower","Lower-Risk")    ~ "2",
    TRUE ~ x_chr
  )
  # Normalize things like "C3" -> "3", "C4" -> "4"
  out <- sub("^\\s*(?:[Cc]|[Cc]luster)\\s*([0-9]+)\\s*$", "\\1", out, perl = TRUE)
  out
}

# 3a) Silhouette vs k
sil_df <- if (exists("k_sil")) k_sil else val_sil_perk
sil_df <- sil_df %||% read_or_tk("", tk_cols = c("k","scaling","silhouette"))
sil_df <- sil_df %>% dplyr::mutate(scaling = dplyr::coalesce(scaling, "robust_iqr"))

sil_main <- sil_df %>% dplyr::filter(tolower(scaling) %in% c("robust_iqr","iqr","median_iqr"))
if (!nrow(sil_main)) sil_main <- sil_df

best_row <- sil_main %>% dplyr::arrange(dplyr::desc(silhouette)) %>% dplyr::slice(1)
best_k   <- best_row$k %||% 2L

p_sil <- ggplot(sil_main, aes(k, silhouette)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  geom_vline(xintercept = best_k, linetype = "dashed") +
  labs(
    x = "Number of clusters (k)",
    y = "Mean silhouette score",
    title = "A) Mean Silhouette Score by k Solution"
  ) +
  axes_only_theme() +
  theme(legend.position = "none")

# 3b) UMAP panels (k = 2–4 if files exist)
load_umap_k <- function(k) {
  p <- first_existing(
    p_valid(glue::glue("umap_embedding_k{k}.csv")),
    p_valid(glue::glue("umap_embedding_k{k}.rds"))
  )
  df <- safe_read(p)
  if (is.null(df)) return(NULL)
  
  # Accept CSV with UMAP1/UMAP2/Cluster OR tidy x/y/cluster OR umap object (RDS)
  if (all(c("UMAP1","UMAP2") %in% names(df))) {
    df <- dplyr::rename(df, x = UMAP1, y = UMAP2)
  } else if (all(c("UMAP_1","UMAP_2") %in% names(df))) {
    df <- dplyr::rename(df, x = UMAP_1, y = UMAP_2)
  } else if (!all(c("x","y") %in% names(df))) {
    if (is.list(df) && !is.null(df$layout)) {
      df <- tibble::tibble(x = df$layout[,1], y = df$layout[,2])
    } else {
      return(NULL)
    }
  }
  
  if ("Cluster" %in% names(df) && !"cluster" %in% names(df)) {
    df <- dplyr::rename(df, cluster = Cluster)
  }
  if (!"cluster" %in% names(df)) return(NULL)
  
  df$cluster <- coerce_cluster_digits(df$cluster)
  df$k <- k
  df
}

umaps <- purrr::compact(list(load_umap_k(2), load_umap_k(3), load_umap_k(4)))
if (!length(umaps)) {
  umaps <- list(umap_embed %>% dplyr::mutate(k = 2, cluster = coerce_cluster_digits(cluster)))
}
umap_df <- dplyr::bind_rows(umaps) %>%
  dplyr::mutate(k = factor(k, levels = sort(unique(k))))

# --- Build UMAP palette (after umap_df) for digit labels
present_levels <- sort(unique(umap_df$cluster))
pal_all <- c("1"="#7F3C8D", "2"="#11A579", "3"="#3969AC", "4"="#F2B701", "5"="#E66100")
pal <- pal_all[present_levels]

# --- Apply theme + palette (small axis text) and give facets breathing room
p_sil <- p_sil + axes_only_theme() + theme(legend.position = "none")

p_umap <- ggplot(umap_df, aes(x, y, color = cluster)) +
  geom_point(alpha = 0.6, size = 0.8) +
  facet_wrap(~k, ncol = 2, labeller = labeller(k = function(x) paste0("k = ", x))) +
  coord_equal() +
  scale_color_manual(values = pal, breaks = present_levels) +
  labs(title = "B) UMAP Embeddings by k Solution", x = "UMAP Dimension 1", y = "UMAP Dimension 2") +
  axes_only_theme(axis_text_size = 8) +
  theme(
    legend.position = "bottom",
    panel.spacing = grid::unit(1.2, "lines")
  ) +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))

# 3c) Elbow plot with Kneedle (max distance to end-line), no text
knee_detect <- function(df) {
  df <- df %>% dplyr::arrange(k)
  x <- df$k; y <- df$wss
  p1 <- c(x[1], y[1]); p2 <- c(x[length(x)], y[length(x)])
  denom <- sqrt((p2[2]-p1[2])^2 + (p2[1]-p1[1])^2)
  d <- abs((p2[2]-p1[2])*x - (p2[1]-p1[1])*y + p2[1]*p1[2] - p2[2]*p1[1]) / denom
  x[which.max(d)]
}

wss_df <- if (exists("k_wss")) k_wss else read_or_tk("", tk_cols = c("k","scaling","wss"))
wss_main <- wss_df %>% dplyr::filter(tolower(scaling) %in% c("robust_iqr","iqr","median_iqr"))
if (!nrow(wss_main)) wss_main <- wss_df
knee_k <- if (nrow(wss_main)) knee_detect(wss_main) else NA_integer_

p_elbow <- ggplot(wss_main, aes(k, wss)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  geom_vline(xintercept = knee_k, linetype = "dashed", color = "black") +
  labs(
    x = "Number of clusters (k)",
    y = "Total WSS",
    title = "C) Elbow Plot (WSS) by k Solution"
  ) +
  axes_only_theme() +
  theme(legend.position = "none")
p_elbow <- p_elbow + axes_only_theme() + theme(legend.position = "none")

# Layout & export (give UMAP more width)
fig3 <- ((p_sil / p_elbow) | p_umap) + patchwork::plot_layout(widths = c(1, 1.25))
save_fig(fig3, "Figure_03_Internal_Validation", width = 12.5, height = 6.5)
fig3

```

## Table 3 - Baseline Risk Variable Descriptives by Cluster (+ effect sizes)

```{r table 3}

## 4. TABLE 3: Risk-variable descriptives by cluster (+ effect sizes) ----------

# pkgs we rely on
stopifnot(
  requireNamespace("dplyr", quietly = TRUE),
  requireNamespace("tidyr", quietly = TRUE),
  requireNamespace("effectsize", quietly = TRUE),
  requireNamespace("broom", quietly = TRUE),
  requireNamespace("gt", quietly = TRUE),
  requireNamespace("purrr", quietly = TRUE)
)

# --- cluster label mapping C1->Higher-Risk, C2->Lower-Risk (as per your paper)
coerce_cluster <- function(x) {
  dplyr::recode(as.character(x),
    "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
    "C2"="Lower-Risk", "2"="Lower-Risk", "low"="Lower-Risk", "lower"="Lower-Risk",
    .default = as.character(x)
  )
}

# --- bring risk_vars + cluster
# --- bring risk_vars + cluster
rv0 <- risk_vars
if (!is.null(rv0) && nrow(rv0)) {
  if (!"cluster" %in% names(rv0) && !is_tk(cluster_labels)) {
    rv0 <- rv0 %>% dplyr::left_join(cluster_labels, by = "participant_id")
  }
  rv0 <- rv0 %>%
    dplyr::mutate(cluster = coerce_cluster(cluster)) %>%
    dplyr::filter(cluster %in% c("Higher-Risk","Lower-Risk"))

  # NEW: pivot wide -> long (make `variable` + `value`)
  id_cols <- c("participant_id","session_id","site","age","race_ethnicity","sex","family_id","cluster")
  risk_cols <- setdiff(names(rv0), id_cols)
  rv0 <- rv0 %>%
    tidyr::pivot_longer(
      cols = dplyr::all_of(risk_cols),
      names_to  = "variable",
      values_to = "value"
    )
} else {
  rv0 <- read_or_tk("", tk_cols = c("participant_id","variable","value","cluster"))
}

# --- type detection (binary if all non-missing values are 0/1; else numeric->continuous)
var_types <- rv0 %>%
  dplyr::group_by(variable) %>%
  dplyr::summarise(
    n_nonmiss  = sum(!is.na(value)),
    is_numeric = all(is.numeric(value) | is.integer(value)),
    uniq_nonNA = dplyr::n_distinct(value[!is.na(value)]),
    all01      = all(value[!is.na(value)] %in% c(0,1)),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    type = dplyr::case_when(
      is_numeric & all01 ~ "Binary",
      is_numeric & uniq_nonNA > 2 ~ "Continuous",
      TRUE ~ "Other"
    )
  )

cont_vars <- var_types %>% dplyr::filter(type == "Continuous", n_nonmiss > 1) %>% dplyr::pull(variable)
bin_vars  <- var_types %>% dplyr::filter(type == "Binary",     n_nonmiss > 0) %>% dplyr::pull(variable)

# --- helpers
fmt_m_sd <- function(x) sprintf("%.2f (%.2f)", mean(x, na.rm = TRUE), stats::sd(x, na.rm = TRUE))
fmt_n_pct <- function(n1, den) sprintf("%d (%.1f%%)", n1, 100 * n1 / den)
fmt_ci <- function(lo, hi, digits = 2) sprintf("[%.2f, %.2f]", round(lo, digits), round(hi, digits))
fmt_p <- function(p) ifelse(is.na(p), "-", ifelse(p < .001, "<.001", sprintf("%.3f", p)))

# pretty labels (optional)
label_map <- tryCatch({
  lb <- safe_read(p_proc("risk_variable_labels.csv"))
  if (is.data.frame(lb) && all(c("variable","label") %in% names(lb)))
    setNames(lb$label, lb$variable) else NULL
}, error = function(e) NULL)

# --- continuous: Cohen's d (Hedges correction) + 95% CI via effectsize; p from Welch t-test
analyze_cont <- function(v) {
  df <- rv0 %>% dplyr::filter(variable == v, !is.na(value)) %>%
    dplyr::mutate(cluster = factor(cluster, levels = c("Higher-Risk","Lower-Risk"))) # d = HR - LR

  if (length(unique(df$cluster)) < 2) return(NULL)

  # group stats
  gstats <- df %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(m = mean(value, na.rm = TRUE), s = stats::sd(value, na.rm = TRUE), n = dplyr::n(), .groups="drop")
  m_hr <- gstats$m[gstats$cluster=="Higher-Risk"]; s_hr <- gstats$s[gstats$cluster=="Higher-Risk"]
  m_lr <- gstats$m[gstats$cluster=="Lower-Risk"];  s_lr <- gstats$s[gstats$cluster=="Lower-Risk"]

  # effect size with CI
  d_obj <- effectsize::cohens_d(value ~ cluster, data = df, pooled_sd = TRUE,
                                hedges.correction = TRUE, ci = 0.95)
  d_val <- as.numeric(d_obj$Cohens_d)
  d_lo  <- as.numeric(d_obj$CI_low)
  d_hi  <- as.numeric(d_obj$CI_high)

  # p-value (Welch)
  p_val <- tryCatch({
    broom::tidy(stats::t.test(value ~ cluster, data = df))$p.value[1]
  }, error = function(e) NA_real_)

  tibble::tibble(
    Type = "Continuous",
    Variable = if (!is.null(label_map)) dplyr::recode(v, !!!label_map) else v,
    `Lower-risk`  = sprintf("%.2f (%.2f)", m_lr, s_lr),
    `Higher-risk` = sprintf("%.2f (%.2f)", m_hr, s_hr),
    `Effect (95% CI)` = sprintf("d = %.2f %s", d_val, fmt_ci(d_lo, d_hi)),
    `p` = fmt_p(p_val)
  )
}

# --- binary: OR (Higher vs Lower) with 95% CI via effectsize on glm; p from glm
analyze_bin <- function(v) {
  df <- rv0 %>% dplyr::filter(variable == v, !is.na(value)) %>%
    dplyr::mutate(
      value = as.integer(value),
      cluster = factor(cluster, levels = c("Lower-Risk","Higher-Risk")) # LR = ref
    )

  if (length(unique(df$cluster)) < 2) return(NULL)

  # counts
  tab <- df %>%
    dplyr::count(cluster, value) %>%
    tidyr::complete(cluster = c("Lower-Risk","Higher-Risk"), value = c(0,1), fill = list(n = 0)) %>%
    tidyr::pivot_wider(names_from = value, values_from = n, names_prefix = "v") %>%
    dplyr::arrange(cluster)

  lr_yes <- tab$v1[tab$cluster=="Lower-Risk"];  lr_den <- rowSums(tab[tab$cluster=="Lower-Risk", c("v0","v1")])
  hr_yes <- tab$v1[tab$cluster=="Higher-Risk"]; hr_den <- rowSums(tab[tab$cluster=="Higher-Risk", c("v0","v1")])

  # model + effect size
  fit <- stats::glm(value ~ cluster, data = df, family = stats::binomial())
  # OR + CI from effectsize
  or_es <- tryCatch(effectsize::oddsratio(fit, ci = 0.95), error = function(e) NULL)
  if (!is.null(or_es)) {
    # the row with clusterHigher-Risk
    row <- which(grepl("clusterHigher-Risk", or_es$Parameter))
    or_val <- as.numeric(or_es$OR[row]); or_lo <- as.numeric(or_es$CI_low[row]); or_hi <- as.numeric(or_es$CI_high[row])
  } else {
    # fallback to broom (still not "by hand")
    tr <- broom::tidy(fit, conf.int = TRUE, exponentiate = TRUE)
    or_row <- tr[tr$term=="clusterHigher-Risk",]
    or_val <- or_row$estimate; or_lo <- or_row$conf.low; or_hi <- or_row$conf.high
  }
  # p-value from model (Wald)
  p_val <- broom::tidy(fit)$p.value[broom::tidy(fit)$term=="clusterHigher-Risk"]

  tibble::tibble(
    Type = "Binary",
    Variable = if (!is.null(label_map)) dplyr::recode(v, !!!label_map) else v,
    `Lower-risk`  = fmt_n_pct(lr_yes, lr_den),
    `Higher-risk` = fmt_n_pct(hr_yes, hr_den),
    `Effect (95% CI)` = sprintf("OR = %.2f %s", or_val, fmt_ci(or_lo, or_hi)),
    `p` = fmt_p(p_val)
  )
}

# --- build rows
cont_rows <- purrr::map(cont_vars, analyze_cont) |> purrr::compact()
bin_rows  <- purrr::map(bin_vars,  analyze_bin)  |> purrr::compact()
t3 <- dplyr::bind_rows(cont_rows, bin_rows) |>
  dplyr::arrange(factor(Type, levels = c("Continuous","Binary")), Variable)

# --- render
t3_caption <- paste0(
  "**Table 3. Baseline risk-variable descriptive statistics by cluster**  \n",
  "Continuous: mean (SD); effect size is Cohen’s *d* with Hedges’ correction and 95% CI (Higher–Lower). ",
  "Binary: n (% “Yes”); effect size is odds ratio (Higher vs Lower) with 95% CI. ",
  "p-values from Welch *t*-test (continuous) and logistic regression Wald test (binary)."
)

t3_gt <- gt::gt(t3, groupname_col = "Type") |>
  gt::tab_caption(t3_caption) |>
  gt::cols_align(align = "center", columns = c(`Lower-risk`,`Higher-risk`,`Effect (95% CI)`,`p`))

save_gt(t3_gt, "Table_03_Risk_Variables_by_Cluster")
t3_gt

```

## Figure 4 - Baseline Risk Variable Distributions by Cluster

```{r figure 4}

## FIGURE 4: Baseline risk-variable distributions by cluster ----------------

# --- colors (paper-wide)
cluster_cols <- c("Lower-Risk" = "#11A579", "Higher-Risk" = "#7F3C8D")

# --- small theme helper (left Y + bottom X; no grids)
axes_only_theme <- function(base_size = 9, axis_text_size = 7) {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.line = element_blank(),
      axis.line.x.bottom = element_line(color = "black"),
      axis.line.y.left   = element_line(color = "black"),
      axis.ticks = element_line(color = "black"),
      axis.ticks.x.top = element_blank(),
      axis.ticks.y.right = element_blank(),
      axis.text = element_text(size = axis_text_size),
      legend.title = element_blank()
    )
}

# --- ensure needed objects (rv0 long; var_types; cont_vars; bin_vars) exist from Table 3 step
stopifnot(exists("rv0"), exists("var_types"))
cont_vars <- var_types %>% dplyr::filter(type == "Continuous", n_nonmiss > 1) %>% dplyr::pull(variable)
bin_vars  <- var_types %>% dplyr::filter(type == "Binary",     n_nonmiss > 0) %>% dplyr::pull(variable)

# Labels
labels_numeric <- c(
  "ACE_index_sum_score"                         = "ACE Index Sum Score",
  "mh_p_cbcl__synd__aggr_tscore"                = "CBCL Aggression Problems T",
  "mh_p_cbcl__synd__attn_tscore"                = "CBCL Attention Problems T",
  "mh_p_cbcl__dsm__anx_tscore"                  = "CBCL DSM-5 Anxiety T",
  "mh_p_cbcl__dsm__dep_tscore"                  = "CBCL DSM-5 Depression T",
  "le_l_coi__addr1__coi__total__national_zscore"= "COI Z-Score",
  "mh_p_gbi_sum"                                = "GBI Mania Sum Score",
  "fc_p_nsc__ns_mean"                           = "Mean Neighborhood Safety",
  "nc_y_nihtb__flnkr__uncor_score"              = "NIHTB Flanker Score",
  "nc_y_nihtb__lswmt__uncor_score"              = "NIHTB List Sorting Score",
  "nc_y_nihtb__pttcp__uncor_score"              = "NIHTB Pattern Comparison Score",
  "sds_total"                                   = "SDSC Sum Score",
  "mh_y_upps__nurg_sum"                         = "UPPS-P Negative Urgency Score",
  "mh_y_upps__purg_sum"                         = "UPPS-P Positive Urgency Score"
)

labels_binary <- c(
  "bullying"                  = "Bullying Victimization",
  "family_history_depression" = "Family History of Depression",
  "family_history_mania"      = "Family History of Mania"
)


# --- optional pretty labels (same mapping you used in Table 3)
label_map <- tryCatch({
  lb <- safe_read(p_proc("risk_variable_labels.csv"))
  if (is.data.frame(lb) && all(c("variable","label") %in% names(lb)))
    setNames(lb$label, lb$variable) else NULL
}, error = function(e) NULL)

labeller_vars <- if (!is.null(label_map)) as_labeller(label_map) else label_value

# --- build star annotations from Table 3 (no new stats)
stars_from_t3 <- NULL
if (exists("t3") && is.data.frame(t3) && all(c("Variable","p") %in% names(t3))) {
  # parse "p" which was formatted (e.g., "<.001", "0.023", "-")
  stars_from_t3 <- t3 %>%
    dplyr::transmute(
      Variable,
      p_num = dplyr::case_when(
        grepl("^<\\s*\\.?0?0*1", p) ~ 0.001,        # "<.001" or "<0.001"
        p == "-" ~ NA_real_,
        TRUE ~ suppressWarnings(as.numeric(p))
      ),
      stars = dplyr::case_when(
        is.na(p_num)        ~ "",
        p_num < 0.001       ~ "***",
        p_num < 0.01        ~ "***",
        p_num < 0.05        ~ "*",
        TRUE                ~ ""
      )
    )
  # if we have a label_map, make a lookup on label; otherwise join by raw var id
  if (!is.null(label_map)) {
    # turn raw var -> label, then join on label text in t3$Variable
    stars_from_t3 <- tibble::tibble(
      variable = names(label_map),
      Variable = unname(label_map)
    ) %>%
      dplyr::right_join(stars_from_t3, by = "Variable") %>%
      dplyr::select(variable, stars)
  } else {
    # assume t3$Variable equals the raw var names
    stars_from_t3 <- stars_from_t3 %>%
      dplyr::rename(variable = Variable) %>%
      dplyr::select(variable, stars)
  }
}

## ---------- 4A. Continuous (alphabetical by label, filled row-wise) ----------

# 1) Helper: map raw variable -> display label (CSV > fallback vector > raw name)
label_for <- function(v) {
  base <- if (!is.null(label_map)) label_map else labels_numeric
  out  <- unname(base[v])
  out[is.na(out)] <- v[is.na(out)]
  out
}

# 2) Build a key: which vars are present + their display labels
cont_key <- tibble::tibble(
  variable  = cont_vars,
  facet_lab = label_for(cont_vars)
)

# 3) Alphabetize by label (case-insensitive), use as the facet level order
cont_levels_alpha <- cont_key$facet_lab[order(tolower(cont_key$facet_lab), cont_key$facet_lab)]

# 4) Data for plotting (add the facet label column)
cont_df <- rv0 %>%
  dplyr::filter(variable %in% cont_vars,
                !is.na(value),
                cluster %in% c("Lower-Risk","Higher-Risk")) %>%
  dplyr::left_join(cont_key, by = "variable") %>%
  dplyr::mutate(
    cluster  = factor(cluster, levels = c("Lower-Risk","Higher-Risk")),
    facet_lab = factor(facet_lab, levels = cont_levels_alpha)
  )

# 5) Ranges + star positions, computed by facet label
cont_span <- cont_df %>%
  dplyr::group_by(facet_lab) %>%
  dplyr::summarise(
    y_min = min(value, na.rm = TRUE),
    y_max = max(value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(y_lab = y_max + 0.21 * (y_max - y_min))

# 6) Bring in stars from Table 3 (still keyed by raw variable), then to facet label
cont_star_map <- if (!is.null(stars_from_t3)) {
  cont_key %>% dplyr::left_join(stars_from_t3, by = "variable") %>%
    dplyr::select(facet_lab, stars)
} else {
  tibble::tibble(facet_lab = cont_levels_alpha, stars = "")
}

cont_ann <- cont_span %>%
  dplyr::left_join(cont_star_map, by = "facet_lab")

# Invisible points to grow facet headroom (needs facet_lab present in data)
cont_headroom <- tidyr::crossing(
  cont_ann[, c("facet_lab","y_lab")],
  cluster = factor(c("Lower-Risk","Higher-Risk"), levels = c("Lower-Risk","Higher-Risk"))
)

# 7) Plot — facet by the label column; row-wise fill via dir = "h"
p_cont <- ggplot(cont_df, aes(x = cluster, y = value, fill = cluster)) +
  geom_violin(trim = FALSE, alpha = 0.5, scale = "width") +
  geom_boxplot(width = 0.18, outlier.size = 0.4) +
  geom_blank(data = cont_headroom, aes(x = cluster, y = y_lab), inherit.aes = FALSE) +
  facet_wrap(~ facet_lab, scales = "free_y", dir = "h") +
  scale_fill_manual(values = cluster_cols, drop = FALSE) +
  labs(title = "A) Numeric Risk Variable Distributions by Risk Cluster",
       x = "Cluster", y = "Value") +
  axes_only_theme(base_size = 12, axis_text_size = 9) +
  coord_cartesian(clip = "off") +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.key.height = grid::unit(0.35, "lines"),
    legend.key.width  = grid::unit(0.7, "lines"),
    legend.box.spacing = grid::unit(0.2, "lines"),
    strip.text = element_text(size = 10)
  ) +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE, override.aes = list(alpha = 0.6)))

if (requireNamespace("ggsignif", quietly = TRUE) &&
    any(nchar(cont_ann$stars %||% "") > 0)) {
  p_cont <- p_cont +
    ggsignif::geom_signif(
      data = cont_ann,
      aes(xmin = 1, xmax = 2, annotations = stars, y_position = y_lab),
      manual = TRUE, inherit.aes = FALSE,
      tip_length = 0.01, textsize = 2.8, vjust = 0.25
    )
}

## ---------- 4B. Binary (just add the factor + labeller and keep your plot) ---
# order categorical facets alphabetically by clean label
bin_levels_alpha <- names(sort(labels_binary[names(labels_binary) %in% bin_vars]))

# Build the df
bin_df <- rv0 %>%
  dplyr::filter(variable %in% bin_vars,
                !is.na(value),
                cluster %in% c("Lower-Risk","Higher-Risk")) %>%
  dplyr::mutate(
    cluster  = factor(cluster, levels = c("Lower-Risk","Higher-Risk")),
    value    = ifelse(value == 1, "Yes", "No"),
    variable = factor(variable, levels = bin_levels_alpha)
  )

bin_plot_df <- bin_df %>%
  dplyr::count(variable, cluster, value) %>%
  dplyr::group_by(variable, cluster) %>%
  dplyr::mutate(pct = 100*n/sum(n)) %>%
  dplyr::ungroup()

bin_ann <- bin_plot_df %>% dplyr::distinct(variable) %>% dplyr::mutate(x = 1.5, y = 103)
if (!is.null(stars_from_t3)) bin_ann <- bin_ann %>% dplyr::left_join(stars_from_t3, by = "variable") else bin_ann$stars <- ""

p_bin <- ggplot(bin_plot_df, aes(cluster, pct, fill = value)) +
  geom_col() +
  geom_text(aes(label = n), position = position_stack(vjust = 0.5), size = 2.8) +
  facet_wrap(~ variable, labeller = as_labeller(labels_binary, default = label_value)) +
  scale_y_continuous(limits = c(0, 105), expand = expansion(mult = c(0, 0.02))) +
  scale_fill_manual(values = c("No" = "#c7d4ee", "Yes" = "#f2a1a1")) +
  labs(title = "B) Categorical Risk Variable Distributions by Risk Cluster", x = "Cluster", y = "Percent endorsed", fill = "") +
  axes_only_theme(base_size = 12, axis_text_size = 9) +
  theme(
    legend.position = "top",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.key.height = grid::unit(0.35, "lines"),
    legend.key.width  = grid::unit(0.7, "lines"),
    legend.box.spacing = grid::unit(0.2, "lines"),
    strip.text = element_text(size = 10)
  ) +
  geom_text(
    data = subset(bin_ann, nchar(stars %||% "") > 0),
    aes(x = x, y = y, label = stars),
    inherit.aes = FALSE, size = 2.8
  )

# ---------- compose & export ----------
fig4 <- p_cont / p_bin + patchwork::plot_layout(heights = c(2, 1))
save_fig(fig4, "Figure_04_Risk_Distributions_by_Cluster", width = 14, height = 11.75)
fig4

```


## Table S1: Characteristics of participants in the BD DTH onset analysis

```{r table s1}

## 6. Table S1: Characteristics of participants in the onset analysis -----------

## Pre-Processing (same as modeling) 
# Load person-period BD data
bd_pp <- bd_pp %>% 
  mutate(
    participant_id = as.character(participant_id),
    family_id = factor(as.character(family_id)),
    site_factor = factor(site_factor),
    cluster = factor(cluster),
    start_wave = factor(start_wave),
    end_wave = factor(end_wave),
    outcome = factor(outcome),
    sex = factor(sex)
  )

# Refine pre-built data using a model-ready filter that mirrors QC "post" rules
bd_pp_model <- bd_pp %>%
  filter(event %in% c(0L,1L)) %>%
  filter(!is.na(cluster)) %>%
  filter(!is.na(age_mid), !is.na(sex), !is.na(site_factor), !is.na(family_id))

# Ensure cluster, wave, sex, and site reference levels (consistent displays)
cluster_levels <- levels(bd_pp$cluster)
bd_pp_model <- bd_pp_model %>%
  mutate(
    cluster = forcats::fct_relevel(cluster, "C2"),
    end_wave = forcats::fct_relevel(end_wave, "ses-02A", "ses-04A", "ses-06A"),
    sex = forcats::fct_relevel(sex, "Female"),
    site_factor = forcats::fct_relevel(site_factor, "Site_1"))

# Establish interval length in years (02A~2, 04A~4, 06A~6); handles missed waves
wave_year <- function(w) {
  as.numeric(stringr::str_extract(as.character(w), "\\d+"))
}
bd_pp_model <- bd_pp_model %>%
  mutate(dt_years = pmax(wave_year(end_wave) - wave_year(start_wave), 1),
    log_dt = log(dt_years))

## Baseline prevalence at baseline (participants) by outcome x risk cluster ##

# IMPORTANT: do this BEFORE filtering out baseline-positive so the counts are complete - collapse to one row per participant x outcome x cluster, then count baseline-positive IDs
baseline_prev_ids <- bd_pp_model %>%
  dplyr::group_by(outcome, cluster, participant_id) %>%
  dplyr::summarise(
    baseline_pos = as.integer(any(baseline_status == 1, na.rm = TRUE)),
    .groups = "drop"
  )

## Primary risk set for FIRST ONSET (critical) ##

# Build an ID-level baseline flag using the any_bsd outcome (covers BD-I/II/NOS)
baseline_any_bsd_ids <- bd_pp_model %>% 
  dplyr::filter(outcome == "any_bsd") %>%
  dplyr::group_by(participant_id) %>%
  dplyr::summarise(
    all_na = all(is.na(baseline_status)),
    baseline_any_bsd = dplyr::if_else(
      all_na, NA_integer_, as.integer(any(baseline_status == 1L, na.rm = TRUE))
    ),
    .groups = "drop"
  )

# Join to all outcomes, do not assume 0 for missing data
bd_pp_model <- bd_pp_model %>%
  dplyr::left_join(baseline_any_bsd_ids %>% dplyr::select(participant_id, baseline_any_bsd),
    by = "participant_id")

# Filter the dataset to contain participants that had not yet had BD
bd_pp_model <- bd_pp_model %>% dplyr::filter(baseline_any_bsd == 0L)

# Censor after first onset (per outcome x participant); keep all intervals up to and including the first event==1 row; drop any later rows
bd_pp_model <- bd_pp_model %>%
  arrange(outcome, participant_id,
          if ("interval_index" %in% names(.)) interval_index else as.integer(end_wave)) %>%
  group_by(outcome, participant_id) %>%
  mutate(after_onset = dplyr::lag(cummax(event == 1L), default = FALSE)) %>%
  filter(!after_onset) %>%
  ungroup() %>%
  dplyr::select(-after_onset)

# Establish empirical wave-median ages for plotting/prediction
wave_age_medians <- bd_pp_model %>%
  dplyr::group_by(end_wave) %>%
  dplyr::summarise(age_med = median(age_mid, na.rm = TRUE), .groups = "drop") %>%
  dplyr::arrange(match(end_wave, levels(bd_pp_model$end_wave)))
ages_empirical <- wave_age_medians$age_med %>% as.numeric() %>% round(1)

# --- Helpers ---------------------------------------------------------------
# cluster mapping for display
coerce_cluster <- function(x) dplyr::recode(as.character(x),
  "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
  "C2"="Lower-Risk", "2"="Lower-Risk", "low"="Lower-Risk","lower"="Lower-Risk",
  .default = as.character(x)
)

# wave -> timepoint label
time_map <- c("ses-02A" = "2y", "ses-04A" = "4y", "ses-06A" = "6y")
time_levels <- c("2y","4y","6y")  # enforce order

fmt_mean_sd <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return("-")
  sprintf("%.2f \u00B1 %.2f", mean(x), stats::sd(x))
}
fmt_n <- function(n) ifelse(is.na(n), "-", format(as.integer(n), big.mark = ","))
fmt_n_pct <- function(n, den) {
  out <- ifelse(is.na(den) | den == 0,
                "0 (0.0%)",
                sprintf("%s (%.1f%%)", fmt_n(n), 100 * n / den))
  as.character(out)
}

# --- Guard / inputs --------------------------------------------------------
stopifnot(exists("bd_pp_model"))
pp <- bd_pp_model %>%
  dplyr::mutate(
    cluster_disp = coerce_cluster(cluster),
    time = dplyr::recode(end_wave, !!!time_map),
    time = factor(time, levels = time_levels)
  ) %>%
  dplyr::filter(!is.na(time), cluster_disp %in% c("Lower-Risk","Higher-Risk"))

# ---- DEMOGRAPHICS block (use any_bsd risk set: one row/ID per wave) -------
demo_base <- pp %>% dplyr::filter(outcome == "any_bsd")

# N person-periods & N participants
demo_counts <- demo_base %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_mid),
    .groups = "drop"
  )

# Sex rows (use participants per wave to avoid double-counting)
sex_tab <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, cluster_disp, participant_id, sex2) %>%
  dplyr::count(time, cluster_disp, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts %>% dplyr::select(time, cluster_disp, n_part), by = c("time","cluster_disp")) %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>% # keep two lines like your Table 2
  dplyr::mutate(Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

# Age row
age_row <- demo_counts %>%
  dplyr::transmute(time, cluster_disp, Row = "Age in years, Mean (SD)", val = age_mean_sd)

# N participants & N person-periods rows
n_rows <- demo_counts %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw)
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

# Bind DEMO rows (cluster-specific)
demo_rows_cs <- dplyr::bind_rows(n_rows, age_row, sex_tab) %>%
  dplyr::mutate(Section = "Demographics")

# Add TOTAL columns by time (across clusters)
demo_counts_tot <- demo_base %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_mid),
    .groups = "drop"
  )

# N totals (participants + person-periods)
n_rows_total <- demo_counts_tot %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw),
    cluster_disp = "Total"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

# Age total row
age_row_total <- demo_counts_tot %>%
  dplyr::transmute(
    time, cluster_disp = "Total",
    Row = "Age in years, Mean (SD)",
    val = age_mean_sd
  )

# Sex totals (use participants per wave)
sex_tab_total <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, participant_id, sex2) %>%
  dplyr::count(time, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts_tot %>% dplyr::select(time, n_part), by = "time") %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(
    cluster_disp = "Total",
    Row = paste0("Sex at birth - ", sex2)
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

# Bind DEMO totals
demo_rows_total <- dplyr::bind_rows(n_rows_total, age_row_total, sex_tab_total) %>%
  dplyr::mutate(Section = "Demographics")

# ---- INTERVAL ONSETS block (per outcome risk set) -------------------------
outcome_labels <- c(
  "bipolar_I"   = "Interval onset - BD I, n (%)",
  "bipolar_II"  = "Interval onset - BD II, n (%)",
  "bipolar_NOS" = "Interval onset - BD NOS, n (%)",
  "bd_nos"      = "Interval onset - BD NOS, n (%)",
  "any_bsd"     = "Interval onset - Any BSD, n (%)"
)

events_cs <- pp %>%
  dplyr::filter(outcome %in% names(outcome_labels)) %>%
  dplyr::group_by(outcome, time, cluster_disp) %>%
  dplyr::summarise(
    n_at_risk = dplyr::n(),
    n_events  = sum(event == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(Row = dplyr::recode(outcome, !!!outcome_labels),
                val = fmt_n_pct(n_events, n_at_risk),
                Section = "Interval onsets")

events_total <- pp %>%
  dplyr::filter(outcome %in% names(outcome_labels)) %>%
  dplyr::group_by(outcome, time) %>%
  dplyr::summarise(
    n_at_risk = dplyr::n(),
    n_events  = sum(event == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(Row = dplyr::recode(outcome, !!!outcome_labels),
                val = fmt_n_pct(n_events, n_at_risk),
                cluster_disp = "Total",
                Section = "Interval onsets")

# ---- Assemble long -> wide for gt -----------------------------------------
long_all <- dplyr::bind_rows(
  demo_rows_cs, demo_rows_total,
  events_cs %>% dplyr::select(time, cluster_disp, Row, val, Section),
  events_total %>% dplyr::select(time, cluster_disp, Row, val, Section)
) %>%
  dplyr::mutate(
    # make sure every row exists at every time/cluster (fill with em-dash)
    cluster_disp = factor(cluster_disp, levels = c("Total","Lower-Risk","Higher-Risk")),
    time = factor(time, levels = time_levels)
  )

# Complete grid to avoid missing cells
grid <- tidyr::crossing(
  Row = unique(long_all$Row),
  Section = unique(long_all$Section),
  cluster_disp = levels(long_all$cluster_disp),
  time = levels(long_all$time)
)
long_all <- grid %>% dplyr::left_join(long_all, by = c("Row","Section","cluster_disp","time")) %>%
  dplyr::mutate(val = dplyr::coalesce(val, "\u2014")) # em-dash for empty

# Make wide columns: Cluster::Time
wide <- long_all %>%
  dplyr::mutate(col_key = paste0(cluster_disp, "::", time)) %>%
  dplyr::select(Section, Row, col_key, val) %>%
  tidyr::pivot_wider(names_from = col_key, values_from = val)

# Ensure predictable column order
col_keys <- c(
  paste0("Total::", time_levels),
  paste0("Lower-Risk::", time_levels),
  paste0("Higher-Risk::", time_levels)
)
have <- intersect(col_keys, names(wide))
wide <- wide %>% dplyr::select(Section, Row, dplyr::all_of(have))

# Build GT table with nested spanners
ts1 <- gt::gt(wide, groupname_col = "Section", rowname_col = "Row") |>
  # Column labels show only time; spanners show the cluster
  gt::cols_label(.list = setNames(rep(time_levels, 3), have)) |>
  gt::tab_spanner(label = "Total", columns = dplyr::all_of(paste0("Total::", time_levels))) |>
  gt::tab_spanner(label = "Lower-Risk", columns = dplyr::all_of(paste0("Lower-Risk::", time_levels))) |>
  gt::tab_spanner(label = "Higher-Risk", columns = dplyr::all_of(paste0("Higher-Risk::", time_levels))) |>
  gt::cols_align(align = "center", columns = dplyr::all_of(have)) |>
  gt::tab_caption("**Table S1. Characteristics of Participants in the Onset of Bipolar Disorders by Risk Cluster Analysis**  
Counts are shown per assessment interval (2y, 4y, 6y). Demographics are from the *any BSD* risk set (one person-period per participant per interval). Interval onset rows report events within outcome-specific risk sets (post-censoring), shown as *n (percent)* of person-periods at risk.") |>
  gt::tab_options(table.font.size = gt::px(12)) |>
  gt::fmt_missing(columns = dplyr::everything(), missing_text = "\u2014")

# Save + print
save_gt(ts1, "Table_S1_Onset_Characteristics_by_Cluster")
ts1

```

## Figure 5 and Related Stats: Interval and Cumulative Discrete Time Hazard Model Onset by Risk Cluster Incidence Curves for Bipolar Disorders 

```{r figure 5 stats}

## FIGURE 5: Discrete-time hazards and cumulative incidence by cluster -----

# Outcomes and on-disk models
OUT_FIG <- c("bipolar_I","bipolar_II","bd_nos","any_bsd")
fit_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/main_analysis/1_bd_survival"

safe_read <- function(path) tryCatch(readRDS(path), error = function(e) NULL)

if (!exists("fits_primary") || !is.list(fits_primary)) fits_primary <- list()
needed <- setdiff(OUT_FIG, names(fits_primary))

if (length(needed)) {
  add <- setNames(
    lapply(needed, function(o) safe_read(file.path(fit_dir, paste0("fit_primary_", o, ".rds")))),
    needed
  )
  fits_primary[names(add)] <- add
}

# Quick sanity check (prints which are loaded)
loaded_ok <- names(Filter(Negate(is.null), fits_primary))
message("Loaded fits: ", paste(loaded_ok, collapse = ", "))
if (!all(OUT_FIG %in% loaded_ok)) {
  warning("Missing fits for: ", paste(setdiff(OUT_FIG, loaded_ok), collapse = ", "),
          "\nI can only compute CIs for the ones that loaded.")
}

# --- MVN simulation helper (no refitting) --------------------------------------
# Build reference newdata with factor levels/contrasts matching the fit
make_ref_frame <- function(fit, dat) {
  frm <- fit@frame
  levs <- lapply(frm[, vapply(frm, is.factor, TRUE), drop = FALSE], levels)
  
  ref <- expand.grid(
    end_wave = levels(dat$end_wave),
    cluster  = levels(dat$cluster),
    age_mid_between = 0,
    age_mid_cwc     = 0,
    baseline_status = 0,
    sex         = levels(dat$sex)[1],
    site_factor = levels(dat$site_factor)[1],
    stringsAsFactors = FALSE
  )
  # coerce factor levels to match the fitted model
  for (v in intersect(names(levs), names(ref))) {
    ref[[v]] <- factor(ref[[v]], levels = levs[[v]])
  }
  dplyr::arrange(ref, cluster, end_wave)
}

cumrisk_by_wave_ci_mvn <- function(fit, dat, B = 4000, probs = c(0.025, 0.975)) {
  stopifnot(requireNamespace("lme4", quietly = TRUE))
  ref <- make_ref_frame(fit, dat)
  
  # fixed-only RHS with no random effects and no response
  ff_all <- stats::formula(fit)
  ff_fix <- lme4::nobars(ff_all)
  tt     <- stats::delete.response(stats::terms(ff_fix))
  
  # use the model's contrasts so columns line up
  contr <- attr(fit@frame, "contrasts")
  X     <- stats::model.matrix(tt, ref, contrasts.arg = contr)
  
  beta  <- lme4::fixef(fit)
  V     <- as.matrix(stats::vcov(fit))
  
  # align columns; add any missing columns (rare) as zeros
  miss <- setdiff(names(beta), colnames(X))
  if (length(miss)) X <- cbind(X, matrix(0, nrow(X), length(miss), dimnames = list(NULL, miss)))
  X <- X[, names(beta), drop = FALSE]
  
  # MVN draws of fixed effects
  if (requireNamespace("MASS", quietly = TRUE)) {
    beta_draws <- MASS::mvrnorm(n = B, mu = beta, Sigma = V)
  } else {
    L <- chol(V); Z <- matrix(stats::rnorm(B * length(beta)), nrow = B)
    beta_draws <- sweep(Z %*% t(L), 2, beta, `+`)
  }
  
  eta_draws <- X %*% t(beta_draws)
  p_draws   <- plogis(eta_draws)
  
  ref$end_wave <- factor(ref$end_wave, levels = levels(dat$end_wave))
  ref$cluster  <- factor(ref$cluster,  levels = levels(dat$cluster))
  idx_by_clu   <- split(seq_len(nrow(ref)), ref$cluster)
  
  out <- lapply(names(idx_by_clu), function(cl) {
    R  <- idx_by_clu[[cl]]
    H  <- p_draws[R, , drop = FALSE]
    CR <- apply(H, 2, function(col) 1 - cumprod(1 - col))  # waves x B
    if (is.null(dim(CR))) CR <- matrix(CR, nrow = length(R), ncol = 1)
    
    # point estimate from beta-hat
    cr_hat <- {
      p_hat <- plogis(as.numeric(X[R, , drop = FALSE] %*% beta))
      1 - cumprod(1 - p_hat)
    }
    
    lo <- apply(CR, 1, stats::quantile, probs = probs[1], na.rm = TRUE)
    hi <- apply(CR, 1, stats::quantile, probs = probs[2], na.rm = TRUE)
    
    tibble::tibble(
      end_wave   = ref$end_wave[R],
      cluster    = as.character(ref$cluster[R]),
      cumrisk    = cr_hat,
      cumrisk_lo = lo,
      cumrisk_hi = hi
    )
  }) |> dplyr::bind_rows()
  
  out
}

# Colors (paper-wide)
cluster_cols <- c("Lower-Risk" = "#11A579", "Higher-Risk" = "#7F3C8D")

# Outcome order + pretty labels
OUT_FIG <- c("bipolar_I","bipolar_II","bd_nos","any_bsd")
OUT_LABS <- c(
  bipolar_I = "BD-I",
  bipolar_II = "BD-II",
  bd_nos = "BD-NOS",
  any_bsd = "Any BSD"
)

# Helpers ----------------------------------------------------------------------
wave_levels  <- c("ses-02A","ses-04A","ses-06A")
coerce_cluster <- function(x) dplyr::recode(as.character(x),
                                            "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
                                            "C2"="Lower-Risk","2"="Lower-Risk","low"="Lower-Risk","lower"="Lower-Risk",
                                            .default = as.character(x)
)

ctrl <- glmerControl(optimizer = "bobyqa",
                     optCtrl = list(maxfun = 2e5),
                     check.conv.singular = "ignore")

cum_ci_list <- lapply(OUT_FIG, function(out) {
  fit <- fits_primary[[out]]; if (is.null(fit)) return(NULL)
  dat <- bd_pp_model |>
    dplyr::filter(outcome == out) |>
    droplevels() |>
    dplyr::mutate(
      end_wave = factor(end_wave, levels = wave_levels),
      cluster  = factor(cluster)
    )
  if (!nrow(dat)) return(NULL)
  
  cr <- cumrisk_by_wave_ci_mvn(fit, dat, B = 2000)  # 2k draws is typically plenty/fast
  
  cr |>
    dplyr::mutate(
      outcome      = out,
      model        = "logit",
      end_wave     = factor(end_wave, levels = wave_levels),
      cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk"))
    ) |>
    dplyr::select(outcome, model, end_wave, cluster, cluster_disp, cumrisk, cumrisk_lo, cumrisk_hi)
})
cum_by_wave <- dplyr::bind_rows(purrr::compact(cum_ci_list))

tmp <- dplyr::bind_rows(purrr::compact(cum_ci_list))
stopifnot(is.data.frame(tmp), nrow(tmp) > 0)  # guard: fail early if nothing computed
cum_by_wave <- tmp

# Pretty wave labels + median ages for tick labels
wave_pretty <- c("ses-02A" = "Year-2",
                 "ses-04A" = "Year-4",
                 "ses-06A" = "Year-6")

age_meds_tbl <- bd_pp_model %>%
  dplyr::group_by(end_wave) %>%
  dplyr::summarise(age_med = median(age_mid, na.rm = TRUE), .groups = "drop") %>%
  dplyr::mutate(end_wave = as.character(end_wave))

age_meds_vec <- setNames(age_meds_tbl$age_med, age_meds_tbl$end_wave)

x_lab_vec <- setNames(
  ifelse(is.finite(age_meds_vec[wave_levels]),
         sprintf("%s\nMedian Mid-Interval Age=%.1f", wave_pretty[wave_levels], age_meds_vec[wave_levels]),
         sprintf("%s\nMedian Mid-Interval Age=—",      wave_pretty[wave_levels])),
  wave_levels
)

# --- Observed cumulative incidence (unadjusted) for overlay -------------------
emp_cum_by_wave <- bd_pp_model %>%
  dplyr::filter(outcome %in% OUT_FIG) %>%
  dplyr::mutate(
    cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
    end_wave     = factor(end_wave, levels = wave_levels)
  ) %>%
  # per-interval empirical hazard among those at risk
  dplyr::group_by(outcome, cluster_disp, end_wave) %>%
  dplyr::summarise(h = mean(event == 1L, na.rm = TRUE), .groups = "drop") %>%
  # roll up to cumulative incidence: 1 - Π(1 - h_j)
  dplyr::group_by(outcome, cluster_disp) %>%
  dplyr::arrange(end_wave, .by_group = TRUE) %>%
  dplyr::mutate(cumrisk_obs = 1 - cumprod(1 - pmin(pmax(h, 0), 1))) %>%
  dplyr::ungroup()

# Replace your theme_small() with this:
axes_only_theme <- function(base_size = 8, axis_text = 6.5) {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid = element_blank(),                # no gridlines
      axis.line = element_blank(),
      axis.line.x.bottom = element_line(color = "black"),
      axis.line.y.left   = element_line(color = "black"),
      axis.ticks = element_line(color = "black"),
      axis.ticks.x.top = element_blank(),
      axis.ticks.y.right = element_blank(),
      axis.text = element_text(size = axis_text),
      legend.position = "bottom",
      legend.box = "horizontal"
    )
}

# Helpers to blank axes on interior panels (use at composition time)
strip_x <- theme(axis.title.x = element_blank(),
                 axis.text.x  = element_blank(),
                 axis.ticks.x = element_blank())
strip_y <- theme(axis.title.y = element_blank(),
                 axis.text.y  = element_blank(),
                 axis.ticks.y = element_blank())

# Guard: make empty frames if needed
empty_pred <- tibble(
  outcome=character(), model=character(), pred_mode=character(),
  end_wave=factor(character(), levels = wave_levels),
  cluster=character(), age_years=double(), pred=double(),
  lower=double(), upper=double()
)
empty_cum <- tibble(
  outcome=character(), model=character(), end_wave=factor(character(), levels=wave_levels),
  cluster=character(), cumrisk=double(), cumrisk_lo=double(), cumrisk_hi=double()
)

# Pull predictions (primary link only; wave-aligned for hazards)
pred_aligned <- if (exists("bd_dth_preds")) bd_dth_preds else empty_pred
pred_aligned <- pred_aligned %>%
  dplyr::filter(model == params$link_primary, pred_mode == "aligned",
                outcome %in% OUT_FIG) %>%
  dplyr::mutate(
    end_wave = factor(end_wave, levels = wave_levels),
    cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk"))
  )

# Trigger CI recompute if missing
need_cum_ci <- (nrow(cum_by_wave) == 0) ||
  all(is.na(cum_by_wave$cumrisk_lo) & is.na(cum_by_wave$cumrisk_hi))

if (need_cum_ci) {
  cum_ci_list <- lapply(OUT_FIG, function(out) {
    fit <- try(fits_primary[[out]], silent = TRUE)
    if (inherits(fit, "try-error") || is.null(fit)) return(NULL)
    dat <- bd_pp_model |> dplyr::filter(outcome == out) |> droplevels()
    
    # Use existing helper if it actually returns CIs; else fall back to bootMer
    cr <- if (exists("cumrisk_by_wave_ci")) {
      tmp <- try(cumrisk_by_wave_ci(fit, dat, B = 500), silent = TRUE)
      if (inherits(tmp, "try-error") || !"cumrisk_lo" %in% names(tmp) ||
          all(is.na(tmp$cumrisk_lo))) cumrisk_by_wave_ci_boot(fit, dat, B = 500) else tmp
    } else {
      cumrisk_by_wave_ci_boot(fit, dat, B = 500)
    }
    
    cr |>
      dplyr::mutate(
        outcome     = out,
        model       = params$link_primary,
        end_wave    = factor(end_wave, levels = wave_levels),
        cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
        cumrisk_lo  = as.numeric(cumrisk_lo),
        cumrisk_hi  = as.numeric(cumrisk_hi)
      )
  })
  cum_by_wave <- dplyr::bind_rows(purrr::compact(cum_ci_list))
}

# Robust CI checks (use na.rm=TRUE)
plot_haz_wave <- function(df, out_key) {
  d <- df %>% dplyr::filter(.data$outcome == out_key)
  has_ci <- all(c("lower","upper") %in% names(d)) &&
    any(is.finite(d$lower) & is.finite(d$upper), na.rm = TRUE)
  
  emp <- bd_pp_model %>%
    dplyr::filter(outcome == out_key) %>%
    dplyr::mutate(
      cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
      end_wave = factor(end_wave, levels = wave_levels)
    ) %>%
    dplyr::group_by(end_wave, cluster_disp) %>%
    dplyr::summarise(emp = mean(event == 1L, na.rm = TRUE), .groups = "drop")
  
  ggplot(d, aes(x = end_wave, y = pred, color = cluster_disp, group = cluster_disp)) +
    { if (has_ci) geom_ribbon(aes(ymin = lower, ymax = upper, fill = cluster_disp),
                              alpha = 0.18, color = NA) } +   # << ribbon CI
    geom_line(size = 0.9) +
    geom_point(size = 1.8) +
    geom_point(data = emp, aes(x = end_wave, y = emp, color = cluster_disp),
               shape = 1, size = 1.8, inherit.aes = FALSE) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.01), limits = c(0, NA)) +
    scale_x_discrete(drop = FALSE, labels = x_lab_vec) +
    scale_color_manual(
      values = cluster_cols,
      breaks = names(cluster_cols),
      labels = names(cluster_cols)) +
    scale_fill_manual(values = cluster_cols, guide = "none") +
    guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
    labs(title = paste0("(", LETTERS[match(out_key, OUT_FIG)], ")  ", OUT_LABS[[out_key]], " Interval Hazard"),
         x = "Wave (Interval End)", y = "Predicted Hazard (Per Interval)", color = "Cluster") +
    axes_only_theme()
}

plot_cum_wave <- function(df, out_key) {
  d <- df %>% dplyr::filter(.data$outcome == out_key)
  has_ci <- all(c("cumrisk_lo","cumrisk_hi") %in% names(d)) &&
    any(is.finite(d$cumrisk_lo) & is.finite(d$cumrisk_hi), na.rm = TRUE)
  i <- match(out_key, OUT_FIG)
  panel_letter <- LETTERS[i + 4]
  
  # observed cumulative for this outcome
  emp <- emp_cum_by_wave %>% dplyr::filter(outcome == out_key)
  
  ggplot(d, aes(x = end_wave, y = cumrisk, color = cluster_disp, group = cluster_disp)) +
    { if (has_ci) geom_ribbon(aes(ymin = cumrisk_lo, ymax = cumrisk_hi, fill = cluster_disp),
                              alpha = 0.15, color = NA) } +
    geom_line(size = 0.9) +
    geom_point(size = 1.8) +  # model-based points (solid)
    # --- NEW: observed cumulative incidence (hollow points) ---
    geom_point(data = emp,
               aes(x = end_wave, y = cumrisk_obs, color = cluster_disp),
               shape = 1, size = 1.8, inherit.aes = FALSE) +
    # -----------------------------------------------------------
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.1), limits = c(0, 0.30)) +
    scale_x_discrete(drop = FALSE, labels = x_lab_vec) +
    scale_color_manual(values = cluster_cols, breaks = names(cluster_cols), labels = names(cluster_cols)) +
    scale_fill_manual(values = cluster_cols, guide = "none") +
    labs(title = paste0("(", panel_letter, ")  ", OUT_LABS[[out_key]], " Cumulative Incidence"),
         x = "Wave (Interval End)", y = "Cumulative Risk", color = "Cluster") +
    axes_only_theme()
}

# Build panels
haz_panels <- lapply(OUT_FIG, function(o) plot_haz_wave(pred_aligned, o))
cum_panels <- lapply(OUT_FIG, function(o) plot_cum_wave(cum_by_wave, o))

# Keep legend only on the first hazard panel
haz_panels[2:4] <- lapply(haz_panels[2:4], function(p) p + theme(legend.position = "none"))
# Hide all legends on cumulative panels
cum_panels <- lapply(cum_panels, function(p) p + theme(legend.position = "none"))

# Strip interior axes (2x2 grids for hazards and cumulative)
haz_grid <- (haz_panels[[1]] + strip_x) + (haz_panels[[2]] + strip_x) +
  (haz_panels[[3]])           +  (haz_panels[[4]]) +
  patchwork::plot_layout(ncol = 2)

cum_grid <- (cum_panels[[1]] + strip_x) + (cum_panels[[2]] + strip_x) +
  (cum_panels[[3]])           +  (cum_panels[[4]]) +
  patchwork::plot_layout(ncol = 2)
cum_grid <- cum_grid & theme(legend.position = "none")

# final: collect once here
fig5 <- haz_grid / cum_grid +
  patchwork::plot_layout(heights = c(1, 1), guides = "collect") &
  theme(legend.position = "bottom", legend.justification = "center")
print(fig5)
save_fig(fig5, "Figure_05_DTH_Hazards_and_Cumulative_by_Cluster", width = 9.5, height = 11)


######################## In line stats ##############################
# ---- Setup: assumes fits_primary, bd_pp_model, wave_levels, coerce_cluster exist ----
# Pretty labels (same as you had)
OUT_LABS <- c(bipolar_I="BD I", bipolar_II="BD II", bd_nos="BD NOS", any_bsd="Any BSD")

# ---- Helper: build ref grid + model matrix with model's factor levels/contrasts ----
make_ref_frame <- function(fit, dat) {
  frm <- fit@frame  # model frame used at fit time (has full levels & contrasts)

  # pull levels from the fitted model frame (not the subset 'dat')
  get_levs <- function(var) if (var %in% names(frm) && is.factor(frm[[var]])) levels(frm[[var]]) else NULL

  waves_lev  <- get_levs("end_wave")
  cluster_lev<- get_levs("cluster")
  sex_lev    <- get_levs("sex")
  site_lev   <- get_levs("site_factor")
  base_lev   <- get_levs("baseline_status")

  if (is.null(waves_lev))  stop("Fitted model lacks factor levels for end_wave.")
  if (is.null(cluster_lev)) stop("Fitted model lacks factor levels for cluster.")

  # reference grid: all wave × all cluster, other covariates held at reference
  ref <- expand.grid(
    end_wave        = waves_lev,
    cluster         = cluster_lev,
    age_mid_between = 0,
    age_mid_cwc     = 0,
    baseline_status = if (is.null(base_lev)) 0 else base_lev[1],
    sex             = if (is.null(sex_lev)) NA else sex_lev[1],
    site_factor     = if (is.null(site_lev)) NA else site_lev[1],
    stringsAsFactors = FALSE
  )

  # coerce to factors with the *model's* full levels (so each has >=2 where applicable)
  if (!is.null(sex_lev))  ref$sex         <- factor(ref$sex,         levels = sex_lev)
  if (!is.null(site_lev)) ref$site_factor <- factor(ref$site_factor, levels = site_lev)
  if (!is.null(base_lev)) ref$baseline_status <- factor(ref$baseline_status, levels = base_lev)

  ref$end_wave <- factor(ref$end_wave, levels = waves_lev)
  ref$cluster  <- factor(ref$cluster,  levels = cluster_lev)

  # model terms/contrasts (drop contrasts for any 1-level factors to avoid the error)
  ff_fix <- lme4::nobars(stats::formula(fit))
  tt     <- stats::delete.response(stats::terms(ff_fix))

  contr_all <- attr(frm, "contrasts")
  if (!is.null(contr_all)) {
    multi_lvl <- names(frm)[sapply(frm, function(x) is.factor(x) && nlevels(x) > 1)]
    contr_all <- contr_all[names(contr_all) %in% multi_lvl]
  }

  X <- stats::model.matrix(tt, ref, contrasts.arg = contr_all)

  beta <- lme4::fixef(fit)
  V    <- as.matrix(stats::vcov(fit))

  # align columns to the order of beta (pad zeros for any columns not in X)
  miss <- setdiff(names(beta), colnames(X))
  if (length(miss)) {
    X <- cbind(X, matrix(0, nrow(X), length(miss), dimnames = list(NULL, miss)))
  }
  X <- X[, names(beta), drop = FALSE]

  list(ref = ref, X = X, beta = beta, V = V, waves = waves_lev, clus = cluster_lev)
}

# ---- Hazards -> cumulative risk up to wave index k (stable) ----
cumrisk_from_haz <- function(h, k) {
  h <- pmin(pmax(h, 1e-8), 1 - 1e-8)
  1 - exp(sum(log1p(-h[seq_len(k)])))
}

# ---- Wald CI helper (delta method) ----
wald_ci <- function(theta_hat, grad, V, level = 0.95, log_scale = FALSE) {
  # small ridge in case of near-singular V
  if (any(!is.finite(V))) V[!is.finite(V)] <- 0
  V <- V + diag(1e-10, nrow(V))
  se <- sqrt(drop(t(grad) %*% V %*% grad))
  z  <- qnorm((1 + level)/2)
  if (log_scale) {
    lo <- theta_hat * exp(-z * se)
    hi <- theta_hat * exp(+z * se)
  } else {
    lo <- theta_hat - z * se
    hi <- theta_hat + z * se
  }
  list(se = se, lo = lo, hi = hi, z = theta_hat / se, p = 2 * pnorm(-abs(theta_hat / se)))
}

# ---- Year-6 RD/RR with delta-method CIs/p-values (no refits) ----
year6_rd_rr_delta <- function(fit, dat, wave_key = "ses-06A") {
  obj <- make_ref_frame(fit, dat)
  ref <- obj$ref; X <- obj$X; beta <- obj$beta; V <- obj$V
  waves <- obj$waves

  if (!wave_key %in% waves) wave_key <- tail(waves, 1)
  k_idx <- match(wave_key, waves)

  # map C1/C2 -> Higher/Lower using your coerce_cluster()
  cl_levels <- levels(ref$cluster)
  disp <- coerce_cluster(cl_levels)
  role <- setNames(rep(NA_character_, length(cl_levels)), cl_levels)
  role[disp == "Higher-Risk"] <- "HR"
  role[disp == "Lower-Risk"]  <- "LR"
  if (anyNA(role)) {
    # fallback: choose HR as the one with larger point CR
    point_cr <- sapply(cl_levels, function(cl) {
      rows <- which(ref$cluster == cl)
      h <- plogis(as.numeric(X[rows, , drop = FALSE] %*% beta))
      cumrisk_from_haz(h, k_idx)
    })
    role[] <- "LR"; role[names(which.max(point_cr))] <- "HR"
  }

  make_f <- function(cl) {
    rows <- which(ref$cluster == cl)
    function(b) {
      h <- plogis(as.numeric(X[rows, , drop = FALSE] %*% b))
      cumrisk_from_haz(h, k_idx)
    }
  }
  f_HR <- make_f(names(role)[role == "HR"])
  f_LR <- make_f(names(role)[role == "LR"])

  CR_HR <- f_HR(beta); CR_LR <- f_LR(beta)
  CR_HR <- pmin(pmax(CR_HR, 1e-8), 1 - 1e-8)
  CR_LR <- pmin(pmax(CR_LR, 1e-8), 1 - 1e-8)
  RD    <- CR_HR - CR_LR
  RR    <- CR_HR / CR_LR

  g_HR <- numDeriv::grad(f_HR, beta)
  g_LR <- numDeriv::grad(f_LR, beta)

  # RD
  g_RD  <- g_HR - g_LR
  ci_RD <- wald_ci(RD, g_RD, V, level = 0.95, log_scale = FALSE)

  # log(RR)
  g_logRR  <- g_HR / CR_HR - g_LR / CR_LR
  se_logRR <- sqrt(drop(t(g_logRR) %*% V %*% g_logRR))
  z <- qnorm(0.975)
  RR_lo <- RR * exp(-z * se_logRR)
  RR_hi <- RR * exp(+z * se_logRR)
  p_logRR <- 2 * pnorm(-abs(log(RR) / se_logRR))

  list(
    wave = wave_key,
    CR_HR = CR_HR, CR_LR = CR_LR,
    RD = RD, RD_lo = ci_RD$lo, RD_hi = ci_RD$hi, RD_p = ci_RD$p,
    RR = RR, RR_lo = RR_lo, RR_hi = RR_hi, RR_p = p_logRR
  )
}

# ---- Run for all outcomes; print nice lines -----------------------------------
cum6 <- lapply(OUT_FIG, function(out) {
  fit <- fits_primary[[out]]; if (is.null(fit)) return(NULL)
  dat <- bd_pp_model %>%
    dplyr::filter(outcome == out) %>%
    dplyr::mutate(
      # dat is only used to select rows; factor levels now come from fit@frame
      end_wave = factor(end_wave),
      cluster  = factor(cluster),
      sex         = factor(sex),
      site_factor = factor(site_factor)
    )

  res <- year6_rd_rr_delta(fit, dat, wave_key = "ses-06A")
  tibble::tibble(
    outcome = out,
    out_lab = OUT_LABS[out],
    wave    = res$wave,
    HR      = res$CR_HR, LR = res$CR_LR,
    RD      = res$RD, RD_lo = res$RD_lo, RD_hi = res$RD_hi, RD_p = res$RD_p,
    RR      = res$RR, RR_lo = res$RR_lo, RR_hi = res$RR_hi, RR_p = res$RR_p
  )
}) %>% dplyr::bind_rows()

# Human-readable lines
cum6_lines <- cum6 %>%
  mutate(
    line = glue::glue(
      "{out_lab} Year-6 cumulative risk: ",
      "{scales::percent(HR, 0.1)} (HR) vs {scales::percent(LR, 0.1)} (LR); ",
      "RD = {scales::percent(RD, 0.1)} [{scales::percent(RD_lo, 0.1)}, {scales::percent(RD_hi, 0.1)}], p = {sprintf('%.3f', RD_p)}; ",
      "RR = {sprintf('%.2f', RR)} [{sprintf('%.2f', RR_lo)}, {sprintf('%.2f', RR_hi)}], p = {sprintf('%.3f', RR_p)}"
    )
  ) %>% pull(line)

cat(paste("•", cum6_lines), sep = "\n")

# ---- Age terms: ensure p-values even if not in table --------------------------
age_terms <- c("age_mid_cwc","age_mid_between")
source_tbl <- if (exists("wald_all") && is.data.frame(wald_all)) wald_all else bd_dth_sum
out_map <- c(bipolar_I="BD I", bipolar_II="BD II", bd_nos="BD NOS", any_bsd="Any BSD",
             BDI="BD I", BDII="BD II", BDNOS="BD NOS", BSD="Any BSD")

age_effects <- source_tbl %>%
  filter(term %in% age_terms) %>%
  mutate(
    OR  = if ("OR" %in% names(.)) OR else exp(estimate),
    pv  = dplyr::case_when(!is.na(p.value) ~ p.value,
                           is.finite(estimate) & is.finite(se) ~ 2*pnorm(-abs(estimate/se)),
                           TRUE ~ NA_real_),
    out_lab = out_map[as.character(outcome)],
    lbl = recode(term, age_mid_cwc="within-person age", age_mid_between="between-person age")
  )

age_lines <- age_effects %>%
  transmute(line = glue::glue("{out_lab}: {lbl} OR = {sprintf('%.2f', OR)} (p = {ifelse(is.na(pv), '-', sprintf('%.3f', pv))}).")) %>%
  pull(line)

cat(paste("•", age_lines), sep = "\n")

```

## Table S2: Characteristics of Participants in the Prevalence of Bipolar Disorders Over Time by Risk Cluster Analysis

```{r table s2}

## Table S2 — Prevalence (GEE) analysis characteristics ------------------------

# Prepare the BD panel dataset
bd_panel <- bd_panel %>%
  mutate(
    participant_id = as.character(participant_id),
    family_id = factor(as.character(family_id)),
    site_factor = factor(site_factor),
    cluster = factor(cluster),
    wave = factor(wave),
    outcome = factor(outcome),
    sex = factor(sex))

# Require response to exist and be 0/1
bd_panel <- bd_panel %>% mutate("status" := as.integer(.data[["status"]]))

# Model-ready filter (post-QC)
bd_panel_model <- bd_panel %>%
  filter(.data[["status"]] %in% c(0L,1L)) %>%
  filter(!is.na(cluster),
    !is.na(sex),
    !is.na(site_factor),
    !is.na(family_id),
    !is.na(wave)) %>%
  
  # Require age fields present for prediction/interpretation
  filter(!is.na(age_wave), !is.na(age_wave_cwc), !is.na(age_wave_between))

# Reference levels (consistent display)
bd_panel_model <- bd_panel_model %>%
  mutate(
    cluster = forcats::fct_relevel(cluster, "C2"),
    wave = forcats::fct_relevel(wave, "ses-02A", "ses-04A", "ses-06A"),
    sex = forcats::fct_relevel(sex, "Female"),
    site_factor = forcats::fct_relevel(site_factor, "site01")
  )

# Guards -----------------------------------------------------------------------
stopifnot(exists("bd_panel_model"), is.data.frame(bd_panel_model))

# Response var (default to "status" if params$response_var not present)
status_var <- if (exists("params") && !is.null(params$response_var)) params$response_var else "status"
stopifnot(status_var %in% names(bd_panel_model))
# Force to {0,1,NA}
bd_panel_model[[status_var]] <- as.integer(bd_panel_model[[status_var]])
bd_panel_model[[status_var]][!bd_panel_model[[status_var]] %in% c(0L,1L)] <- NA_integer_

# Display helpers --------------------------------------------------------------
coerce_cluster <- function(x) dplyr::recode(as.character(x),
  "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
  "C2"="Lower-Risk", "2"="Lower-Risk", "low"="Lower-Risk","lower"="Lower-Risk",
  .default = as.character(x)
)

# Wave → time labels (2y/4y/6y), keep your order
time_map <- c("ses-02A" = "2y", "ses-04A" = "4y", "ses-06A" = "6y")
time_levels <- c("2y","4y","6y")

fmt_mean_sd <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return("\u2014")
  sprintf("%.2f \u00B1 %.2f", mean(x), stats::sd(x))
}
fmt_n <- function(n) ifelse(is.na(n), "\u2014", format(as.integer(n), big.mark = ","))
fmt_n_pct <- function(n, den) {
  out <- ifelse(is.na(den) | den == 0,
                "0 (0.0%)",
                sprintf("%s (%.1f%%)", fmt_n(n), 100 * n / den))
  as.character(out)
}

# Working frame (panel) --------------------------------------------------------
# Keep only rows with required displays; demographics drawn from any_bsd to avoid duplication across outcomes
panel <- bd_panel_model %>%
  dplyr::mutate(
    cluster_disp = coerce_cluster(cluster),
    time = dplyr::recode(as.character(wave), !!!time_map),
    time = factor(time, levels = time_levels),
    sex = as.character(sex)
  ) %>%
  dplyr::filter(!is.na(time), cluster_disp %in% c("Lower-Risk","Higher-Risk"))

# DEMOGRAPHICS (per time x cluster) -------------------------------------------
demo_base <- panel %>% dplyr::filter(outcome == "any_bsd")

# N person-periods, N participants, Age
demo_counts <- demo_base %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_wave),
    .groups = "drop"
  )

age_row <- demo_counts %>%
  dplyr::transmute(time, cluster_disp, Row = "Age in years, Mean (SD)", val = age_mean_sd)

n_rows <- demo_counts %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw)
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

# Sex (participants per wave; Male/Female lines like Table S1)
sex_tab <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, cluster_disp, participant_id, sex2) %>%
  dplyr::count(time, cluster_disp, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts %>% dplyr::select(time, cluster_disp, n_part), by = c("time","cluster_disp")) %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_cs <- dplyr::bind_rows(n_rows, age_row, sex_tab) %>%
  dplyr::mutate(Section = "Demographics")

# Totals across clusters (per time)
demo_counts_tot <- demo_base %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_wave),
    .groups = "drop"
  )

n_rows_total <- demo_counts_tot %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw),
    cluster_disp = "Total"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

age_row_total <- demo_counts_tot %>%
  dplyr::transmute(time, cluster_disp = "Total", Row = "Age in years, Mean (SD)", val = age_mean_sd)

sex_tab_total <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, participant_id, sex2) %>%
  dplyr::count(time, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts_tot %>% dplyr::select(time, n_part), by = "time") %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(cluster_disp = "Total", Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_total <- dplyr::bind_rows(n_rows_total, age_row_total, sex_tab_total) %>%
  dplyr::mutate(Section = "Demographics")

# OCCURRENCE rows (prevalence within wave) --------------------------------------
occ_labels <- c(
  "bipolar_I"  = "Occurrence - BD I, n (%)",
  "bipolar_II" = "Occurrence - BD II, n (%)",
  "bd_nos"     = "Occurrence - BD NOS, n (%)",
  "any_bsd"    = "Occurrence - Any BSD, n (%)"
)

# Cluster-specific
occ_cs <- panel %>%
  dplyr::filter(outcome %in% names(occ_labels)) %>%
  dplyr::group_by(outcome, time, cluster_disp) %>%
  dplyr::summarise(
    n_obs   = sum(!is.na(.data[[status_var]])),
    n_cases = sum(.data[[status_var]] == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!occ_labels),
    val = fmt_n_pct(n_cases, n_obs),
    Section = "Occurrence (wave prevalence)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

# Totals across clusters
occ_total <- panel %>%
  dplyr::filter(outcome %in% names(occ_labels)) %>%
  dplyr::group_by(outcome, time) %>%
  dplyr::summarise(
    n_obs   = sum(!is.na(.data[[status_var]])),
    n_cases = sum(.data[[status_var]] == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!occ_labels),
    val = fmt_n_pct(n_cases, n_obs),
    cluster_disp = "Total",
    Section = "Occurrence (wave prevalence)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

# Assemble, complete grid, go wide --------------------------------------------
long_all <- dplyr::bind_rows(
  demo_rows_cs, demo_rows_total,
  occ_cs, occ_total
) %>%
  dplyr::mutate(
    cluster_disp = factor(cluster_disp, levels = c("Total","Lower-Risk","Higher-Risk")),
    time = factor(time, levels = time_levels)
  )

grid <- tidyr::crossing(
  Row = unique(long_all$Row),
  Section = unique(long_all$Section),
  cluster_disp = levels(long_all$cluster_disp),
  time = levels(long_all$time)
)
long_all <- grid %>%
  dplyr::left_join(long_all, by = c("Row","Section","cluster_disp","time")) %>%
  dplyr::mutate(val = dplyr::coalesce(val, "\u2014"))

wide <- long_all %>%
  dplyr::mutate(col_key = paste0(cluster_disp, "::", time)) %>%
  dplyr::select(Section, Row, col_key, val) %>%
  tidyr::pivot_wider(names_from = col_key, values_from = val)

col_keys <- c(
  paste0("Total::", time_levels),
  paste0("Lower-Risk::", time_levels),
  paste0("Higher-Risk::", time_levels)
)
have <- intersect(col_keys, names(wide))
wide <- wide %>% dplyr::select(Section, Row, dplyr::all_of(have))

# Build GT table ---------------------------------------------------------------
tS2 <- gt::gt(wide, groupname_col = "Section", rowname_col = "Row") |>
  gt::cols_label(.list = setNames(rep(time_levels, 3), have)) |>
  gt::tab_spanner(label = "Total",      columns = dplyr::all_of(paste0("Total::", time_levels))) |>
  gt::tab_spanner(label = "Lower-Risk", columns = dplyr::all_of(paste0("Lower-Risk::", time_levels))) |>
  gt::tab_spanner(label = "Higher-Risk",columns = dplyr::all_of(paste0("Higher-Risk::", time_levels))) |>
  gt::cols_align(align = "center", columns = dplyr::all_of(have)) |>
  gt::tab_caption("**Table S2. Characteristics of Participants in the Prevalence of Bipolar Disorders Over Time by Risk Cluster (GEE Analysis)**
Counts are shown per assessment wave (2y, 4y, 6y). Demographics are derived from the *Any BSD* panel at each wave (one row per participant per wave). Occurrence rows report wave prevalence (status==1) within outcome-specific panels, shown as *n (percent)* of observed person-periods (denominator excludes missing).") |>
  gt::tab_options(table.font.size = gt::px(12)) |>
  gt::fmt_missing(columns = dplyr::everything(), missing_text = "\u2014")

# Save + print (fallback if save_gt not available)
if (exists("save_gt")) {
  save_gt(tS2, "Table_S2_Prevalence_Characteristics_by_Cluster")
} else {
  out_file <- file.path(getwd(), "Table_S2_Prevalence_Characteristics_by_Cluster.html")
  gt::gtsave(tS2, out_file)
  message("Saved: ", out_file)
}
tS2

```

## Figure 6: Bipolar Disorder Odds by Risk Cluster Over Time stats

```{r figure 6 stats}

# ================= Figure 6: Bipolar Disorder Odds by Risk Cluster Over Time =================
# Requires:
#   - bd_panel_model (from Table S2 prep; used only to grab wave medians for labels)
#   - Saved geeglm objects with the cluster x wave interaction, paths like:
#       ".../2_bd_mixed_logit/rds/<outcome>_GEE_EXC_INT.rds"
#   - Outcomes: bipolar_I, bipolar_II, bd_nos, any_bsd
# Produces:
#   - tibble 'gee_pairs' with OR/CI/p per outcome x wave
#   - Console one-liners for Results text

# ---- Config ----
out_labs <- c(bipolar_I="BD I", bipolar_II="BD II", bd_nos="BD NOS", any_bsd="Any BSD")
wave_pretty <- c("ses-02A"="Year-2", "ses-04A"="Year-4", "ses-06A"="Year-6")

fit_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/main_analysis/2_bd_mixed_logit/rds"
fit_paths <- c(
  bipolar_I  = file.path(fit_dir, "bipolar_I_GEE_EXC_INT.rds"),
  bipolar_II = file.path(fit_dir, "bipolar_II_GEE_EXC_INT.rds"),
  bd_nos     = file.path(fit_dir, "bd_nos_GEE_EXC_INT.rds"),
  any_bsd    = file.path(fit_dir, "any_bsd_GEE_EXC_INT.rds")
)

safe_read <- function(p) tryCatch(readRDS(p), error = function(e) NULL)

# Wave medians for age (for labels); fall back to NA if bd_panel_model absent
age_meds <- try({
  bd_panel_model %>%
    dplyr::group_by(wave) %>%
    dplyr::summarise(age_med = median(age_wave, na.rm = TRUE), .groups="drop") %>%
    dplyr::transmute(wave = as.character(wave), lab = sprintf("%s (median age %.1f)",
                                                              dplyr::recode(wave, !!!wave_pretty), age_med))
}, silent = TRUE)
age_meds <- if (inherits(age_meds, "try-error")) tibble::tibble(wave = names(wave_pretty), lab = wave_pretty[names(wave_pretty)]) else age_meds

# ---------- NEW: emmeans-based per-wave C1 vs C2 OR (no refit) -----------------
em_or_by_wave <- function(fit) {
  # Use robust vcov from the model (vcov.geeglm is robust by default)
  V <- try(vcov(fit), silent = TRUE)
  emm <- emmeans::emmeans(fit, ~ cluster | wave, type = "link", vcov. = if (!inherits(V, "try-error")) V else NULL)
  
  # Force contrast to be C1 - C2 (so OR = odds_C1 / odds_C2) regardless of reference
  lev <- levels(emm@grid$cluster)
  if (!all(c("C1","C2") %in% lev)) stop("Cluster levels not found in fit: ", paste(lev, collapse=", "))
  
  w <- setNames(numeric(length(lev)), lev); w["C1"] <- 1; w["C2"] <- -1
  cmp <- emmeans::contrast(emm, method = list("C1 - C2" = w))
  sm  <- summary(cmp, infer = TRUE)  # on link (logit) scale
  
  tibble::tibble(
    wave   = as.character(sm$wave),
    OR     = exp(sm$estimate),
    CI_low = exp(sm$lower.CL),
    CI_high= exp(sm$upper.CL),
    p      = sm$p.value
  )
}

# --------- Gather per-wave ORs for all outcomes (using saved INT models) -------
gee_pairs <- purrr::imap_dfr(fit_paths, function(fp, oc) {
  fit <- safe_read(fp)
  if (is.null(fit)) return(NULL)
  em_or_by_wave(fit) %>%
    dplyr::mutate(
      outcome = oc,
      out_lab = out_labs[oc],
      wave_pretty = dplyr::recode(wave, !!!wave_pretty)
    ) %>%
    dplyr::left_join(age_meds, by = c("wave" = "wave")) %>%
    dplyr::mutate(wave_lab = ifelse(!is.na(lab), lab, wave_pretty))
})

if (!nrow(gee_pairs)) stop("Could not load any *_GEE_EXC_INT.rds fits or compute emmeans contrasts.")

# Nice inline lines for Results text -------------------------------------------
fmt_p <- function(p) ifelse(is.na(p), "-", ifelse(p < .001, "<.001", sprintf("%.3f", p)))
fmt_ci <- function(lo, hi) sprintf("%s–%s", sprintf("%.2f", lo), sprintf("%.2f", hi))
inline_lines <- gee_pairs %>%
  dplyr::mutate(line = glue("{out_lab} {wave_pretty}: OR={sprintf('%.2f', OR)}, 95% CI {fmt_ci(CI_low, CI_high)}, p={fmt_p(p)}")) %>%
  dplyr::arrange(factor(out_lab, levels = out_labs), factor(wave, levels = names(wave_pretty))) %>%
  dplyr::pull(line)

cat("Figure 6 in-line stats (Higher- vs Lower-Risk, emmeans, per wave):\n",
    paste0(" • ", inline_lines, collapse = "\n"), "\n\n")

# ---- JAMA-style panel forest (linear scale, common axis) ----------------------
# KEEPING YOUR EXISTING PLOT AS-IS BELOW

# 1) Ordering helpers (unchanged)
wave_order <- c("Year-2","Year-4","Year-6")
out_order  <- unname(c("BD I","BD II","BD NOS","Any BSD"))

# 2) Build tidy plotting frame
gee_pairs_plot <- gee_pairs %>%
  dplyr::mutate(
    out_lab     = factor(out_lab,     levels = out_order),
    wave_pretty = factor(wave_pretty, levels = wave_order)
  )

str(gee_pairs_plot)

# 3) Strip labels: "Year-X\n(median age Y.Y)"
age_meds_num <- try({
  bd_panel_model %>%
    dplyr::group_by(wave) %>%
    dplyr::summarise(age_med = median(age_wave, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(wave_pretty = dplyr::recode(as.character(wave),
                                              "ses-02A"="Year-2","ses-04A"="Year-4","ses-06A"="Year-6")) %>%
    dplyr::select(wave_pretty, age_med)
}, silent = TRUE)
if (inherits(age_meds_num, "try-error")) {
  age_meds_num <- tibble::tibble(wave_pretty = wave_order, age_med = NA_real_)
}
wave_strip_map <- setNames(
  sprintf("%s\n(median age %s)",
          wave_order,
          ifelse(is.na(age_meds_num$age_med), "\u2014", sprintf("%.1f", age_meds_num$age_med))),
  wave_order
)
str(wave_strip_map)

# 4) Common x-axis
x_min <- 0; x_max <- 15; x_brk <- c(0, 5, 10, 15)

# --- Visual knobs (unchanged) --------------------------------------------------
ci_linewidth   <- 0.3
cap_linewidth  <- 0.30
cap_y          <- 1e-7
dot_size       <- 1.5
dot_color      <- "#7F3C8D"
arrow_len_mm   <- 1
col_spacing_pt <- 20
tick_len_pt    <- 3
tick_color     <- "grey35"
row_spacing_pt <- 0.3

base_size         <- 10
title_size        <- 10
strip_size        <- 9
axis_title_x_size <- 9
axis_text_x_size  <- 7.5

# --- Prep plotting frame with truncation flags ---------------------------------
plot_df <- gee_pairs_plot %>%
  dplyr::mutate(
    x_low_plot   = pmax(CI_low,  x_min),
    x_high_plot  = pmin(CI_high, x_max),
    trunc_right  = CI_high > x_max + 1e-10,
    trunc_left   = CI_low  < x_min - 1e-10,
    x_or_plot    = pmin(pmax(OR, x_min), x_max)
  )
seg_ok    <- dplyr::filter(plot_df, !trunc_right & !trunc_left)
seg_right <- dplyr::filter(plot_df,  trunc_right & !trunc_left)
seg_left  <- dplyr::filter(plot_df,  trunc_left  & !trunc_right)

# ---- Theme helper (unchanged) -------------------------------------------------
jamafy_linear <- function(base_size = 12,
                          col_spacing_pt = 12,
                          row_spacing_pt = 3,
                          title_size = 13,
                          strip_size = 11,
                          axis_title_x_size = 11,
                          axis_text_x_size  = 9,
                          tick_len_pt = 3,
                          tick_color  = "grey35") {
  ggplot2::theme_minimal(base_size = base_size) +
    ggplot2::theme(
      panel.grid.major = ggplot2::element_blank(),
      panel.grid.minor = ggplot2::element_blank(),
      axis.text.x       = ggplot2::element_text(size = axis_text_x_size),
      axis.title.x      = ggplot2::element_text(size = axis_title_x_size, margin = ggplot2::margin(t = 6)),
      axis.ticks.x      = ggplot2::element_line(color = tick_color, linewidth = 0.3),
      axis.ticks.length = grid::unit(tick_len_pt, "pt"),
      axis.line.x       = ggplot2::element_blank(),
      axis.title.y      = ggplot2::element_blank(),
      axis.text.y       = ggplot2::element_blank(),
      axis.ticks.y      = ggplot2::element_blank(),
      strip.placement   = "outside",
      strip.text.x      = ggplot2::element_text(size = strip_size, face = "bold",
                                                lineheight = 1.05, margin = ggplot2::margin(b = 2)),
      strip.text.y.left = ggplot2::element_text(size = strip_size, face = "bold", angle = 0,
                                                margin = ggplot2::margin(r = 6)),
      strip.background  = ggplot2::element_blank(),
      panel.spacing.x   = grid::unit(col_spacing_pt, "pt"),
      panel.spacing.y   = grid::unit(row_spacing_pt, "pt"),
      plot.title        = ggplot2::element_text(size = title_size, face = "bold",
                                                hjust = 0, margin = ggplot2::margin(b = 6)),
      legend.position   = "none"
    )
}

# --- Plot (identical aesthetics) ----------------------------------------------
g6 <- ggplot(plot_df, aes(y = 0)) +
  geom_vline(xintercept = 1.0, linetype = 2, linewidth = 0.4, color = "grey40") +
  geom_segment(data = seg_ok,
               aes(x = x_low_plot, xend = x_high_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black") +
  geom_segment(data = seg_right,
               aes(x = x_low_plot, xend = x_high_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black",
               arrow = grid::arrow(type = "closed", length = grid::unit(arrow_len_mm, "mm"))) +
  geom_segment(data = seg_left,
               aes(x = x_high_plot, xend = x_low_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black",
               arrow = grid::arrow(type = "closed", length = grid::unit(arrow_len_mm, "mm"))) +
  geom_segment(data = dplyr::filter(plot_df, !trunc_left),
               aes(x = x_low_plot,  xend = x_low_plot,  y = -cap_y, yend =  cap_y),
               linewidth = cap_linewidth, color = "black") +
  geom_segment(data = dplyr::filter(plot_df, !trunc_right),
               aes(x = x_high_plot, xend = x_high_plot, y = -cap_y, yend =  cap_y),
               linewidth = cap_linewidth, color = "black") +
  geom_point(aes(x = x_or_plot), size = dot_size, color = dot_color) +
  scale_x_continuous(limits = c(x_min, x_max), breaks = x_brk,
                     labels = scales::number_format(accuracy = 0.1, trim = TRUE)) +
  scale_y_continuous(NULL, breaks = NULL, limits = c(-0.05, 0.05), expand = expansion(mult = 0)) +
  facet_grid(rows = vars(out_lab),
             cols = vars(wave_pretty),
             switch = "y",
             labeller = labeller(wave_pretty = wave_strip_map)) +
  labs(x = "Odds Ratio") +
  jamafy_linear(col_spacing_pt = col_spacing_pt)

# Apply theme with your knobs
g6 <- g6 + jamafy_linear(
  base_size         = base_size,
  col_spacing_pt    = col_spacing_pt,
  row_spacing_pt    = row_spacing_pt,
  title_size        = title_size,
  strip_size        = strip_size,
  axis_title_x_size = axis_title_x_size,
  axis_text_x_size  = axis_text_x_size,
  tick_len_pt       = tick_len_pt,
  tick_color        = tick_color
)

print(g6)

# ---- Save ---------------------------------------------------------------------
out_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/figures"
out_pdf <- file.path(out_dir, "Figure_06_GEE_OR_by_Cluster.pdf")
out_png <- file.path(out_dir, "Figure_06_GEE_OR_by_Cluster.png")
ggsave(out_pdf, g6, width = 4.5, height = 4, device = cairo_pdf)
ggsave(out_png, g6, width = 4.5, height = 4, dpi = 720)
message("Saved Figure 6 to:\n  ", out_pdf, "\n  ", out_png)

```

## Table S3: Characteristics of Participants in the Nested Onset of Suicidality Within Ever-BD by Risk Cluster Analysis

```{r table s3}

## Table S3 - Nested suicidality onset (ever-BD) characteristics -----------------

su_pp <- nested_pp %>%
  mutate(
    participant_id = factor(as.character(participant_id)),
    family_id = factor(as.character(family_id)),
    site_factor = factor(site_factor),
    cluster = factor(cluster),
    start_wave = factor(start_wave),
    end_wave = factor(end_wave),
    outcome = factor(outcome),
    sex = factor(sex)
  )

SUIC_OUTCOMES <- c("si_passive","si_active","sa","nssi")
su_pp <- su_pp %>% filter(outcome %in% SUIC_OUTCOMES)

su_pp_model <- su_pp %>%
  filter(event %in% c(0L,1L)) %>%
  filter(!is.na(cluster), !is.na(sex), !is.na(site_factor), !is.na(family_id), !is.na(participant_id)) %>%
  filter(!is.na(age_mid), !is.na(age_start), !is.na(age_end)) %>%
  filter(!is.na(bd_any_start))

# References (consistent display)
su_pp_model <- su_pp_model %>%
  mutate(
    cluster = forcats::fct_relevel(cluster, "C2"),
    end_wave = forcats::fct_relevel(end_wave, "ses-02A", "ses-04A", "ses-06A"),
    sex = forcats::fct_relevel(sex, "Female"),
    site_factor = forcats::fct_relevel(site_factor, levels(site_factor)[1])
  )

# First-onset risk set per suicidality outcome: exclude baseline-positive for that outcome
su_baseline_ids <- su_pp_model %>%
  group_by(participant_id, outcome) %>%
  summarise(
    all_na = all(is.na(baseline_status)),
    baseline_outcome = if_else(all_na, NA_integer_, as.integer(any(baseline_status == 1L, na.rm = TRUE))),
    .groups = "drop"
  )

su_pp_model <- su_pp_model %>%
  left_join(su_baseline_ids, by = c("participant_id","outcome"))

# Censor at the first onset (per outcome x participant) ; keeps all rows up to and including first event==1L; drops rows strictly after it. 
su_pp_model <- su_pp_model %>%
  arrange(
    outcome, participant_id,
    if ("interval_index" %in% names(.)) interval_index else as.integer(end_wave)) %>% 
  group_by(outcome, participant_id) %>%
  mutate(
    first_onset_row = match(TRUE, event == 1L),
    row_id = dplyr::row_number()) %>% 
  filter(is.na(first_onset_row) | row_id <= first_onset_row) %>%
  ungroup() %>%
  dplyr::select(-first_onset_row, -row_id)

# If the model-ready nested dataset isn't present, build it from `nested_pp`
if (!exists("su_pp_model")) {
  stopifnot(exists("nested_pp"))
  su_pp_model <- nested_pp %>%
    dplyr::mutate(
      participant_id = factor(as.character(participant_id)),
      family_id      = factor(as.character(family_id)),
      site_factor    = factor(site_factor),
      cluster        = factor(cluster),
      start_wave     = factor(start_wave),
      end_wave       = factor(end_wave, levels = c("ses-02A","ses-04A","ses-06A")),
      outcome        = factor(outcome, levels = c("si_passive","si_active","sa","nssi")),
      sex            = factor(sex)
    ) %>%
    # model-ready filters (mirror your pipeline)
    dplyr::filter(event %in% c(0L,1L)) %>%
    dplyr::filter(!is.na(cluster), !is.na(sex), !is.na(site_factor),
                  !is.na(family_id), !is.na(participant_id)) %>%
    dplyr::filter(!is.na(age_mid), !is.na(age_start), !is.na(age_end)) %>%
    # keep only rows where we know BD status at start (as in your code)
    dplyr::filter(!is.na(bd_any_start)) %>%
    # only ever-BD rows (nested analysis)
    dplyr::filter(isTRUE(ever_bd) | ever_bd) %>%
    # interval length (guards)
    dplyr::mutate(
      dt_years = pmax(age_end - age_start, 1/12),
      log_dt   = log(dt_years)
    ) %>%
    dplyr::filter(is.finite(dt_years), is.finite(log_dt)) %>%
    # references (consistent display)
    dplyr::mutate(
      cluster    = forcats::fct_relevel(cluster, "C2"),
      end_wave   = forcats::fct_relevel(end_wave, "ses-02A","ses-04A","ses-06A"),
      sex        = forcats::fct_relevel(sex, "Female"),
      site_factor= forcats::fct_relevel(site_factor, levels(site_factor)[1])
    ) %>%
    # baseline-negative for THIS suicidality outcome + censor at first onset
    dplyr::group_by(participant_id, outcome) %>%
    dplyr::mutate(
      baseline_outcome = {
        all_na <- all(is.na(baseline_status))
        if (all_na) NA_integer_ else as.integer(any(baseline_status == 1L, na.rm = TRUE))
      }
    ) %>% dplyr::ungroup() %>%
    dplyr::filter(baseline_outcome == 0L) %>%
    dplyr::arrange(outcome, participant_id,
                   dplyr::if_else("interval_index" %in% names(.), interval_index, as.numeric(end_wave))) %>%
    dplyr::group_by(outcome, participant_id) %>%
    dplyr::mutate(first_onset_row = match(TRUE, event == 1L),
                  row_id = dplyr::row_number()) %>%
    dplyr::filter(is.na(first_onset_row) | row_id <= first_onset_row) %>%
    dplyr::ungroup() %>%
    dplyr::select(-first_onset_row, -row_id)
}

# ---- Display helpers ----------------------------------------------------------
coerce_cluster <- function(x) dplyr::recode(as.character(x),
  "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
  "C2"="Lower-Risk","2"="Lower-Risk","low"="Lower-Risk","lower"="Lower-Risk",
  .default = as.character(x)
)

time_map    <- c("ses-02A"="2y","ses-04A"="4y","ses-06A"="6y")
time_levels <- c("2y","4y","6y")

fmt_mean_sd <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return("\u2014")
  sprintf("%.2f \u00B1 %.2f", mean(x), stats::sd(x))
}
fmt_n <- function(n) ifelse(is.na(n), "\u2014", format(as.integer(n), big.mark = ","))
fmt_n_pct <- function(n, den) {
  out <- ifelse(is.na(den) | den == 0,
                "0 (0.0%)",
                sprintf("%s (%.1f%%)", fmt_n(n), 100 * n / den))
  as.character(out)
}

# Working frame (one row per pp interval) --------------------------------------
stopifnot(exists("su_pp_model"))
pp <- su_pp_model %>%
  dplyr::mutate(
    cluster_disp = coerce_cluster(cluster),
    time = factor(dplyr::recode(as.character(end_wave), !!!time_map), levels = time_levels)
  ) %>%
  dplyr::filter(!is.na(time), cluster_disp %in% c("Lower-Risk","Higher-Risk"))

# ---- DEMOGRAPHICS (ever-BD set; one row per participant × wave) --------------
demo_base <- pp %>%
  # collapse to one row per person per wave to avoid duplicating across outcomes
  dplyr::distinct(participant_id, time, cluster_disp, sex, site_factor, age_mid)

demo_counts <- demo_base %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),                             # = unique participants this wave
    n_part = dplyr::n_distinct(participant_id),    # same as n_pp by construction
    age_mean_sd = fmt_mean_sd(age_mid),
    .groups = "drop"
  )

age_row <- demo_counts %>%
  dplyr::transmute(time, cluster_disp, Row = "Age in years, Mean (SD)", val = age_mean_sd)

n_rows <- demo_counts %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw)
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

sex_tab <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ as.character(sex),
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, cluster_disp, participant_id, sex2) %>%
  dplyr::count(time, cluster_disp, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts %>% dplyr::select(time, cluster_disp, n_part), by = c("time","cluster_disp")) %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_cs <- dplyr::bind_rows(n_rows, age_row, sex_tab) %>%
  dplyr::mutate(Section = "Demographics")

# Totals across clusters
demo_counts_tot <- demo_base %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_mid),
    .groups = "drop"
  )

n_rows_total <- demo_counts_tot %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw),
    cluster_disp = "Total"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

age_row_total <- demo_counts_tot %>%
  dplyr::transmute(time, cluster_disp = "Total", Row = "Age in years, Mean (SD)", val = age_mean_sd)

sex_tab_total <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ as.character(sex),
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, participant_id, sex2) %>%
  dplyr::count(time, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts_tot %>% dplyr::select(time, n_part), by = "time") %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(cluster_disp = "Total", Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_total <- dplyr::bind_rows(n_rows_total, age_row_total, sex_tab_total) %>%
  dplyr::mutate(Section = "Demographics")

# ---- BD status rows (ever-BD: participant × wave) -----------------------------
collapse01 <- function(x) {
  if (all(is.na(x))) NA_integer_ else as.integer(any(x == 1L, na.rm = TRUE))
}

bd_by_id_wave <- su_pp_model %>%
  dplyr::mutate(
    cluster_disp = coerce_cluster(cluster),
    time = factor(dplyr::recode(as.character(end_wave), !!!time_map),
                  levels = time_levels)
  ) %>%
  dplyr::filter(!is.na(time), cluster_disp %in% c("Lower-Risk","Higher-Risk")) %>%
  dplyr::group_by(participant_id, time, cluster_disp) %>%
  dplyr::summarise(
    bd_start = collapse01(bd_any_start),
    bd_end   = collapse01(bd_any_end),
    .groups = "drop"
  )

# Cluster-specific n (%) per wave
bd_rows_cs <- bd_by_id_wave %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_start = sum(bd_start == 1L, na.rm = TRUE),
    den_start = sum(!is.na(bd_start)),
    n_end   = sum(bd_end == 1L,   na.rm = TRUE),
    den_end = sum(!is.na(bd_end)),
    .groups = "drop"
  ) %>%
  dplyr::bind_rows() %>%
  dplyr::transmute(
    time, cluster_disp,
    Row = "BD present at interval start, n (%)",
    val = fmt_n_pct(n_start, den_start)
  ) %>%
  dplyr::bind_rows(
    bd_by_id_wave %>%
      dplyr::group_by(time, cluster_disp) %>%
      dplyr::summarise(
        n_end = sum(bd_end == 1L, na.rm = TRUE),
        den_end = sum(!is.na(bd_end)),
        .groups = "drop"
      ) %>%
      dplyr::transmute(
        time, cluster_disp,
        Row = "BD present at interval end, n (%)",
        val = fmt_n_pct(n_end, den_end)
      )
  ) %>%
  dplyr::mutate(Section = "BD status (ever-BD)")

# Totals across clusters
bd_rows_total <- bd_by_id_wave %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_start = sum(bd_start == 1L, na.rm = TRUE),
    den_start = sum(!is.na(bd_start)),
    n_end   = sum(bd_end == 1L,   na.rm = TRUE),
    den_end = sum(!is.na(bd_end)),
    .groups = "drop"
  ) %>%
  dplyr::transmute(
    time, cluster_disp = "Total",
    Row = "BD present at interval start, n (%)",
    val = fmt_n_pct(n_start, den_start)
  ) %>%
  dplyr::bind_rows(
    bd_by_id_wave %>%
      dplyr::group_by(time) %>%
      dplyr::summarise(
        n_end = sum(bd_end == 1L, na.rm = TRUE),
        den_end = sum(!is.na(bd_end)),
        .groups = "drop"
      ) %>%
      dplyr::transmute(
        time, cluster_disp = "Total",
        Row = "BD present at interval end, n (%)",
        val = fmt_n_pct(n_end, den_end)
      )
  ) %>%
  dplyr::mutate(Section = "BD status (ever-BD)")

# ---- INTERVAL ONSETS (nested suicidality) -------------------------------------
su_out_labs <- c(
  si_passive = "Interval onset - Passive SI, n (%)",
  si_active  = "Interval onset - Active SI, n (%)",
  sa         = "Interval onset - Suicide attempt, n (%)",
  nssi       = "Interval onset - NSSI, n (%)"
)

events_cs <- pp %>%
  dplyr::filter(outcome %in% names(su_out_labs)) %>%
  dplyr::group_by(outcome, time, cluster_disp) %>%
  dplyr::summarise(
    n_at_risk = dplyr::n(),
    n_events  = sum(event == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!su_out_labs),
    val = fmt_n_pct(n_events, n_at_risk),
    Section = "Interval onsets (nested within ever-BD)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

events_total <- pp %>%
  dplyr::filter(outcome %in% names(su_out_labs)) %>%
  dplyr::group_by(outcome, time) %>%
  dplyr::summarise(
    n_at_risk = dplyr::n(),
    n_events  = sum(event == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!su_out_labs),
    val = fmt_n_pct(n_events, n_at_risk),
    cluster_disp = "Total",
    Section = "Interval onsets (nested within ever-BD)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

# ---- Assemble → wide → gt -----------------------------------------------------
long_all <- dplyr::bind_rows(
  demo_rows_cs, demo_rows_total,
  bd_rows_cs, bd_rows_total,       # << add these
  events_cs, events_total
) %>%
  dplyr::mutate(
    cluster_disp = factor(cluster_disp, levels = c("Total","Lower-Risk","Higher-Risk")),
    time = factor(time, levels = time_levels))

grid <- tidyr::crossing(
  Row = unique(long_all$Row),
  Section = unique(long_all$Section),
  cluster_disp = levels(long_all$cluster_disp),
  time = levels(long_all$time)
)
long_all <- grid %>%
  dplyr::left_join(long_all, by = c("Row","Section","cluster_disp","time")) %>%
  dplyr::mutate(val = dplyr::coalesce(val, "\u2014"))

wide <- long_all %>%
  dplyr::mutate(col_key = paste0(cluster_disp, "::", time)) %>%
  dplyr::select(Section, Row, col_key, val) %>%
  tidyr::pivot_wider(names_from = col_key, values_from = val)

col_keys <- c(
  paste0("Total::", time_levels),
  paste0("Lower-Risk::", time_levels),
  paste0("Higher-Risk::", time_levels)
)
have <- intersect(col_keys, names(wide))
wide <- wide %>% dplyr::select(Section, Row, dplyr::all_of(have))

tS3 <- gt::gt(wide, groupname_col = "Section", rowname_col = "Row") |>
  gt::cols_label(.list = setNames(rep(time_levels, 3), have)) |>
  gt::tab_spanner(label = "Total",       columns = dplyr::all_of(paste0("Total::", time_levels))) |>
  gt::tab_spanner(label = "Lower-Risk",  columns = dplyr::all_of(paste0("Lower-Risk::", time_levels))) |>
  gt::tab_spanner(label = "Higher-Risk", columns = dplyr::all_of(paste0("Higher-Risk::", time_levels))) |>
  gt::cols_align(align = "center", columns = dplyr::all_of(have)) |>
  gt::tab_caption("**Table S3. Characteristics of Participants in the Nested Onset of Suicidality Within Ever-BD by Risk Cluster Analysis**
Counts are shown per assessment interval (2y, 4y, 6y). Demographics are from the *ever-BD* risk set (one person-period per participant per interval). Interval onset rows report events within suicidality outcome–specific first-onset risk sets (post baseline-negative restriction and censoring), shown as *n (percent)* of person-periods at risk.") |>
  gt::tab_options(table.font.size = gt::px(12)) |>
  gt::fmt_missing(columns = dplyr::everything(), missing_text = "\u2014")

# Save + print
if (exists("save_gt")) {
  save_gt(tS3, "Table_S3_Nested_Suicidality_Onset_Characteristics_by_Cluster")
} else {
  gt::gtsave(tS3, file.path(getwd(), "Table_S3_Nested_Suicidality_Onset_Characteristics_by_Cluster.html"))
}
tS3

```

## Figure 7: Discrete Time Hazards and Cumulative Incidence of Suicidality Onset Nested Within Ever-BD by Risk Cluster

```{r figure 7 stats}

# ================= Figure 7: DTH Hazards & Cumulative Incidence of Suicidality (Nested within ever-BD) =================
# Outputs:
#   • fig7 object + saved PDF/PNG
#   • Console: per-outcome, Year-4 cumulative HR vs LR with RD & RR (95% CI, p)
#   • Console: across-intervals cluster OR (single summary per outcome)
#   • Console: BD present at interval start/end ORs (if in model), age within/between ORs

# -------- Config / labels ------------------------------------------------------
OUT_SU   <- c("si_passive","si_active","sa","nssi")
OUT_LABS <- c(si_passive="Passive SI",
              si_active ="Active SI",
              sa        ="Suicide Attempt",
              nssi      ="NSSI")
cluster_cols <- c("Lower-Risk" = "#11A579", "Higher-Risk" = "#7F3C8D")

cluster_scale_color <- scale_color_manual(
  name   = "Cluster",
  values = cluster_cols,
  limits = names(cluster_cols),  # only these two
  labels = names(cluster_cols),
  drop   = FALSE,
  na.value = NA
)

cluster_scale_fill <- scale_fill_manual(
  values = cluster_cols,
  limits = names(cluster_cols),
  drop   = FALSE,
  guide  = "none"                # hide fill legend
)

# File locations for nested DTH fits (adapt if your names differ)
fit_dir_su <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/main_analysis/3_nested_suic_dth"
fit_paths_su <- c(
  si_passive = file.path(fit_dir_su, "fit_primary_si_passive.rds"),
  si_active  = file.path(fit_dir_su, "fit_primary_si_active.rds"),
  sa         = file.path(fit_dir_su, "fit_primary_sa.rds"),
  nssi       = file.path(fit_dir_su, "fit_primary_nssi.rds")
)

safe_read <- function(p) tryCatch(readRDS(p), error = function(e) { message("Could not read: ", p); NULL })

# ---- Helpers shared with Fig 5 (slightly adapted for nested data) ------------
wave_levels  <- c("ses-02A","ses-04A")  # two post-baseline intervals (end at 2y, 4y)
wave_pretty  <- c("ses-02A"="Year-2", "ses-04A"="Year-4")

coerce_cluster <- function(x) dplyr::recode(as.character(x),
                                            "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
                                            "C2"="Lower-Risk","2"="Lower-Risk","low"="Lower-Risk","lower"="Lower-Risk",
                                            .default = as.character(x)
)

# Build a reference grid matched to the fit's factor levels/contrasts
make_ref_frame_su <- function(fit) {
  frm <- fit@frame
  
  levs <- lapply(frm[, vapply(frm, is.factor, TRUE), drop = FALSE], levels)
  get_lev <- function(v) if (v %in% names(levs)) levs[[v]] else NULL
  
  waves_lev   <- get_lev("end_wave");  if (is.null(waves_lev))  stop("No factor levels for end_wave in fit.")
  cluster_lev <- get_lev("cluster");   if (is.null(cluster_lev)) stop("No factor levels for cluster in fit.")
  
  # reference values for covariates (held constant)
  sex_lev     <- get_lev("sex");        site_lev <- get_lev("site_factor")
  base_lev    <- get_lev("baseline_status") # usually not used here, kept for safety
  
  ref <- expand.grid(
    end_wave        = waves_lev,
    cluster         = cluster_lev,
    age_mid_between = 0,
    age_mid_cwc     = 0,
    bd_any_start    = 0,    # hold BD state at reference (0) for display
    bd_any_end      = 0,
    sex             = if (!is.null(sex_lev)) sex_lev[1] else NA,
    site_factor     = if (!is.null(site_lev)) site_lev[1] else NA,
    stringsAsFactors = FALSE
  )
  
  # coerce to factors with full model levels
  ref$end_wave    <- factor(ref$end_wave, levels = waves_lev)
  ref$cluster     <- factor(ref$cluster,  levels = cluster_lev)
  if (!is.null(sex_lev))  ref$sex         <- factor(ref$sex,         levels = sex_lev)
  if (!is.null(site_lev)) ref$site_factor <- factor(ref$site_factor, levels = site_lev)
  if (!is.null(base_lev)) ref$baseline_status <- factor(base_lev[1], levels = base_lev)
  
  # model terms/contrasts (remove 1-level factors)
  ff_fix   <- lme4::nobars(stats::formula(fit))
  tt       <- stats::delete.response(stats::terms(ff_fix))
  contr_all <- attr(frm, "contrasts")
  if (!is.null(contr_all)) {
    multi_lvl <- names(frm)[sapply(frm, function(x) is.factor(x) && nlevels(x) > 1)]
    contr_all <- contr_all[names(contr_all) %in% multi_lvl]
  }
  
  X <- stats::model.matrix(tt, ref, contrasts.arg = contr_all)
  beta <- lme4::fixef(fit)
  V    <- as.matrix(stats::vcov(fit))
  
  # align columns to beta order
  miss <- setdiff(names(beta), colnames(X))
  if (length(miss)) X <- cbind(X, matrix(0, nrow(X), length(miss), dimnames = list(NULL, miss)))
  X <- X[, names(beta), drop = FALSE]
  
  list(ref = ref, X = X, beta = beta, V = V,
       waves = waves_lev, clusters = cluster_lev)
}

# Hazards -> cumulative risk up to wave index k
cumrisk_from_haz <- function(h, k) {
  h <- pmin(pmax(h, 1e-8), 1 - 1e-8)
  1 - exp(sum(log1p(-h[seq_len(k)])))
}

# MVN draws of fixed effects: hazards & cumulative risk (by wave × cluster)
haz_cum_by_wave_ci_mvn <- function(fit, B = 3000, probs = c(0.025, 0.975)) {
  obj <- make_ref_frame_su(fit)
  ref <- obj$ref; X <- obj$X; beta <- obj$beta; V <- obj$V
  
  # Draws
  if (requireNamespace("MASS", quietly = TRUE)) {
    beta_draws <- MASS::mvrnorm(n = B, mu = beta, Sigma = V)
  } else {
    L <- try(chol(V), silent = TRUE)
    if (inherits(L, "try-error")) {
      V <- diag(diag(V), nrow(V))  # ridge fallback
      L <- chol(V)
    }
    Z <- matrix(stats::rnorm(B * length(beta)), nrow = B)
    beta_draws <- sweep(Z %*% t(L), 2, beta, `+`)
  }
  
  eta_draws <- X %*% t(beta_draws)
  p_draws   <- plogis(eta_draws)
  
  # index rows by cluster & wave
  ref$end_wave <- factor(ref$end_wave, levels = obj$waves)
  ref$cluster  <- factor(ref$cluster,  levels = obj$clusters)
  idx_by <- split(seq_len(nrow(ref)), paste(ref$cluster, ref$end_wave, sep = "::"))
  
  # Hazards: point & CI by row
  haz <- purrr::map_dfr(names(idx_by), function(key) {
    r <- idx_by[[key]]
    phat <- plogis(as.numeric(X[r, , drop = FALSE] %*% beta))
    draws <- p_draws[r, , drop = FALSE]
    lo <- stats::quantile(draws, probs = probs[1], na.rm = TRUE)
    hi <- stats::quantile(draws, probs = probs[2], na.rm = TRUE)
    tibble(
      cluster = as.character(ref$cluster[r]),
      end_wave = as.character(ref$end_wave[r]),
      hazard = phat, hazard_lo = as.numeric(lo), hazard_hi = as.numeric(hi)
    )
  })
  
  # Cumulative risk by cluster across ordered waves
  idx_by_clu <- split(seq_len(nrow(ref)), ref$cluster)
  cum <- purrr::map_dfr(names(idx_by_clu), function(cl) {
    rows <- idx_by_clu[[cl]]
    rows <- rows[order(ref$end_wave[rows])]  # enforce ses-02A -> ses-04A
    Hhat <- plogis(as.numeric(X[rows, , drop = FALSE] %*% beta))
    CRhat <- cumsum(log1p(-Hhat)) |> (\(v) 1 - exp(v))()  # numerically stable
    
    draws <- p_draws[rows, , drop = FALSE]  # waves x B
    CRdraws <- apply(draws, 2, function(col) 1 - cumprod(1 - col))
    if (is.null(dim(CRdraws))) CRdraws <- matrix(CRdraws, nrow = length(rows), ncol = 1)
    lo <- apply(CRdraws, 1, stats::quantile, probs = probs[1], na.rm = TRUE)
    hi <- apply(CRdraws, 1, stats::quantile, probs = probs[2], na.rm = TRUE)
    
    tibble(
      cluster = cl,
      end_wave = as.character(ref$end_wave[rows]),
      cumrisk = as.numeric(CRhat),
      cumrisk_lo = as.numeric(lo),
      cumrisk_hi = as.numeric(hi)
    )
  })
  
  list(haz = haz, cum = cum)
}

# Delta-method CI for Year-4 RD/RR (HR vs LR)
wald_ci <- function(theta_hat, grad, V, level = 0.95, log_scale = FALSE) {
  V <- V + diag(1e-10, nrow(V))  # tiny ridge
  se <- sqrt(drop(t(grad) %*% V %*% grad))
  z  <- qnorm((1 + level)/2)
  if (log_scale) {
    lo <- theta_hat * exp(-z * se); hi <- theta_hat * exp(+z * se)
  } else {
    lo <- theta_hat - z * se;       hi <- theta_hat + z * se
  }
  list(se = se, lo = lo, hi = hi, z = theta_hat / se, p = 2 * pnorm(-abs(theta_hat / se)))
}

year4_rd_rr_delta <- function(fit, wave_key = "ses-04A") {
  obj <- make_ref_frame_su(fit)
  ref <- obj$ref; X <- obj$X; beta <- obj$beta; V <- obj$V
  waves <- obj$waves
  if (!wave_key %in% waves) wave_key <- tail(waves, 1)
  k_idx <- match(wave_key, waves)
  
  cl_levels <- levels(ref$cluster)
  disp <- coerce_cluster(cl_levels)
  role <- setNames(ifelse(disp == "Higher-Risk","HR", ifelse(disp == "Lower-Risk","LR", NA_character_)), cl_levels)
  if (anyNA(role)) {
    # fallback by larger point CR
    point_cr <- sapply(cl_levels, function(cl) {
      rows <- which(ref$cluster == cl)
      h <- plogis(as.numeric(X[rows, , drop = FALSE] %*% beta))
      cumrisk_from_haz(h, k_idx)
    })
    role[] <- "LR"; role[names(which.max(point_cr))] <- "HR"
  }
  
  make_f <- function(cl) {
    rows <- which(ref$cluster == cl)
    function(b) {
      h <- plogis(as.numeric(X[rows, , drop = FALSE] %*% b))
      cumrisk_from_haz(h, k_idx)
    }
  }
  f_HR <- make_f(names(role)[role == "HR"])
  f_LR <- make_f(names(role)[role == "LR"])
  
  CR_HR <- f_HR(beta); CR_LR <- f_LR(beta)
  CR_HR <- pmin(pmax(CR_HR, 1e-8), 1 - 1e-8)
  CR_LR <- pmin(pmax(CR_LR, 1e-8), 1 - 1e-8)
  RD    <- CR_HR - CR_LR
  RR    <- CR_HR / CR_LR
  
  g_HR <- numDeriv::grad(f_HR, beta)
  g_LR <- numDeriv::grad(f_LR, beta)
  
  # RD
  g_RD  <- g_HR - g_LR
  ci_RD <- wald_ci(RD, g_RD, V, level = 0.95, log_scale = FALSE)
  
  # log(RR)
  g_logRR  <- g_HR / CR_HR - g_LR / CR_LR
  se_logRR <- sqrt(drop(t(g_logRR) %*% V %*% g_logRR))
  z <- qnorm(0.975)
  RR_lo <- RR * exp(-z * se_logRR)
  RR_hi <- RR * exp(+z * se_logRR)
  p_logRR <- 2 * pnorm(-abs(log(RR) / se_logRR))
  
  list(
    wave = wave_key,
    CR_HR = CR_HR, CR_LR = CR_LR,
    RD = RD, RD_lo = ci_RD$lo, RD_hi = ci_RD$hi, RD_p = ci_RD$p,
    RR = RR, RR_lo = RR_lo, RR_hi = RR_hi, RR_p = p_logRR
  )
}

# Across-intervals cluster OR (average contrast over available waves)
cluster_or_overall <- function(fit) {
  obj <- make_ref_frame_su(fit)
  ref <- obj$ref; X <- obj$X; beta <- obj$beta; V <- obj$V
  waves <- obj$waves
  cl_lev <- levels(ref$cluster)
  if (length(cl_lev) < 2) return(NULL)
  
  D <- lapply(waves, function(w) {
    r1 <- which(ref$end_wave == w & ref$cluster == cl_lev[2]) # C1
    r0 <- which(ref$end_wave == w & ref$cluster == cl_lev[1]) # C2
    X[r1, , drop=FALSE] - X[r0, , drop=FALSE]
  })
  dbar <- Reduce(`+`, D) / length(D)
  est <- as.numeric(dbar %*% beta)
  se  <- sqrt(drop(dbar %*% V %*% t(dbar)))
  OR  <- exp(est)
  lo  <- OR * exp(-qnorm(0.975) * se)
  hi  <- OR * exp(+qnorm(0.975) * se)
  p   <- 2 * pnorm(-abs(est / se))
  c(OR = OR, lo = lo, hi = hi, p = p)
}

# Convenience: pull OR/CI/p for a named coefficient if present
coef_or <- function(fit, term) {
  b <- lme4::fixef(fit); V <- as.matrix(stats::vcov(fit))
  if (!term %in% names(b)) return(NULL)
  est <- unname(b[term]); se <- sqrt(V[term, term, drop=TRUE])
  OR <- exp(est); lo <- OR * exp(-qnorm(0.975)*se); hi <- OR * exp(+qnorm(0.975)*se)
  p  <- 2 * pnorm(-abs(est/se))
  c(OR = OR, lo = lo, hi = hi, p = p)
}

fmt_p  <- function(p) ifelse(is.na(p), "-", ifelse(p < .001, "<.001", sprintf("%.3f", p)))
fmt_ci <- function(lo, hi) sprintf("%s–%s", sprintf("%.2f", lo), sprintf("%.2f", hi))

# ---- Load models and compute hazards/cumulative --------------------------------
fits_su <- lapply(OUT_SU, function(o) safe_read(fit_paths_su[[o]])) |> setNames(OUT_SU)
loaded_ok <- names(Filter(Negate(is.null), fits_su))
message("Loaded nested DTH fits: ", paste(loaded_ok, collapse = ", "))

# Wave median ages for x-axis labels (from nested_pp or su_pp_model if present)
age_meds_tbl <- try({
  (if (exists("su_pp_model")) su_pp_model else nested_pp) %>%
    dplyr::group_by(end_wave) %>%
    dplyr::summarise(age_med = median(age_mid, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(end_wave = as.character(end_wave))
}, silent = TRUE)
if (inherits(age_meds_tbl, "try-error")) {
  age_meds_tbl <- tibble(end_wave = wave_levels, age_med = NA_real_)
}
age_meds_vec <- setNames(age_meds_tbl$age_med, age_meds_tbl$end_wave)
x_lab_vec <- setNames(
  ifelse(is.finite(age_meds_vec[wave_levels]),
         sprintf("%s\nMedian Mid-Interval Age=%.1f", wave_pretty[wave_levels], age_meds_vec[wave_levels]),
         sprintf("%s\nMedian Mid-Interval Age=—",      wave_pretty[wave_levels])),
  wave_levels
)

# Predictive summaries for all outcomes
haz_list <- list(); cum_list <- list()
for (o in OUT_SU) {
  fit <- fits_su[[o]]
  if (is.null(fit)) next
  hc <- haz_cum_by_wave_ci_mvn(fit, B = 3000)
  haz_list[[o]] <- hc$haz %>%
    mutate(outcome = o,
           cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
           end_wave = factor(end_wave, levels = wave_levels))
  cum_list[[o]] <- hc$cum %>%
    mutate(outcome = o,
           cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
           end_wave = factor(end_wave, levels = wave_levels))
}
haz_df <- bind_rows(haz_list)
cum_df <- bind_rows(cum_list)

# Empirical (unadjusted) per-interval proportions for overlay
emp_df <- try({
  (if (exists("su_pp_model")) su_pp_model else nested_pp) %>%
    dplyr::filter(outcome %in% OUT_SU, event %in% c(0,1)) %>%
    dplyr::mutate(cluster_disp = factor(coerce_cluster(cluster), levels = c("Lower-Risk","Higher-Risk")),
                  end_wave = factor(end_wave, levels = wave_levels)) %>%
    dplyr::group_by(outcome, end_wave, cluster_disp) %>%
    dplyr::summarise(emp = mean(event == 1L, na.rm = TRUE), .groups = "drop")
}, silent = TRUE)
if (inherits(emp_df, "try-error")) {
  emp_df <- tibble(outcome=character(), end_wave=factor(character(), levels=wave_levels),
                   cluster_disp=factor(character(), levels=c("Lower-Risk","Higher-Risk")), emp=double())
}

# --- Observed cumulative incidence (unadjusted) for overlay -------------------
emp_cum_df <- try({
  src <- if (exists("su_pp_model")) su_pp_model else nested_pp
  src %>%
    dplyr::filter(outcome %in% OUT_SU, event %in% c(0, 1)) %>%
    dplyr::mutate(
      end_wave_chr = as.character(end_wave),
      cluster_chr  = coerce_cluster(cluster)
    ) %>%
    # keep only the two waves you're plotting and the two valid clusters
    dplyr::filter(end_wave_chr %in% wave_levels,
                  cluster_chr  %in% names(cluster_cols)) %>%
    dplyr::mutate(
      end_wave     = factor(end_wave_chr, levels = wave_levels),
      cluster_disp = factor(cluster_chr,  levels = names(cluster_cols))
    ) %>%
    dplyr::group_by(outcome, cluster_disp, end_wave) %>%
    dplyr::summarise(h = mean(event == 1L, na.rm = TRUE), .groups = "drop") %>%
    dplyr::group_by(outcome, cluster_disp) %>%
    dplyr::arrange(end_wave, .by_group = TRUE) %>%
    dplyr::mutate(cumrisk_obs = 1 - cumprod(1 - pmin(pmax(h, 0), 1))) %>%
    dplyr::ungroup()
}, silent = TRUE)

if (inherits(emp_cum_df, "try-error")) {
  emp_cum_df <- tibble::tibble(
    outcome = character(),
    end_wave = factor(character(), levels = wave_levels),
    cluster_disp = factor(character(), levels = c("Lower-Risk","Higher-Risk")),
    cumrisk_obs = double()
  )
}

# ---- Plot helpers (clean axes only, no gridlines) -----------------------------
# Tweak these two to change sizes globally
BASE_TEXT_SIZE   <- 10  # titles & general text
AXIS_TEXT_SIZE   <- 7.5   # tick labels

axes_only_theme <- function(base_size = BASE_TEXT_SIZE, axis_text = AXIS_TEXT_SIZE) {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid        = element_blank(),       # no gridlines
      axis.line.x.bottom= element_line(color = "black", linewidth = 0.3),
      axis.line.y.left  = element_line(color = "black", linewidth = 0.3),
      axis.ticks        = element_line(color = "black", linewidth = 0.3),
      axis.ticks.length = grid::unit(2.5, "pt"),
      axis.text         = element_text(size = axis_text),
      legend.position   = "bottom",
      legend.box        = "horizontal"
    )
}

# Per-panel “strip” helpers to remove lines/ticks/labels on interior panels
strip_x_all <- theme(
  axis.title.x        = element_blank(),
  axis.text.x         = element_blank(),
  axis.ticks.x        = element_blank(),
  axis.line.x.bottom  = element_blank()
)
strip_y_all <- theme(
  axis.title.y        = element_blank(),
  axis.text.y         = element_blank(),
  axis.ticks.y        = element_blank(),
  axis.line.y.left    = element_blank()
)
strip_y_title <- theme(axis.title.y = element_blank())


# ---- Build per-outcome panels -------------------------------------------------
# Dynamic ymax for cumulative (prevents clipping; add a bit of headroom)
cum_ymax <- if (nrow(cum_df)) min(1, max(cum_df$cumrisk_hi, na.rm = TRUE) * 1.05) else 0.3

plot_haz <- function(out_key) {
  d <- haz_df %>% dplyr::filter(outcome == out_key)
  e <- emp_df %>%
    dplyr::filter(outcome == out_key,
                  !is.na(cluster_disp),
                  as.character(end_wave) %in% wave_levels) %>%
    dplyr::mutate(end_wave = factor(end_wave, levels = wave_levels)) %>%
    droplevels()
  
  ggplot(d, aes(x = end_wave, y = hazard, color = cluster_disp, group = cluster_disp)) +
    geom_ribbon(aes(ymin = hazard_lo, ymax = hazard_hi, fill = cluster_disp),
                alpha = 0.18, color = NA) +
    geom_line(linewidth = 0.9) +
    geom_point(size = 1.8) +
    geom_point(data = e, aes(x = end_wave, y = emp, color = cluster_disp),
               shape = 1, size = 1.8, inherit.aes = FALSE) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.01), limits = c(0, NA)) +
    scale_x_discrete(drop = FALSE, labels = x_lab_vec) +
    cluster_scale_color +
    cluster_scale_fill +
    guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
    labs(title = glue("({LETTERS[match(out_key, OUT_SU)]})  {OUT_LABS[[out_key]]} Interval Hazard"),
         x = "Wave (Interval End)", y = "Predicted hazard (Per Interval)") +
    axes_only_theme()
}

plot_cum <- function(out_key) {
  d <- cum_df %>% dplyr::filter(outcome == out_key)
  e_cum <- emp_cum_df %>% dplyr::filter(outcome == out_key)
  
  ggplot(d, aes(x = end_wave, y = cumrisk, color = cluster_disp, group = cluster_disp)) +
    geom_ribbon(aes(ymin = cumrisk_lo, ymax = cumrisk_hi, fill = cluster_disp),
                alpha = 0.15, color = NA) +
    geom_line(linewidth = 0.9) +
    geom_point(size = 1.8) +
    geom_point(data = e_cum,
               aes(x = end_wave, y = cumrisk_obs, color = cluster_disp),
               shape = 1, size = 1.8, inherit.aes = FALSE, na.rm = TRUE) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.1),
                       limits = c(0, cum_ymax)) +
    scale_x_discrete(drop = FALSE, labels = x_lab_vec) +
    cluster_scale_color +
    cluster_scale_fill +
    labs(title = glue("({LETTERS[match(out_key, OUT_SU)+4]})  {OUT_LABS[[out_key]]} Cumulative Incidence"),
         x = "Wave (Interval End)", y = "Cumulative Risk") +
    axes_only_theme()
}

haz_panels <- lapply(OUT_SU, plot_haz)
cum_panels <- lapply(OUT_SU, plot_cum)

# Legends: keep only on first hazard panel
haz_panels[2:4] <- lapply(haz_panels[2:4], \(p) p + theme(legend.position = "none"))
cum_panels      <- lapply(cum_panels,      \(p) p + theme(legend.position = "none"))

# Show axis lines only on leftmost (y) and bottommost (x) panels in each 2x2 grid
# Hazards grid: panels arranged as 1 2 / 3 4
haz_panels[[1]] <- haz_panels[[1]] + strip_x_all                    # top-left: remove x; keep y
haz_panels[[2]] <- haz_panels[[2]] + strip_x_all   # top-right: remove x and y
# bottom-left keeps both axes; bottom-right removes y only
haz_panels[[4]] <- haz_panels[[4]] 

# Cumulative grid: same treatment
cum_panels[[1]] <- cum_panels[[1]] + strip_x_all
cum_panels[[2]] <- cum_panels[[2]] + strip_x_all
cum_panels[[4]] <- cum_panels[[4]]

# Arrange (2×2 hazards over 2×2 cumulative)
haz_grid <- (haz_panels[[1]]) + (haz_panels[[2]]) +
  (haz_panels[[3]]) + (haz_panels[[4]]) +
  patchwork::plot_layout(ncol = 2)
cum_grid <- (cum_panels[[1]]) + (cum_panels[[2]]) +
  (cum_panels[[3]]) + (cum_panels[[4]]) +
  patchwork::plot_layout(ncol = 2)

fig7 <- haz_grid / cum_grid +
  patchwork::plot_layout(heights = c(1, 1), guides = "collect") &
  theme(legend.position = "bottom", legend.justification = "center")

print(fig7)

# Save
out_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/figures"
pdf7 <- file.path(out_dir, "Figure_07_Nested_Suicidality_DTH_Hazards_and_Cumulative_by_Cluster.pdf")
png7 <- file.path(out_dir, "Figure_07_Nested_Suicidality_DTH_Hazards_and_Cumulative_by_Cluster.png")
ggsave(pdf7, fig7, width = 8.5, height = 11, device = cairo_pdf)
ggsave(png7, fig7, width = 8.5, height = 11, dpi = 720)

# ---- In-line stats for Results -------------------------------------------------
# 1) Year-4 cumulative risk HR vs LR with RD & RR
yr4_tbl <- purrr::map_dfr(OUT_SU, function(o) {
  fit <- fits_su[[o]]; if (is.null(fit)) return(NULL)
  res <- year4_rd_rr_delta(fit, wave_key = "ses-04A")
  tibble(
    outcome = o, out_lab = OUT_LABS[o],
    wave = res$wave,
    HR = res$CR_HR, LR = res$CR_LR,
    RD = res$RD, RD_lo = res$RD_lo, RD_hi = res$RD_hi, RD_p = res$RD_p,
    RR = res$RR, RR_lo = res$RR_lo, RR_hi = res$RR_hi, RR_p = res$RR_p
  )
})

if (nrow(yr4_tbl)) {
  yr4_lines <- yr4_tbl %>%
    mutate(
      line = glue("{out_lab} Year-4 cumulative risk: ",
                  "{scales::percent(HR, 0.1)} (HR) vs {scales::percent(LR, 0.1)} (LR); ",
                  "RD = {scales::percent(RD, 0.1)} [{scales::percent(RD_lo, 0.1)}, {scales::percent(RD_hi, 0.1)}], p = {sprintf('%.3f', RD_p)}; ",
                  "RR = {sprintf('%.2f', RR)} [{sprintf('%.2f', RR_lo)}, {sprintf('%.2f', RR_hi)}], p = {sprintf('%.3f', RR_p)}")
    ) %>% pull(line)
  cat("Figure 7 in-line stats — Year-4 cumulative risk (HR vs LR):\n",
      paste0(" • ", yr4_lines, collapse = "\n"), "\n\n")
} else {
  message("Year-4 cumulative table could not be computed (no fits?).")
}

# 2) Across-intervals cluster OR (summary per outcome)
clust_lines <- purrr::map_chr(OUT_SU, function(o) {
  fit <- fits_su[[o]]; if (is.null(fit)) return(NA_character_)
  or <- cluster_or_overall(fit); if (is.null(or)) return(NA_character_)
  glue("{OUT_LABS[[o]]}: higher- vs lower-risk OR = {sprintf('%.2f', or['OR'])} ",
       "(95% CI {fmt_ci(as.numeric(or['lo']), as.numeric(or['hi']))}, p = {fmt_p(as.numeric(or['p']))})")
}) %>% stats::na.omit()
if (length(clust_lines)) {
  cat("Across-intervals cluster effect (OR, averaged over intervals):\n",
      paste0(" • ", clust_lines, collapse = "\n"), "\n\n")
}

# 3) BD at interval start/end, and age effects (report if present in the fit)
pull_effects <- function(fit, map) {
  out <- list()
  # bd_any_start / bd_any_end
  for (tm in c("bd_any_start","bd_any_end","age_mid_cwc","age_mid_between")) {
    co <- coef_or(fit, tm)
    if (!is.null(co)) {
      label <- dplyr::case_when(
        tm == "bd_any_start"   ~ "BD present at interval start",
        tm == "bd_any_end"     ~ "BD present at interval end",
        tm == "age_mid_cwc"    ~ "within-person age",
        tm == "age_mid_between"~ "between-person age",
        TRUE ~ tm
      )
      out[[tm]] <- glue("{label}: OR = {sprintf('%.2f', co['OR'])} ",
                        "(95% CI {fmt_ci(as.numeric(co['lo']), as.numeric(co['hi']))}, p = {fmt_p(as.numeric(co['p']))})")
    }
  }
  unname(unlist(out))
}

eff_lines <- purrr::imap_chr(fits_su, function(fit, o) {
  if (is.null(fit)) return(NA_character_)
  effs <- pull_effects(fit, o)
  if (!length(effs)) return(NA_character_)
  glue("{OUT_LABS[[o]]}: {paste(effs, collapse='; ')}")
}) %>% stats::na.omit()

if (length(eff_lines)) {
  cat("Key covariate effects (reported when present in the model):\n",
      paste0(" • ", eff_lines, collapse = "\n"), "\n")
}

```

## Table S4: Characteristics of Participants in the Prevalence of Suicidality Over Time Within Ever-BD by Risk Cluster Analysis

```{r table s4}

## Table S4 — Prevalence of suicidality (GEE) within ever-BD, by cluster --------

# 0) Prep -----------------------------------------------------------------------
stopifnot(exists("nested_panel"), is.data.frame(nested_panel))

np <- nested_panel %>%
  dplyr::mutate(
    participant_id = as.character(participant_id),
    family_id      = factor(as.character(family_id)),
    site_factor    = factor(site_factor),
    cluster        = factor(cluster),
    wave           = factor(wave, levels = c("ses-02A","ses-04A")),
    outcome        = factor(outcome, levels = c("si_passive","si_active","sa","nssi")),
    sex            = factor(sex)
  )

# Keep binary response + required fields; restrict to ever-BD rows
status_var <- "status"
np[[status_var]] <- as.integer(np[[status_var]])
np[[status_var]][!np[[status_var]] %in% c(0L,1L)] <- NA_integer_

panel <- np %>%
  dplyr::filter(.data[[status_var]] %in% c(0L,1L) | is.na(.data[[status_var]])) %>%
  dplyr::filter(!is.na(cluster), !is.na(sex), !is.na(site_factor),
                !is.na(family_id), !is.na(participant_id), !is.na(wave)) %>%
  dplyr::filter(isTRUE(ever_bd) | ever_bd) %>%
  # reference levels
  dplyr::mutate(
    cluster = forcats::fct_relevel(cluster, "C2"),
    sex     = forcats::fct_relevel(sex, "Female")
  )

# 1) Display helpers ------------------------------------------------------------
coerce_cluster <- function(x) dplyr::recode(as.character(x),
  "C1"="Higher-Risk","1"="Higher-Risk","high"="Higher-Risk","higher"="Higher-Risk",
  "C2"="Lower-Risk","2"="Lower-Risk","low"="Lower-Risk","lower"="Lower-Risk",
  .default = as.character(x)
)
time_map_all  <- c("ses-02A"="2y","ses-04A"="4y","ses-06A"="6y")
# keep only waves present, but in canonical order
have_waves    <- intersect(names(time_map_all), levels(panel$wave))
time_map      <- time_map_all[have_waves]
time_levels   <- unname(time_map)

fmt_mean_sd <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return("\u2014")
  sprintf("%.2f \u00B1 %.2f", mean(x), stats::sd(x))
}
fmt_n <- function(n) ifelse(is.na(n), "\u2014", format(as.integer(n), big.mark = ","))
fmt_n_pct <- function(n, den) {
  out <- ifelse(is.na(den) | den == 0,
                "0 (0.0%)",
                sprintf("%s (%.1f%%)", fmt_n(n), 100 * n / den))
  as.character(out)
}

panel <- panel %>%
  dplyr::mutate(
    cluster_disp = coerce_cluster(cluster),
    time = factor(dplyr::recode(as.character(wave), !!!time_map), levels = time_levels),
    sex  = as.character(sex)
  ) %>%
  dplyr::filter(!is.na(time), cluster_disp %in% c("Lower-Risk","Higher-Risk"))

# 2) DEMOGRAPHICS (participant×wave; collapse across outcomes) ------------------
demo_base <- panel %>%
  dplyr::distinct(participant_id, time, cluster_disp, sex, site_factor, age_wave)

demo_counts <- demo_base %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_wave),
    .groups = "drop"
  )

age_row <- demo_counts %>%
  dplyr::transmute(time, cluster_disp, Row = "Age in years, Mean (SD)", val = age_mean_sd)

n_rows <- demo_counts %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw)
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

sex_tab <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, cluster_disp, participant_id, sex2) %>%
  dplyr::count(time, cluster_disp, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts %>% dplyr::select(time, cluster_disp, n_part), by = c("time","cluster_disp")) %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_cs <- dplyr::bind_rows(n_rows, age_row, sex_tab) %>%
  dplyr::mutate(Section = "Demographics")

# Totals
demo_counts_tot <- demo_base %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_pp = dplyr::n(),
    n_part = dplyr::n_distinct(participant_id),
    age_mean_sd = fmt_mean_sd(age_wave),
    .groups = "drop"
  )

n_rows_total <- demo_counts_tot %>%
  tidyr::pivot_longer(c(n_pp, n_part), names_to = "what", values_to = "val_raw") %>%
  dplyr::mutate(
    Row = dplyr::case_when(
      what == "n_part" ~ "N (participants)",
      what == "n_pp"   ~ "N (person-periods)"
    ),
    val = fmt_n(val_raw),
    cluster_disp = "Total"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val)

age_row_total <- demo_counts_tot %>%
  dplyr::transmute(time, cluster_disp = "Total", Row = "Age in years, Mean (SD)", val = age_mean_sd)

sex_tab_total <- demo_base %>%
  dplyr::mutate(sex2 = dplyr::case_when(
    !is.na(sex) & sex %in% c("Male","Female") ~ sex,
    TRUE ~ "Other/Unknown"
  )) %>%
  dplyr::distinct(time, participant_id, sex2) %>%
  dplyr::count(time, sex2, name = "n_sex") %>%
  dplyr::left_join(demo_counts_tot %>% dplyr::select(time, n_part), by = "time") %>%
  dplyr::mutate(val = fmt_n_pct(n_sex, n_part)) %>%
  dplyr::filter(sex2 %in% c("Male","Female")) %>%
  dplyr::mutate(cluster_disp = "Total", Row = paste0("Sex at birth - ", sex2)) %>%
  dplyr::select(time, cluster_disp, Row, val)

demo_rows_total <- dplyr::bind_rows(n_rows_total, age_row_total, sex_tab_total) %>%
  dplyr::mutate(Section = "Demographics")

# 3) OCCURRENCE rows — suicidality wave prevalence ------------------------------
su_out_labs <- c(
  si_passive = "Occurrence - Passive SI, n (%)",
  si_active  = "Occurrence - Active SI, n (%)",
  sa         = "Occurrence - Suicide attempt, n (%)",
  nssi       = "Occurrence - NSSI, n (%)"
)

occ_cs <- panel %>%
  dplyr::filter(outcome %in% names(su_out_labs)) %>%
  dplyr::group_by(outcome, time, cluster_disp) %>%
  dplyr::summarise(
    n_obs   = sum(!is.na(.data[[status_var]])),
    n_cases = sum(.data[[status_var]] == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!su_out_labs),
    val = fmt_n_pct(n_cases, n_obs),
    Section = "Occurrence (suicidality wave prevalence)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

occ_total <- panel %>%
  dplyr::filter(outcome %in% names(su_out_labs)) %>%
  dplyr::group_by(outcome, time) %>%
  dplyr::summarise(
    n_obs   = sum(!is.na(.data[[status_var]])),
    n_cases = sum(.data[[status_var]] == 1L, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    Row = dplyr::recode(outcome, !!!su_out_labs),
    val = fmt_n_pct(n_cases, n_obs),
    cluster_disp = "Total",
    Section = "Occurrence (suicidality wave prevalence)"
  ) %>%
  dplyr::select(time, cluster_disp, Row, val, Section)

# 4) Any-BSD at the same wave (one row per participant×wave to avoid duplication)
bsd_wave_cs <- panel %>%
  dplyr::distinct(participant_id, time, cluster_disp, any_bsd) %>%
  dplyr::group_by(time, cluster_disp) %>%
  dplyr::summarise(
    n_obs = sum(!is.na(any_bsd)),
    n_bsd = sum(any_bsd == 1, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::transmute(
    time, cluster_disp,
    Row = "Any BSD at wave, n (%)",
    val = fmt_n_pct(n_bsd, n_obs),
    Section = "BD at wave (ever-BD set)"
  )

bsd_wave_total <- panel %>%
  dplyr::distinct(participant_id, time, any_bsd) %>%
  dplyr::group_by(time) %>%
  dplyr::summarise(
    n_obs = sum(!is.na(any_bsd)),
    n_bsd = sum(any_bsd == 1, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::transmute(
    time, cluster_disp = "Total",
    Row = "Any BSD at wave, n (%)",
    val = fmt_n_pct(n_bsd, n_obs),
    Section = "BD at wave (ever-BD set)"
  )

# 5) Assemble → complete grid → wide → GT ---------------------------------------
long_all <- dplyr::bind_rows(
  demo_rows_cs, demo_rows_total,
  bsd_wave_cs, bsd_wave_total,
  occ_cs, occ_total
) %>%
  dplyr::mutate(
    cluster_disp = factor(cluster_disp, levels = c("Total","Lower-Risk","Higher-Risk")),
    time = factor(time, levels = time_levels)
  )

grid <- tidyr::crossing(
  Row = unique(long_all$Row),
  Section = unique(long_all$Section),
  cluster_disp = levels(long_all$cluster_disp),
  time = levels(long_all$time)
)
long_all <- grid %>%
  dplyr::left_join(long_all, by = c("Row","Section","cluster_disp","time")) %>%
  dplyr::mutate(val = dplyr::coalesce(val, "\u2014"))

wide <- long_all %>%
  dplyr::mutate(col_key = paste0(cluster_disp, "::", time)) %>%
  dplyr::select(Section, Row, col_key, val) %>%
  tidyr::pivot_wider(names_from = col_key, values_from = val)

col_keys <- c(
  paste0("Total::", time_levels),
  paste0("Lower-Risk::", time_levels),
  paste0("Higher-Risk::", time_levels)
)
have <- intersect(col_keys, names(wide))
wide <- wide %>% dplyr::select(Section, Row, dplyr::all_of(have))

tS4 <- gt::gt(wide, groupname_col = "Section", rowname_col = "Row") |>
  gt::cols_label(.list = setNames(rep(time_levels, 3), have)) |>
  gt::tab_spanner(label = "Total",       columns = dplyr::all_of(paste0("Total::", time_levels))) |>
  gt::tab_spanner(label = "Lower-Risk",  columns = dplyr::all_of(paste0("Lower-Risk::", time_levels))) |>
  gt::tab_spanner(label = "Higher-Risk", columns = dplyr::all_of(paste0("Higher-Risk::", time_levels))) |>
  gt::cols_align(align = "center", columns = dplyr::all_of(have)) |>
  gt::tab_caption("**Table S4. Characteristics of Participants in the Prevalence of Suicidality Over Time Within Ever-BD by Risk Cluster (GEE Analysis)**
Counts are shown per assessment wave (2y, 4y, 6y). Demographics collapse to one row per participant per wave within the ever-BD set. 
“Any BSD at wave” reflects contemporaneous BSD presence at that wave. 
Occurrence rows report suicidality wave prevalence (status==1) within outcome panels, shown as *n (percent)* of observed person-periods (denominator excludes missing).") |>
  gt::tab_options(table.font.size = gt::px(12)) |>
  gt::fmt_missing(columns = dplyr::everything(), missing_text = "\u2014")

# Save + print
if (exists("save_gt")) {
  save_gt(tS4, "Table_S4_Suicidality_Prevalence_EverBD_Characteristics_by_Cluster")
} else {
  gt::gtsave(tS4, file.path(getwd(), "Table_S4_Suicidality_Prevalence_EverBD_Characteristics_by_Cluster.html"))
}
tS4

```

## Figure 8: Ever-BD Nested Suicidality Odds for the Higher-Risk Relative to Lower-Risk Cluster Over Time

```{r figure 8 stats}

# ================= Figure 8: Ever-BD Nested Suicidality Odds (C1 vs C2) Over Time =================
# Inputs:
#   - Saved GEE models with wave×cluster interaction:
#       ".../4_nested_suicidality_mixed_logit/rds/<outcome>_GEE_EXC_INT.rds"
#   - Optional: nested_panel (for median ages under column strips)
# Outputs:
#   - gee_pairs_su (OR/CI/p per outcome × wave via emmeans)
#   - Console in-line stats (per outcome × wave; and 'any_bsd' main-effect ORs)
#   - Figure_08_GEE_OR_by_Cluster.pdf/.png

# ---- Config ----
OUT_SU   <- c("si_active","si_passive","sa","nssi")
OUT_LABS <- c(si_active="Active ideation",
              si_passive="Passive ideation",
              sa="Suicide attempt",
              nssi="NSSI")
wave_map   <- c("ses-02A"="Year-2","ses-04A"="Year-4")
wave_order <- c("Year-2","Year-4")
out_order  <- unname(OUT_LABS[OUT_SU])

fit_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/main_analysis/4_nested_suicidality_mixed_logit/rds"
fit_paths <- c(
  si_active  = file.path(fit_dir, "si_active_GEE_EXC_INT.rds"),
  si_passive = file.path(fit_dir, "si_passive_GEE_EXC_INT.rds"),
  sa         = file.path(fit_dir, "sa_GEE_EXC_INT.rds"),
  nssi       = file.path(fit_dir, "nssi_GEE_EXC_INT.rds")
)

safe_read <- function(p) tryCatch(readRDS(p), error = function(e) { message("Could not read: ", p); NULL })

# Wave medians for labels (fallback to em-dash if unavailable)
age_by_wave <- try({
  nested_panel %>%
    group_by(wave) %>%
    summarise(age_med = median(age_wave, na.rm = TRUE), .groups = "drop") %>%
    transmute(wave = as.character(wave),
              wave_pretty = recode(wave, !!!wave_map),
              lab = sprintf("%s\n(median age %.1f)", wave_pretty, age_med))
}, silent = TRUE)
if (inherits(age_by_wave, "try-error")) {
  age_by_wave <- tibble(wave = names(wave_map),
                        wave_pretty = unname(wave_map),
                        lab = paste0(unname(wave_map), "\n(median age —)"))
}
strip_labs <- setNames(age_by_wave$lab, age_by_wave$wave_pretty)

# ---- emmeans helper: C1 vs C2 per wave on logit scale -> OR -------------------
# Robust to factor-level order; uses the model’s vcov()
em_or_by_wave <- function(fit) {
  # marginal means on the LINK scale so differences = log-odds ratios
  emm <- emmeans::emmeans(fit, ~ cluster | wave, type = "link")
  lev <- levels(emm@grid$cluster)
  if (!all(c("C1","C2") %in% lev)) stop("Cluster levels not found in fit: ", paste(lev, collapse = ", "))

  w <- setNames(numeric(length(lev)), lev); w["C1"] <- 1; w["C2"] <- -1
  cmp <- emmeans::contrast(emm, method = list("C1 - C2" = w))   # one contrast per wave
  sm  <- summary(cmp, infer = TRUE)                             # on logit (link) scale

  tibble(
    wave     = as.character(sm$wave),
    OR       = exp(sm$estimate),
    CI_low   = exp(sm$lower.CL),
    CI_high  = exp(sm$upper.CL),
    p        = sm$p.value
  )
}

# ---- Extract 'any_bsd' main-effect OR (if present in the model) ---------------
extract_anybsd_or <- function(fit) {
  b <- coef(fit); V <- vcov(fit)
  nm <- names(b)
  idx <- grep("any_bsd", nm, ignore.case = TRUE)
  if (!length(idx)) return(NULL)
  nm <- nm[idx[1]]
  est <- unname(b[nm]); se <- sqrt(V[nm, nm, drop=TRUE])
  OR <- exp(est); lo <- OR * exp(-qnorm(0.975)*se); hi <- OR * exp(+qnorm(0.975)*se); p <- 2*pnorm(-abs(est/se))
  tibble(term = nm, OR = OR, CI_low = lo, CI_high = hi, p = p)
}

# ---- Run across outcomes ------------------------------------------------------
fits <- lapply(OUT_SU, \(o) safe_read(fit_paths[[o]])) |> setNames(OUT_SU)
ok_names <- names(Filter(Negate(is.null), fits))
message("Loaded fits: ", paste(ok_names, collapse = ", "))

if (!length(ok_names)) stop("No *_GEE_EXC_INT.rds models could be loaded.")

# Per-wave ORs (C1 vs C2) via emmeans
gee_pairs <- map_dfr(ok_names, function(o) {
  fit <- fits[[o]]
  or_tab <- em_or_by_wave(fit) %>%
    mutate(
      outcome     = o,
      out_lab     = OUT_LABS[[o]],
      wave_pretty = recode(wave, !!!wave_map)
    )
  or_tab
})

stopifnot(nrow(gee_pairs) > 0)

# 'any_bsd' lines
anybsd_tbl <- map_dfr(ok_names, function(o) {
  fit <- fits[[o]]
  ab  <- extract_anybsd_or(fit)
  if (is.null(ab)) return(NULL)
  ab %>% mutate(outcome = o, out_lab = OUT_LABS[[o]])
})

# ---- In-line stats ------------------------------------------------------------
fmt_p  <- function(p) ifelse(is.na(p), "-", ifelse(p < .001, "<.001", sprintf("%.3f", p)))
fmt_ci <- function(lo, hi) sprintf("%s–%s", sprintf("%.2f", lo), sprintf("%.2f", hi))

inline_lines <- gee_pairs %>%
  mutate(line = glue("{out_lab} {wave_pretty}: OR={sprintf('%.2f', OR)}, 95% CI {fmt_ci(CI_low, CI_high)}, p={fmt_p(p)}")) %>%
  arrange(factor(out_lab, levels = out_order), factor(wave_pretty, levels = wave_order)) %>%
  pull(line)

cat("Figure 8 in-line stats (Higher- vs Lower-Risk, emmeans, per wave):\n",
    paste0(" • ", inline_lines, collapse = "\n"), "\n\n")

if (nrow(anybsd_tbl)) {
  anybsd_lines <- anybsd_tbl %>%
    transmute(line = glue("{out_lab}: Any BSD at timepoint OR={sprintf('%.2f', OR)}, 95% CI {fmt_ci(CI_low, CI_high)}, p={fmt_p(p)}")) %>%
    pull(line)
  cat("Any-BSD effects (main effect in the GEE model):\n",
      paste0(" • ", anybsd_lines, collapse = "\n"), "\n\n")
} else {
  message("No 'any_bsd' term found in the loaded models (skipping those lines).")
}

# ---- Panel forest (linear axis 0–15; rows=outcomes, cols=Year-2/Year-4) -------
# Visual knobs you can tweak
ci_linewidth   <- 0.35
cap_linewidth  <- 0.28
cap_y          <- 1e-7
dot_size       <- 1.8
dot_color      <- "#7F3C8D"
arrow_len_mm   <- 1.5
col_spacing_pt <- 26
row_spacing_pt <- 0.5
tick_len_pt    <- 3
tick_color     <- "grey35"
x_min <- 0; x_max <- 8; x_brk <- c(0,2,4,6,8)

# Build plotting frame with truncation flags
plot_df <- gee_pairs %>%
  mutate(
    out_lab     = factor(out_lab,     levels = out_order),
    wave_pretty = factor(wave_pretty, levels = wave_order),
    x_low_plot   = pmax(CI_low,  x_min),
    x_high_plot  = pmin(CI_high, x_max),
    trunc_right  = CI_high > x_max + 1e-10,
    trunc_left   = CI_low  < x_min - 1e-10,
    x_or_plot    = pmin(pmax(OR, x_min), x_max)
  )

seg_ok    <- filter(plot_df, !trunc_right & !trunc_left)
seg_right <- filter(plot_df,  trunc_right & !trunc_left)
seg_left  <- filter(plot_df,  trunc_left  & !trunc_right)

# Theme (no grids; outcome labels on the left; ticks above numbers)
jamafy_linear <- function(base_size = 10,
                          col_spacing_pt = 26,
                          row_spacing_pt = 0.5,
                          strip_size = 9,
                          axis_title_x_size = 9,
                          axis_text_x_size  = 8,
                          tick_len_pt = 3,
                          tick_color  = "grey35") {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.text.x       = element_text(size = axis_text_x_size),
      axis.title.x      = element_text(size = axis_title_x_size, margin = margin(t = 6)),
      axis.ticks.x      = element_line(color = tick_color, linewidth = 0.3),
      axis.ticks.length = grid::unit(tick_len_pt, "pt"),
      axis.line.x       = element_blank(),
      axis.title.y      = element_blank(),
      axis.text.y       = element_blank(),
      axis.ticks.y      = element_blank(),
      strip.placement   = "outside",
      strip.text.x      = element_text(size = strip_size, face = "bold",
                                       lineheight = 1.05, margin = margin(b = 2)),
      strip.text.y.left = element_text(size = strip_size, face = "bold", angle = 0,
                                       margin = margin(r = 6)),
      strip.background  = element_blank(),
      panel.spacing.x   = grid::unit(col_spacing_pt, "pt"),
      panel.spacing.y   = grid::unit(row_spacing_pt, "pt"),
      legend.position   = "none"
    )
}

g8 <- ggplot(plot_df, aes(y = 0)) +
  geom_vline(xintercept = 1.0, linetype = 2, linewidth = 0.4, color = "grey40") +
  geom_segment(data = seg_ok,
               aes(x = x_low_plot, xend = x_high_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black") +
  geom_segment(data = seg_right,
               aes(x = x_low_plot, xend = x_high_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black",
               arrow = grid::arrow(type = "closed", length = grid::unit(arrow_len_mm, "mm"))) +
  geom_segment(data = seg_left,
               aes(x = x_high_plot, xend = x_low_plot, y = 0, yend = 0),
               linewidth = ci_linewidth, color = "black",
               arrow = grid::arrow(type = "closed", length = grid::unit(arrow_len_mm, "mm"))) +
  geom_segment(data = filter(plot_df, !trunc_left),
               aes(x = x_low_plot,  xend = x_low_plot,  y = -cap_y, yend =  cap_y),
               linewidth = cap_linewidth, color = "black") +
  geom_segment(data = filter(plot_df, !trunc_right),
               aes(x = x_high_plot, xend = x_high_plot, y = -cap_y, yend =  cap_y),
               linewidth = cap_linewidth, color = "black") +
  geom_point(aes(x = x_or_plot), size = dot_size, color = dot_color) +
  scale_x_continuous(limits = c(x_min, x_max), breaks = x_brk,
                     labels = scales::number_format(accuracy = 0.1, trim = TRUE)) +
  scale_y_continuous(NULL, breaks = NULL, limits = c(-0.05, 0.05), expand = expansion(mult = 0)) +
  facet_grid(rows = vars(out_lab),
             cols = vars(wave_pretty),
             switch = "y",
             labeller = labeller(wave_pretty = strip_labs)) +
  labs(x = "Odds Ratio") +
  jamafy_linear(col_spacing_pt = col_spacing_pt, row_spacing_pt = row_spacing_pt)

print(g8)

# ---- Save ---------------------------------------------------------------------
out_dir <- "/home/exacloud/gscratch/NagelLab/staff/sam/projects/ABCD_MDS_Risk/results/figures"
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
ggsave(file.path(out_dir, "Figure_08_GEE_OR_by_Cluster.pdf"), g8, width = 5.5, height = 4.5, device = cairo_pdf)
ggsave(file.path(out_dir, "Figure_08_GEE_OR_by_Cluster.png"), g8, width = 5.5, height = 4.5, dpi = 600)
message("Saved Figure 8 to:\n  ", file.path(out_dir, "Figure_08_GEE_OR_by_Cluster.pdf"),
        "\n  ", file.path(out_dir, "Figure_08_GEE_OR_by_Cluster.png"))

```

