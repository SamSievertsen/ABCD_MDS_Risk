---
title: "4. Feature Importance (k-prototypes)"
author: "Sam A. Sievertsen"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: false
    df_print: paged
params:
  mode: "auto"               # "auto" | "seed" | "aggregate" options to specify run mode
                                # "auto": run seed-level if SLURM_ARRAY_TASK_ID set, else aggregate
                                # "seed": run single seed (requires seed_index)
                                # "aggregate": run aggregation only
  seed_index: !r NULL        # used when mode == "seed" (1..n_seeds)
  k_opt: 2                   # optimal k to specify from previous analyses
  scaling: "z_score"         # documentation only; assumes pre-scaled data
  biter: 1000                # permutations per feature (MCR)
  n_seeds: 50
  stability_keep: 0.80       # >=80% seeds pass shadow-max (high-stringency subset, descriptive only)
  redundancy_rho: 0.80       # corr threshold for numeric redundancy
  redundancy_v: 0.80         # Cramer's V threshold for categorical redundancy
  shadow_B: 1000             # reps for global shadow-null baseline
  shadow_mode: "max"         # "max" or "q"
  shadow_q: 0.95             # only used when shadow_mode == "q"
  holm_alpha: 0.05           # overall alpha; used for FDR threshold in aggregate
  shadow_feat_B: 1000        # reps per feature for feature-specific shadow
  shadow_feat_mode: "max"    # "max" or "q" (quantile) for shadow feature-specific analysis
  shadow_feat_q: 0.95        # used when shadow_feat_mode == "q"
  save_feat_nulls: true      # set TRUE to write per-feature null vectors (RDS)
  biter_for_null: 1          # inner biter for shadow draws (1 = fast; set == biter for purist run)
  save_obs_mcr_draws: true   # persist observed MCR vectors per feature/seed for reuse
  xgb_nrounds: 600           # surrogate capacity (early stopping nested)
  xgb_cv_folds: 5
---

```{r global, include = FALSE}

# Set global env variables
knitr::opts_chunk$set(cache = FALSE, message = TRUE, warning = TRUE, results = "markup", verbose = TRUE, comment = "")

```

## Overview & Plan

This script implements the feature-importance pipeline for the k-prototypes clustering in a descriptive, geometry-first fashion:

* Centroid geometry: z-scored centroid profiles, Cohen’s d, and ANOVA-based separation per feature
* Collinearity diagnostics: correlation matrix to characterise correlated "blocks" (e.g., symptom burden)
* Visual separation: univariate densities and bivariate scatter/biplots with centroid overlays
* Permutation-based MCR: per-feature misclassification rates under leave-one-feature permutation, with Boruta-style shadow baselines
* Redundancy flags: simple correlation/Cramér’s V flags among features
* Surrogate triangulation: XGBoost + SHAP used only for descriptive corroboration/visualization, not as a hard selection gate

Re-clustering and explicit "minimal viable feature set" selection will be deferred to a dedicated follow-up script (`5_parsimonious_feature_selection.Rmd`), where subsets will be evaluated by how well they reproduce the full 17-feature solution (e.g., via ARI stability threshold). In the current script, all importance summaries (i.e., centroid separation, MCR, and SHAP) are treated as continuous characterizations of how features drive the 2-cluster geometry, with any high-stringency "keep" sets used for sensitivity descriptions rather than as the sole definition of "important" features

### 1. Setup & Environment

**Goal:** Load packages, create output paths, configure parallel workers from SLURM, initialize logging, and generate a reproducible seed list shared across array tasks. Also define IO helper(s)

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}

# Print a set-up init message
cat("Set-up beginning\n")

#1. Load packages & set config
#1.1 Suppress package startup noise and load required libraries
suppressPackageStartupMessages({
  library(here); 
  library(knitr);
  library(tibble);
  library(data.table); 
  library(magrittr);
  library(kableExtra);
  library(dplyr); 
  library(tidyr); 
  library(readr)
  library(ggplot2); 
  library(purrr); 
  library(stringr); 
  library(glue);
  library(clustMixType);
  library(FeatureImpCluster);
  library(DescTools); 
  library(effectsize);
  library(future.apply); 
  library(parallel);
  library(xgboost); 
  library(yardstick); 
  library(rsample); 
  library(shapviz);
  library(SHAPforxgboost);
  library(jsonlite); 
  library(inflection);
  library(corrplot);
  library(ggExtra)
})

#1.2 Define canonical project I/O paths
paths <- list(
  data_dir = here("data", "data_processed"),
  risk_csv = here("data", "data_processed", "risk_variable_data.csv"),
  kproto_rds = here("data", "data_processed", "kproto_results", "kproto_z_score.rds"),
  out_dir = here("results", "main_analysis", "1_clustering", "4_feature_importance"),
  seed_dir = here("results", "main_analysis", "1_clustering", "4_feature_importance", "seed_level"),
  sum_dir = here("results", "main_analysis", "1_clustering", "4_feature_importance", "summary"),
  fig_dir = here("results", "main_analysis", "1_clustering", "4_feature_importance", "figures"),
  shap_dir = here("results", "main_analysis", "1_clustering", "4_feature_importance", "shap"))

#1.3 Ensure output directories exist before writing artifacts
invisible(lapply(paths, dir.create, showWarnings = FALSE, recursive = TRUE))

#1.4 Configure parallel workers from SLURM env var or fallback to local cores
n_workers <- suppressWarnings(as.integer(Sys.getenv("SLURM_CPUS_PER_TASK")))
if (is.na(n_workers) || n_workers < 1) n_workers <- max(1, parallel::detectCores() - 1)
if (.Platform$OS.type == "windows") {
  future::plan("multisession", workers = n_workers)
} else {
  future::plan("multicore", workers = n_workers)
}

#1.5 Initialize logging helper (no-op unless $DETAILED_LOG is set)
log_file <- Sys.getenv("DETAILED_LOG", unset = NA)

#1.5.1 Evaluate glue in the caller's frame, and never crash the job on a log failure
.log <- function(text, .envir = parent.frame()) {
  if (is.na(log_file)) return(invisible())
  out <- try(glue::glue(text, .envir = .envir), silent = TRUE)
  if (inherits(out, "try-error")) {
    cat(paste0(format(Sys.time(), "%F %T"), "|LOG_ERR|", as.character(out)),
        file = log_file, sep = "\n", append = TRUE)
  } else {
    cat(out, file = log_file, sep = "\n", append = TRUE)
  }
}

#1.5.2 Log the start of the feature importance analysis
.log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FI_START|mode={params$mode}")

#1.6 Establish reproducible seed list shared across array tasks
seedfile <- file.path(paths$sum_dir, "seedlist.csv")

#1.6.1 Create seed list if missing
if (!file.exists(seedfile)) {
  set.seed(123)
  seeds <- sample.int(.Machine$integer.max, size = params$n_seeds)
  write_csv(tibble(idx = seq_along(seeds), seed = seeds), seedfile)
}

#1.7 Load the shared seed list
seed_tbl <- suppressMessages(readr::read_csv(seedfile, show_col_types = FALSE))

#1.8 Resolve seed for this run (params/SLURM/default)
get_seed <- function() {
  if (!is.null(params$seed_index)) return(seed_tbl$seed[[params$seed_index]])
  arr <- Sys.getenv("SLURM_ARRAY_TASK_ID")
  if (nzchar(arr)) return(seed_tbl$seed[[as.integer(arr)]])
  123L
}

#1.9 Safe CSV writer that ensures parent directory exists
write_csv2 <- function(x, path) { dir.create(dirname(path), TRUE, TRUE); readr::write_csv(x, path) }

#1.10 Print a successful env set-up message
cat("Set-up complete\n")

```

### 2. Data & Fitted Clustering Anchor

**Goal:** Load the cleaned baseline risk dataframe and the final fitted k-prototypes object (scaling currently = z_score, lambda from `lambdaest`). Compute baseline cluster assignments from the anchor model and coerce `risk_dt` column types to match the fitted object to ensure consistent distance calculations in downstream predictions

```{r load_data_and_utils, warning = FALSE, echo = FALSE}

#2. Load Data & Fitted Clustering Solution
#2.1 Load baseline risk dataset used in anchor model
raw_dt <- suppressMessages(readr::read_csv(paths$risk_csv, show_col_types = FALSE)) |> as.data.table()

#2.2 Load fitted k-prototypes anchor object (k, lambda)
#2.2.1 Establish k-prototypes path
kp_path <- paths$kproto_rds

#2.2.2 Check existence of k-prototypes RDS
if (!file.exists(kp_path)) {
  .log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FATAL|missing_kproto|{kp_path}")
  stop(glue("Required kproto RDS not found: {kp_path}"))
}

#2.2.3 Read k-prototypes and extract k, lambda
#2.2.3.1 Read k-prototypes object(s) and select the one for params$k_opt
kp_any <- readRDS(kp_path)

#2.2.3.2 Create a function to dynamically select the kproto object of interest
pick_kproto <- function(obj, k_target) {
  
  #2.2.3.2.1 Case 1: a single kproto object
  if (inherits(obj, "kproto")) return(obj)
  
  #2.2.3.2.2 Case 2: a list of kproto objects (e.g., named "k2","k3",...)
  stopifnot(is.list(obj))
  nm <- names(obj)
  
  #2.2.3.2.3 Prefer exact name match
  if (!is.null(nm)) {
    nm_hit <- paste0("k", k_target)
    if (nm_hit %in% nm && inherits(obj[[nm_hit]], "kproto")) return(obj[[nm_hit]])
  }
  
  #2.2.3.2.4 Fallback: first element whose cluster-count matches k_target
  for (el in obj) {
    if (inherits(el, "kproto")) {
      sz <- tryCatch(el$size, error = function(...) NULL)
      if (!is.null(sz) && length(sz) == k_target) return(el)
    }
  }
  stop(glue("Could not locate a k-prototypes object for k={k_target} in {kp_path}"))
}

#2.2.3.3 Select the desired kproto object and lambda used to generate clusters
kp0 <- pick_kproto(kp_any, params$k_opt)
k_opt <- params$k_opt
lambda_used <- tryCatch(kp0$lambda, error = function(...) NULL)
if (is.null(lambda_used) || is.na(lambda_used)) {
  message("kp0$lambda not found; estimating lambda from kp0$data via clustMixType::lambdaest().")
  lambda_used <- clustMixType::lambdaest(as.data.frame(kp0$data))
}

#2.2.3.4 Print stats RE the kproto object and parameters used
message(glue("Loaded k-prototypes (from list): k={k_opt}, lambda={round(lambda_used, 6)}"))

#2.3 Create a helper function to always return the cluster labels as an integer vector
predict_clusters <- function(kp, newdata) {
  pr <- predict(kp, newdata = newdata)
  if (is.list(pr)) pr$cluster else pr
}

#2.4 Canonicalize data to match the fitted k-prototypes object
#2.4.1 Use the exact matrix used at fit time previously
X_fit <- kp0$data
stopifnot(!is.null(X_fit), nrow(X_fit) > 0)

#2.4.2 Convert to data.table and add subject id from rownames -> ".id"
X_dt <- as.data.table(X_fit)
if (!is.null(rownames(X_fit))) {
  X_dt[, .id := rownames(X_fit)]
} else {
  
  #2.4.2.1 Fallback if the object has no rownames
  X_dt[, .id := sprintf("row%06d", seq_len(.N))]
}

#2.4.3 put .id first
data.table::setcolorder(X_dt, c(".id", setdiff(names(X_dt), ".id")))

#2.4.4 Features actually used by the clustering (drop .id)
features_used <- setdiff(names(X_dt), ".id")

#2.4.5 Make this the dataset for all predict() / FI steps
risk_dt <- X_dt

#2.4.6 Column metadata based on the canonical feature frame
num_cols <- names(Filter(is.numeric, risk_dt[, ..features_used]))
cat_cols <- setdiff(features_used, num_cols)

#2.4.7 Anchor assignments using the canonical feature frame
base_assign0 <- predict_clusters(kp0, risk_dt[, ..features_used])
stopifnot(length(base_assign0) == nrow(risk_dt))

#2.5 Sanity check: predict on kp0$data should match kp0$cluster almost perfectly (if overlap < 100%, that’s a data-prep issue, e.g., filters applied after clustering)
if (!is.null(kp0$cluster)) {
  agree <- mean(base_assign0 == kp0$cluster)
  cat(sprintf("Sanity: predict(kp0, kp0$data) agrees with kp0$cluster in %.1f%% of rows.", 100*agree))
}

```

### 3. Helper Functions

**Goal:** Implement reusable helpers aimed at the following:

* `permute_col()` - type-preserving permutation of a given variable used for cluster reassignment
* `feature_mcr()` - permutation MCR vs a base assignment for a single feature
* `shadow_baseline()` - global shadow baseline per seed
* `shadow_baseline_feat()` - shadow baseline for each feature
* `compute_redundancy()` - |rho| and Cramer's V flags for redundancy among retained features
* `centroid_profiles()` - descriptive numeric/categorical summaries for the centroid of each cluster

```{r helper_functions, echo = FALSE}

#3. Establish Helper Functions
#3.1 permute_col(): Type-preserving permutation of a vector
permute_col <- function(v) {
  if (is.factor(v)) return(sample(v, length(v), replace = FALSE))
  if (is.character(v)) return(sample(v, length(v), replace = FALSE))
  sample(v, length(v), replace = FALSE)
}

#3.2 feature_mcr(): permutation MCR via FeatureImpCluster::PermMisClassRate (shuffle, not i.i.d.)
feature_mcr <- function(kp, data_dt, base_assign, feat, biter = 1000L, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  #3.2.1 Ensure columns exactly match training frame
  dsub <- data_dt[, ..features_used]
  stopifnot(nrow(dsub) == length(base_assign))
  dsub <- align_newdata_to_model(kp, dsub)
  dsub <- as.data.table(dsub)

  v <- FeatureImpCluster::PermMisClassRate(
    clusterObj = kp,
    data = dsub,
    varName = feat,
    basePred = base_assign,
    predFUN = predFUN_kproto,
    sub = 1,
    biter = as.integer(biter),
    seed = if (is.null(seed)) 123L else as.integer(seed))
  list(mean = mean(v, na.rm = TRUE), sd = stats::sd(v, na.rm = TRUE), draws = v)
}

#3.3 shadow_baseline(): global Boruta-style shadow
shadow_baseline <- function(kp,
                            data_dt,
                            base_assign,
                            B = 500L,
                            mode = c("max", "q"),
                            q = 0.95,
                            seed = NULL,
                            biter_for_null = params$biter_for_null) {
  mode <- match.arg(mode)
  if (!is.null(seed))
    set.seed(seed + 101L)
  
  base <- data_dt[, ..features_used]
  stopifnot(nrow(base) == length(base_assign))
  
  vals <- future_sapply(seq_len(as.integer(B)), function(i) {
    f  <- sample(features_used, 1L)
    d0 <- data.table::copy(base)
    d0[[f]] <- permute_col(d0[[f]])
    
    #3.3.1 Align shadow frame to model + recompute base predictions on THIS frame
    d0a <- align_newdata_to_model(kp, d0)
    d0a <- as.data.table(d0a)
    base_shad <- predFUN_kproto(kp, d0a)
    
    v <- FeatureImpCluster::PermMisClassRate(
      clusterObj = kp,
      data = d0a,
      varName = f,
      basePred = base_shad,
      predFUN = predFUN_kproto,
      sub = 1,
      biter = as.integer(biter_for_null),
      seed = sample.int(.Machine$integer.max, 1L))
    mean(v, na.rm = TRUE)
  }, future.seed = TRUE)
  
  thr <- if (identical(mode, "max"))
    max(vals, na.rm = TRUE)
  else
    as.numeric(stats::quantile(vals, q, na.rm = TRUE))
  list(thresh = thr, vals = vals)
}

#3.4 shadow_baseline_feat(): feature-specific Boruta-style shadow
shadow_baseline_feat <- function(kp, data_dt, base_assign,
                                 feat,
                                 B = 200L,
                                 mode = c("max", "q"), q = 0.95,
                                 seed = NULL,
                                 biter_for_null = params$biter_for_null) {
  mode <- match.arg(mode)
  if (!is.null(seed)) set.seed(seed + 303L)

  base <- data_dt[, ..features_used]
  stopifnot(nrow(base) == length(base_assign))

  vals <- future_sapply(seq_len(as.integer(B)), function(i) {
    d0 <- data.table::copy(base)
    d0[[feat]] <- permute_col(d0[[feat]])

    #3.4.1 Align shadow frame to model + recompute base predictions on THIS frame
    d0a <- align_newdata_to_model(kp, d0)
    d0a <- as.data.table(d0a)
    base_shad <- predFUN_kproto(kp, d0a)

    v <- FeatureImpCluster::PermMisClassRate(
      clusterObj = kp,
      data = d0a,
      varName = feat,
      basePred = base_shad,
      predFUN = predFUN_kproto,
      sub = 1,
      biter = as.integer(biter_for_null),
      seed = sample.int(.Machine$integer.max, 1L))
    mean(v, na.rm = TRUE)
  }, future.seed = TRUE)

  thr <- if (identical(mode, "max")) max(vals, na.rm = TRUE)
  else as.numeric(stats::quantile(vals, q, na.rm = TRUE))
  list(thresh = thr,
       mean = mean(vals, na.rm = TRUE),
       sd = stats::sd(vals, na.rm = TRUE),
       vals = vals)
}

#3.5 Compute_redundancy(): Flag numeric/categorical redundancy among retained features
compute_redundancy <- function(dt, rho_cut = 0.80, v_cut = 0.80) {
  nn <- NULL
  cc <- NULL
  if (length(num_cols) >= 2) {
    corM <- suppressWarnings(cor(dt[, ..num_cols], method = "spearman", use = "pairwise.complete.obs"))
    nn <- as.data.frame(as.table(corM), stringsAsFactors = FALSE) |>
      filter(Var1 < Var2, abs(Freq) > rho_cut) |>
      transmute(
        var1 = Var1,
        var2 = Var2,
        metric = "|rho|",
        value = abs(Freq))
  }
  
  if (length(cat_cols) >= 2) {
    pairs <- t(combn(cat_cols, 2))
    cv <- future_apply(pairs, 1, function(p) {
      v <- suppressWarnings(DescTools::CramerV(table(dt[[p[1]]], dt[[p[2]]]), bias.correct = TRUE))
      c(var1 = p[1],
        var2 = p[2],
        value = v)
    })
    cc <- as_tibble(t(cv)) |> mutate(metric = "V", value = as.numeric(value)) |> filter(value > v_cut)
  }
  bind_rows(nn, cc)
}

#3.6 centroid_profiles(): Descriptive numeric/categorical centroid summaries (scaled space)
centroid_profiles <- function(kp, dt_scaled) {
  cl <- factor(base_assign0)

  #3.6.1 Numeric summaries per cluster (on scaled data)
  num_s <- NULL
  if (length(num_cols) > 0) {
    num_s <- dt_scaled[, ..num_cols] |>
      mutate(.cluster = cl) |>
      tidyr::pivot_longer(-.cluster, names_to = "feature", values_to = "value") |>
      dplyr::group_by(.cluster, feature) |>
      dplyr::summarise(
        mean = mean(value, na.rm = TRUE),
        sd = sd(value, na.rm = TRUE),
        .groups = "drop")

    #3.6.2 Global reference mean/SD per feature (on the same scaled data used for clustering)
    gref <- dt_scaled[, ..num_cols] |>
      tidyr::pivot_longer(dplyr::everything(), names_to = "feature", values_to = "value") |>
      dplyr::group_by(feature) |>
      dplyr::summarise(
        mu_ref = mean(value, na.rm = TRUE),
        sd_ref = sd(value, na.rm = TRUE),
        .groups = "drop")

    #3.6.3 Largest pairwise Cohen's d per feature (scale-invariant)
    d_tab <- lapply(num_cols, function(f) {
      lv <- levels(cl)
      if (length(lv) < 2) return(NULL)
      combs <- t(combn(lv, 2))
      ds <- apply(combs, 1, function(pair) {
        effectsize::cohens_d(dt_scaled[[f]][cl == pair[1]],
                             dt_scaled[[f]][cl == pair[2]],
                             pooled_sd = TRUE,
                             hedges.correction = TRUE)$Cohens_d
      })
      
      tibble::tibble(feature = f, max_cohens_d = max(abs(ds), na.rm = TRUE))
    }) |> dplyr::bind_rows()
    num_s <- num_s |>
      dplyr::left_join(gref, by = "feature") |>
      dplyr::left_join(d_tab, by = "feature") |>
      dplyr::mutate(z_ref = dplyr::if_else(sd_ref > 0, (mean - mu_ref) / sd_ref, 0))
  }

  #3.6.4 Categorical summaries per cluster (robust)
  cat_s <- NULL
  if (length(cat_cols) > 0) {
    cat_s <- lapply(cat_cols, function(f) {
      tab <- table(dt_scaled[[f]], cl, useNA = "no")

      #3.6.4.1 Compute (mode, prop) per cluster column with explicit names
      M <- sapply(seq_len(ncol(tab)), function(j) {
        col <- tab[, j]
        den <- sum(col)
        if (den == 0) {
          mode_val <- NA_character_
          prop_val <- NA_real_
        } else {
          i <- which.max(col)
          mode_val <- rownames(tab)[i]
          prop_val <- as.numeric(col[i] / den)
        }
        c(mode = mode_val, prop = prop_val)
      })

      #3.6.4.2 Ensure matrix shape, set names, and build data frame
      if (is.null(dim(M))) M <- matrix(M, nrow = 2,
                                       dimnames = list(c("mode","prop"), colnames(tab)))
      df <- as.data.frame(t(M), stringsAsFactors = FALSE)
      names(df) <- c("mode","prop")
      df$prop <- as.numeric(df$prop)
      df$.cluster <- rownames(df)
      df$feature <- f
      rownames(df) <- NULL
      df[, c(".cluster","feature","mode","prop")]
    }) |> dplyr::bind_rows()
  }

  list(numeric = num_s, categorical = cat_s)
}

#3.7 predFUN wrapper for FeatureImpCluster (k-prototypes -> integer labels)
predFUN_kproto <- function(clusterObj, newdata) {
  nd <- align_newdata_to_model(clusterObj, newdata)
  pr <- predict(clusterObj, newdata = nd)
  if (is.list(pr)) pr$cluster else pr
}

#3.8 align_newdata_to_model(): coerce types/levels to match fitted kp$data
align_newdata_to_model <- function(model, newdata) {
  X <- as.data.frame(model$data)
  Y <- as.data.frame(newdata)
  common <- intersect(names(X), names(Y))
  for (nm in common) {
    if (is.factor(X[[nm]])) {
      
      #3.8.1 Force identical levels/order
      Y[[nm]] <- factor(as.character(Y[[nm]]), levels = levels(X[[nm]]))
    } else if (is.numeric(X[[nm]]) && !is.numeric(Y[[nm]])) {
      Y[[nm]] <- suppressWarnings(as.numeric(Y[[nm]]))
    }
  }
  Y
}

```

### 4. Descriptive Centroid Profiles

**Goal:** Compute and save descriptive centroid profiles (numeric means/SDs and categorical modes/proportions) for reference, then summarise geometry-based separation and add collinearity + visual diagnostics

```{r centroid_profiles, message = FALSE, warning = FALSE, echo = FALSE}

#4. Profile the centroids of the anchor clustering solution
#4.1 Compute centroid summaries and write numeric/categorical tables
cents <- centroid_profiles(kp0, risk_dt)
readr::write_csv(cents$numeric, file.path(paths$sum_dir, "centroids_numeric.csv"))
readr::write_csv(cents$categorical, file.path(paths$sum_dir, "centroids_categorical.csv"))

#4.2 Plot centroid profiles
#4.2.1 Numeric centroid heatmap of features by |max d|
if (!is.null(cents$numeric) && nrow(cents$numeric) > 0) {
  num_tab <- cents$numeric

  #4.2.1.1 Top features by |max d|
  top_feats_tbl <- num_tab |>
    dplyr::distinct(feature, max_cohens_d) |>
    dplyr::slice_max(order_by = max_cohens_d, n = 34, with_ties = FALSE)
  top_feats <- top_feats_tbl$feature
  
  #4.2.1.2 Filter to top features and reorder by effect size
  p_num <- num_tab |>
    dplyr::filter(feature %in% top_feats) |>
    dplyr::mutate(feature = reorder(feature, -max_cohens_d)) |>
  
    #4.2.1.3 Create heatmap with z-scores and diverging color scale
    ggplot2::ggplot(ggplot2::aes(x = feature, y = .cluster, fill = z_ref)) +
    ggplot2::geom_tile() +
    ggplot2::scale_fill_gradient2(name = "z (vs global SD)", limits = c(-3, 3)) +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "Centroid profiles (scaled) by |max d|",
                  x = NULL, y = "Cluster") +
    ggplot2::theme_minimal(base_size = 11)
    
  #4.2.1.4 Save heatmap to file
  ggplot2::ggsave(file.path(paths$fig_dir, "centroids_numeric_heatmap.png"),
                  p_num, width = 8, height = 8, dpi = 300)
}

#4.2.2 Categorical centroid heatmap of modal value and its proportion per cluster
if (!is.null(cents$categorical) && nrow(cents$categorical) > 0) {
  cat_tab <- cents$categorical |>
    mutate(.cluster = factor(.cluster))

  #4.2.2.1 Plot categorical heatmap
  p_cat <- ggplot(cat_tab, aes(x = feature, y = .cluster, fill = prop)) +
    geom_tile() +
    geom_text(aes(label = mode), size = 3) +
    scale_fill_continuous(name = "Modal proportion", limits = c(0, 1)) +
    coord_flip() +
    labs(title = "Centroid profiles (categorical): modal value & proportion",
         x = NULL, y = "Cluster") +
    theme_minimal(base_size = 11)
  ggsave(file.path(paths$fig_dir, "centroids_categorical_heatmap.png"),
         p_cat, width = 8, height = 8, dpi = 300)
}

```

#### 4a. Centroid Geometry

**Goal:** Quantify how far apart the clusters sit along each numeric feature in the z-scored space (delta-z, Cohen’s d, and ANOVA p-values) and rank features by geometry-based separation to inform later visualization and interpretation

```{r centroid_geometry, message = FALSE, warning = FALSE, echo = FALSE}

#4.3 Geometry-based centroid separation summary (delta-z & ANOVA per feature)
if (!is.null(cents$numeric) && nrow(cents$numeric) > 0 && length(num_cols) > 0) {
  
  num_tab <- cents$numeric
  
  #4.3.1 For each feature, compute max/min z_ref across clusters and their difference
  centroid_sep <- num_tab |>
    dplyr::group_by(feature) |>
    dplyr::summarise(
      max_z = max(z_ref, na.rm = TRUE),
      min_z = min(z_ref, na.rm = TRUE),
      delta_z = max_z - min_z,
      max_cohens_d = max(max_cohens_d, na.rm = TRUE),
      .groups = "drop")
  
  #4.3.2 ANOVA per feature: value ~ cluster (using the scaled data)
  geom_df <- risk_dt[, ..num_cols] |>
    as_tibble() |>
    dplyr::mutate(.cluster = factor(base_assign0))
  
  #4.3.2.1 Pivot the ANOVA per feature data to long format
  long_df <- geom_df |>
    tidyr::pivot_longer(cols = all_of(num_cols),
                        names_to = "feature",
                        values_to = "value")
  
  #4.3.2.2 Create a tabular summary of the ANOVA per feature analysis data
  anova_tab <- long_df |>
    dplyr::group_by(feature) |>
    dplyr::summarise(
      p_anova = tryCatch({
        s <- summary(stats::aov(value ~ .cluster))
        as.numeric(s[[1]][["Pr(>F)"]][1])
      }, error = function(e) NA_real_),
      .groups = "drop")
  
  #4.3.2.3 Create a readable centroid separability table by risk feature
  centroid_sep <- centroid_sep |>
    dplyr::left_join(anova_tab, by = "feature") |>
    dplyr::mutate(
      p_anova_fdr = ifelse(is.na(p_anova), NA_real_, p.adjust(p_anova, method = "BH"))) |>
    dplyr::arrange(dplyr::desc(abs(delta_z)))
  
  #4.3.3 Write centroid separation summary to CSV
  write_csv2(centroid_sep, file.path(paths$sum_dir, "centroid_separation_summary.csv"))
  
  #4.3.4 Plot ranked |delta z| (geometry-based separation)
  top_n_plot <- min(34L, nrow(centroid_sep))
  if (top_n_plot > 0) {
    p_sep <- centroid_sep |>
      dplyr::slice_max(order_by = abs(delta_z), n = top_n_plot, with_ties = FALSE) |>
      dplyr::mutate(feature = reorder(feature, abs(delta_z))) |>
      ggplot2::ggplot(ggplot2::aes(x = feature, y = delta_z)) +
      ggplot2::geom_hline(yintercept = 0, linetype = 2, color = "grey60") +
      ggplot2::geom_point() +
      ggplot2::coord_flip() +
      ggplot2::labs(
        x = NULL,
        y = "Centroid separation (max_z - min_z, scaled units)",
        title = "Geometry-based centroid separation by feature") +
      ggplot2::theme_minimal(base_size = 11)
    ggplot2::ggsave(file.path(paths$fig_dir, "centroid_separation_ranked.png"),
                    p_sep, width = 7, height = 8, dpi = 300)
  }
}

```

#### 4b. Correlation Diagnostics

**Goal:** Characterize the correlation/collinearity structure among the 17 risk features, highlighting correlated “blocks” (e.g., symptom burden) that may behave interchangeably in permutation and SHAP analyses

```{r correlation_diagnostics, message = FALSE, warning = FALSE, echo = FALSE}

#4.4 Correlation diagnostics (collinearity among risk features)
if (length(features_used) > 1) {
  risk_df_all <- as.data.frame(risk_dt[, ..features_used])
  
  #4.4.1 Coerce factors to numeric codes for a simple, uniform corrplot
  risk_corr <- risk_df_all |>
    dplyr::mutate(dplyr::across(where(is.factor), ~ as.numeric(.)))
  
  #4.4.2 Compute Pearson correlation matrix (EDA, not inferential)
  cmat <- suppressWarnings(cor(risk_corr,
                               use = "pairwise.complete.obs",
                               method = "pearson"))
  
  #4.4.3 Save correlation matrix to CSV
  cmat_df <- as.data.frame(cmat)
  cmat_df <- tibble::rownames_to_column(cmat_df, var = "feature")
  write_csv2(cmat_df,
             file.path(paths$sum_dir, "correlation_matrix_all_features.csv"))
  
  #4.4.4 Corrplot heatmap (red–white–blue)
  png(file.path(paths$fig_dir, "correlation_matrix_all_features.png"),
      width = 8, height = 8, units = "in", res = 300)
  corrplot::corrplot(cmat,
                     method = "color",
                     diag = FALSE,
                     type = "lower",
                     addCoef.col = "black",
                     number.cex = 0.5,
                     tl.col = "black",
                     tl.cex = 0.6,
                     mar = c(0, 0, 1, 0),
                     title = "Correlation matrix (all 17 risk features)")
  dev.off()
}

```

#### 4c. Visual Separation Diagnostics 

**Goal:** Provide a visual sanity check that clusters separate in 1D/2D space along the top numeric features, using univariate densities, bivariate scatterplots with centroids, and a PCA view to complement the centroid and MCR rankings


```{r visual_separation_diagnostics, message = FALSE, warning = FALSE, echo = FALSE}

#4.5 Visual separation diagnostics (univariate and bivariate)
if (!is.null(cents$numeric) && nrow(cents$numeric) > 0 && length(num_cols) > 0) {
  
  #4.5.1 Use centroid-based separation to pick numeric features (all, ranked)
  if (exists("centroid_sep")) {
    sep_tbl <- centroid_sep
  } else {
    
    #4.5.1.1 Fallback: derive a minimal version if centroid_sep is not in scope
    num_tab <- cents$numeric
    sep_tbl <- num_tab |>
      dplyr::group_by(feature) |>
      dplyr::summarise(
        max_z = max(z_ref, na.rm = TRUE),
        min_z = min(z_ref, na.rm = TRUE),
        delta_z = max_z - min_z,
        max_cohens_d = max(max_cohens_d, na.rm = TRUE),
        .groups = "drop")
  }
  
  sep_tbl <- sep_tbl |>
    dplyr::filter(feature %in% num_cols) |>
    dplyr::arrange(dplyr::desc(abs(delta_z)))
  
  #4.5.1.2 Univariate: use *all* numeric risk features (ranked by |delta_z|)
  top_univ <- sep_tbl$feature
  
  #4.5.1.3 Bivariate: anchor on top 3 most separable features, pair each with all others
  all_feats <- sep_tbl$feature
  anchor_feats <- head(all_feats, min(3L, length(all_feats)))
  
  pair_list <- list()
  seen_keys <- character(0)
  
  #4.5.1.4 Build unique anchor-vs-other pairs (no duplicate A–B and B–A)
  for (a in anchor_feats) {
    for (b in all_feats) {
      if (identical(a, b)) next
      key <- paste(sort(c(a, b)), collapse = "__")
      if (key %in% seen_keys) next
      seen_keys <- c(seen_keys, key)
      pair_list[[length(pair_list) + 1L]] <- c(a, b)
    }
  }
  
  #4.5.2 Long-form numeric data with cluster labels
  df_num <- risk_dt[, ..num_cols] |>
    as_tibble() |>
    dplyr::mutate(.cluster = factor(base_assign0))
  
  #4.5.2.1 Define a consistent cluster color palette (Cluster 1 = red, Cluster 2 = muted grey)
  cl_lev <- levels(df_num$.cluster)
  if (length(cl_lev) == 2 && all(c("1","2") %in% cl_lev)) {
    cluster_cols <- c(
      "1" = "#11A579",
      "2" = "#7F3C8D")
  } else {
    
    #4.5.2.1.1 Fallback: generic palette if labels are not "1"/"2"
    cluster_cols <- stats::setNames(ggplot2::hue_pal()(length(cl_lev)), cl_lev)
  }
  
  #4.5.3 Univariate density plots by cluster for all numeric features
  if (length(top_univ) > 0) {
    for (f in top_univ) {

      #4.5.3.1 Split data once per feature for clarity of layering
      df1 <- df_num[df_num$.cluster == "1", , drop = FALSE]
      df2 <- df_num[df_num$.cluster == "2", , drop = FALSE]

      p_uni <- ggplot2::ggplot(mapping = ggplot2::aes(x = .data[[f]])) +
        
        #4.5.3.1.1 Draw Cluster 2 first (background, lower alpha)
        ggplot2::geom_density(
          data = df2,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["2"],
          alpha = 0.25,
          adjust = 1.0,
          position = "identity") +
        
        #4.5.3.1.2 Draw Cluster 1 second (foreground, higher alpha)
        ggplot2::geom_density(
          data = df1,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["1"],
          alpha = 0.55,
          adjust = 1.0,
          position = "identity") +
        ggplot2::geom_rug(
          data = df_num,
          alpha = 0.15,
          sides = "b") +
        ggplot2::labs(
          x = glue::glue("{f} (scaled)"),
          y = "Scaled density (per cluster)",
          fill = "Cluster",
          title = glue::glue("Univariate density of {f} by cluster")) +
        ggplot2::scale_fill_manual(values = cluster_cols, drop = FALSE) +
        ggplot2::theme_classic(base_size = 11) +
        ggplot2::theme(
          panel.grid = ggplot2::element_blank(),
          axis.line = ggplot2::element_line(color = "black"),
          axis.ticks = ggplot2::element_line(color = "black"))

      #4.5.3.1 Save and print univariate density plot
      ggplot2::ggsave(
        file.path(paths$fig_dir, glue::glue("univariate_density_{f}.png")),
        p_uni, width = 6, height = 4, dpi = 300)
      print(p_uni)
    }
  }
  
  #4.5.4 Bivariate scatter + centroids + marginal scaled densities (built via patchwork)
  if (length(pair_list) > 0) {
    for (pair in pair_list) {
      f1 <- pair[1]; f2 <- pair[2]
      
      #4.5.4.1 Base scatter with centroids in feature space
      centers2d <- df_num |>
        dplyr::group_by(.cluster) |>
        dplyr::summarise(
          !!f1 := mean(.data[[f1]], na.rm = TRUE),
          !!f2 := mean(.data[[f2]], na.rm = TRUE),
          .groups = "drop")
      
      p_bi <- ggplot2::ggplot(
        df_num,
        ggplot2::aes(x = .data[[f1]], y = .data[[f2]], color = .cluster)) +
        ggplot2::geom_point(alpha = 0.25, size = 1) +
        ggplot2::geom_point(
          data = centers2d,
          size = 3,
          shape = 8,
          stroke = 1.1) +
        ggplot2::scale_color_manual(values = cluster_cols, drop = FALSE) +
        ggplot2::labs(
          x = glue::glue("{f1} (scaled)"),
          y = glue::glue("{f2} (scaled)"),
          color = "Cluster",
          title = glue::glue("Bivariate separation: {f1} vs {f2} with centroids")) +
        ggplot2::theme_classic(base_size = 11) +
        ggplot2::theme(
          panel.grid = ggplot2::element_blank(),
          axis.line = ggplot2::element_line(color = "black"),
          axis.ticks = ggplot2::element_line(color = "black"))
      
      #4.5.4.2 Top marginal: scaled density of f1 by cluster (no axis labels)
      df1 <- df_num[df_num$.cluster == "1", , drop = FALSE]
      df2 <- df_num[df_num$.cluster == "2", , drop = FALSE]

      p_xdens <- ggplot2::ggplot(mapping = ggplot2::aes(x = .data[[f1]])) +
        ggplot2::geom_density(
          data = df2,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["2"],
          alpha = 0.25,
          adjust = 1.0,
          position = "identity") +
        ggplot2::geom_density(
          data = df1,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["1"],
          alpha = 0.55,
          adjust = 1.0,
          position = "identity") +
        ggplot2::labs(x = NULL, y = NULL) +
        ggplot2::theme_classic(base_size = 8) +
        ggplot2::theme(
          axis.text.x = ggplot2::element_blank(),
          axis.text.y = ggplot2::element_blank(),
          axis.title.x = ggplot2::element_blank(),
          axis.title.y = ggplot2::element_blank(),
          axis.ticks.x = ggplot2::element_blank(),
          axis.ticks.y = ggplot2::element_blank(),
          legend.position = "none",
          panel.grid = ggplot2::element_blank())

      #4.5.4.3 Right marginal: scaled density of f2 by cluster (flipped, no axis labels)
      p_ydens <- ggplot2::ggplot(mapping = ggplot2::aes(x = .data[[f2]])) +
        ggplot2::geom_density(
          data = df2,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["2"],
          alpha = 0.25,
          adjust = 1.0,
          position = "identity") +
        ggplot2::geom_density(
          data = df1,
          mapping = ggplot2::aes(y = ggplot2::after_stat(scaled)),
          fill = cluster_cols["1"],
          alpha = 0.55,
          adjust = 1.0,
          position = "identity") +
        ggplot2::coord_flip() +
        ggplot2::labs(x = NULL, y = NULL) +
        ggplot2::theme_classic(base_size = 8) +
        ggplot2::theme(
          axis.text.x = ggplot2::element_blank(),
          axis.text.y = ggplot2::element_blank(),
          axis.title.x = ggplot2::element_blank(),
          axis.title.y = ggplot2::element_blank(),
          axis.ticks.x = ggplot2::element_blank(),
          axis.ticks.y = ggplot2::element_blank(),
          legend.position = "none",
          panel.grid = ggplot2::element_blank())
      
      #4.5.4.4 Assemble scatter + marginals into one plot
      p_comb <- (p_xdens + patchwork::plot_spacer()) /
        (p_bi + p_ydens) +
        patchwork::plot_layout(
          heights = c(0.7, 3.3),
          widths  = c(3.3, 0.7))
      
      #4.5.4.5 Save and print bivariate plot with marginals
      fname <- glue::glue("biplot_{f1}_vs_{f2}_with_centroids.png")
      ggplot2::ggsave(
        file.path(paths$fig_dir, fname),
        p_comb, width = 6, height = 6, dpi = 300)
      print(p_comb)
    }
  }
  
  #4.5.5 PCA view of overall 17D geometry (unchanged, but now also printed)
  if (length(num_cols) >= 2) {
    pca_obj <- stats::prcomp(df_num[, num_cols], scale. = FALSE)
    pca_scores <- as_tibble(pca_obj$x[, 1:2, drop = FALSE]) |>
      dplyr::mutate(.cluster = factor(base_assign0))
    
    p_pca <- ggplot2::ggplot(
      pca_scores,
      ggplot2::aes(x = PC1, y = PC2, color = .cluster)) +
      ggplot2::geom_point(alpha = 0.3, size = 1) +
      ggplot2::scale_color_manual(values = cluster_cols, drop = FALSE) +
      ggplot2::labs(
        x = "PC1",
        y = "PC2",
        color = "Cluster",
        title = "PCA of risk feature space (PC1 vs PC2)") +
      ggplot2::theme_minimal(base_size = 11)
    
    ggplot2::ggsave(
      file.path(paths$fig_dir, "pca_clusters_pc1_pc2.png"),
      p_pca, width = 6, height = 5, dpi = 300)
    print(p_pca)
  }
}

```

### 5. Seed-Level Importance Array Task

**Goal:** For a given seed, re-fit k-prototypes (same k, lambda, nstart), compute per-feature MCR with `biter` permutations, evaluate the shadow-max threshold, and emit a per-seed CSV. These are treated as continuous descriptive measures of how sensitive the cluster labels are to perturbations of each feature, not as a sole keep/drop gate for said risk features

```{r feature_importance, message = FALSE, echo = FALSE, warning = FALSE}

#5. Seed-Level Feature Importance
#5.1 Define run_seed(): fit k-prototypes for this seed and compute MCRs
run_seed <- function(seed_idx) {

  #5.1.1 Resolve and set seed for reproducibility of this run
  seed <- seed_tbl$seed[[seed_idx]]
  stopifnot(!is.na(seed))
  set.seed(seed)

  #5.1.2 Refit k-prototypes for this seed and use its own assignments as the base
  kp <- kproto(x = risk_dt[, ..features_used], k = params$k_opt, lambda = lambda_used,
               nstart = 8, verbose = FALSE)
  base_assign <- predict_clusters(kp, risk_dt[, ..features_used])
  
  #5.1.2.1 Guard to ensure basePred equals predFUN(as.data.frame(data)) for the same frame
  nd0 <- align_newdata_to_model(kp, risk_dt[, ..features_used])
  
  #5.1.2.2 Overwrite base_assign with the exact form PermMisClassRate will compare against
  base_assign <- predFUN_kproto(kp, nd0)
  
  #5.1.2.3 Sanity: base_assign must equal predFUN on the aligned frame
  stopifnot(identical(base_assign, predFUN_kproto(kp, nd0)))

  #5.1.3 Compute per-feature permutation MCRs (independent RNG per feature)
  feat_list <- features_used
  mcr_res <- future_lapply(seq_along(feat_list), function(j) {
    f <- feat_list[j]
    feature_mcr(kp, risk_dt, base_assign, f, biter = params$biter, seed = seed + j)
  })
  mcr_df <- tibble(
    feature = feat_list,
    mcr_mean = sapply(mcr_res, `[[`, "mean"),
    mcr_sd = sapply(mcr_res, `[[`, "sd"))

  #5.1.3.1 Persist observed MCR draws (per-feature vectors of length = biter)
  if (isTRUE(params$save_obs_mcr_draws)) {
    obs_draws <- setNames(lapply(mcr_res, `[[`, "draws"), feat_list)
    rds_path_obs <- file.path(paths$seed_dir, glue::glue("observed_mcr_draws_seed{seed_idx}.rds"))
    saveRDS(obs_draws, rds_path_obs)
  }

  #5.1.4 Global shadow baseline (used descriptively; feature-specific shadows carry most weight)
  sb <- shadow_baseline(
    kp, risk_dt, base_assign,
    B = params$shadow_B, mode = params$shadow_mode, q = params$shadow_q, seed = seed)
  mcr_df <- mcr_df |>
    mutate(shadow_thr = sb$thresh,
           pass_shadow = mcr_mean > shadow_thr,
           shadow_mode = params$shadow_mode,
           shadow_q = params$shadow_q)
  
  #5.1.5 Feature-specific shadow thresholds + pass flags (more nuanced than global shadow signal)
  #5.1.5.1 Establish feature-specific list with relevant information
  sb_feat_list <- future_lapply(feat_list, function(f) {
    shadow_baseline_feat(
      kp, risk_dt, base_assign,
      feat = f,
      B = params$shadow_feat_B,
      mode = params$shadow_feat_mode,
      q = params$shadow_feat_q,
      seed = seed)
  })

  #5.1.5.2 Bind feature-specific shadow summaries
  mcr_df$shadow_thr_feat <- vapply(sb_feat_list, `[[`, numeric(1), "thresh")
  mcr_df$null_mean_feat <- vapply(sb_feat_list, `[[`, numeric(1), "mean")
  mcr_df$null_sd_feat <- vapply(sb_feat_list, `[[`, numeric(1), "sd")
  mcr_df$pass_shadow_feat <- mcr_df$mcr_mean > mcr_df$shadow_thr_feat

  #5.1.5.3 Persist raw per-feature null vectors (heavy; off by default)
  if (isTRUE(params$save_feat_nulls)) {
    rds_path <- file.path(paths$seed_dir, glue::glue("feature_spec_mcr_nulls_seed{seed_idx}.rds"))
    saveRDS(sb_feat_list, rds_path)
  }
  
  #5.1.6 Empirical p-values (reuse feature-specific shadow draws; no extra loops)
  mcr_df$p_emp <- vapply(seq_len(nrow(mcr_df)), function(i) {
    
    #5.1.6.1 Shadow(f) draws with pre-permute
    vals <- sb_feat_list[[i]]$vals
    
    #5.1.6.2 Observed = mean MCR after permuting real f
    obs <- mcr_df$mcr_mean[i]
    (1 + sum(vals >= obs, na.rm = TRUE)) / (length(vals) + 1)
  }, numeric(1))
  mcr_df$p_emp_fdr <- p.adjust(mcr_df$p_emp, method = "BH")

  #5.1.7 Save seed-level outputs and session info
  mcr_df <- mcr_df |>
    mutate(
      mcr_biter = params$biter,
      shadow_feat_B = params$shadow_feat_B,
      biter_for_null = params$biter_for_null,
      shadow_B_global = params$shadow_B)
  out <- mcr_df |> arrange(desc(mcr_mean)) |> mutate(seed_idx = seed_idx, seed = seed)
  outfile <- file.path(paths$seed_dir, glue("feature_importance_seed{seed_idx}.csv"))
  write_csv2(out, outfile)

  #5.1.8 Log session run
  sess <- utils::sessionInfo()
  cat(capture.output(print(sess)), sep = "\n",
      file = file.path(paths$seed_dir, glue("session_seed{seed_idx}.txt")))
  .log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FI_SEED_DONE|{seed_idx}|seed={seed}")
  invisible(out)
}

```

### 6. Dispatch Seed Array Job

**Goal:** Run a single-seed task when launched as a SLURM array job, or iterate all seeds locally when testing without SLURM. Array tasks exit early after writing their outputs

```{r feature_importance_run, message = FALSE, warning = FALSE, echo = FALSE}

#6. Stability selection (descriptive MCR stability across seeds)
#6.1 Dispatch based on params$mode and SLURM_ARRAY_TASK_ID
if (params$mode %in% c("auto", "seed")) {

  if (identical(params$mode, "seed") || nzchar(Sys.getenv("SLURM_ARRAY_TASK_ID"))) {

    #6.1.1 Seed/array mode: run a single seed then exit
    idx_env <- as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID"))
    idx <- if (!is.null(params$seed_index)) params$seed_index else idx_env
    stopifnot(!is.na(idx), idx >= 1L, idx <= params$n_seeds)
    run_seed(idx)
    knitr::knit_exit()
  } else {

    #6.1.2 Local/auto mode: iterate all seeds sequentially
    invisible(lapply(seq_len(params$n_seeds), run_seed))
  }
}

```

### 7. Aggregate & Descriptive MCR Summary

**Goal:** Aggregate per-seed outputs to compute mean MCR, SD, and win-rate (fraction of seeds where MCR exceeds feature-specific shadow thresholds). Treat these as continuous rankings of how sensitive the clustering solution is to perturbations in each feature. A high-stringency "keep" subset (stability + FDR) is still derived but used primarily for sensitivity descriptions, not as the sole definition of "important" features

```{r aggregation_and_decision, message = FALSE, warning = FALSE, echo = FALSE}

#7. Aggregation & descriptive MCR ranking
#7.1 Create a feature importance aggregate across seeds
if (params$mode %in% c("auto", "aggregate")) {
  .log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FI_AGG_START")

  #7.1.1 Load all seed-level feature importance outputs
  seed_files <- list.files(paths$seed_dir,
                           pattern = "feature_importance_seed[0-9]+\\.csv$",
                           full.names = TRUE)
  stopifnot(length(seed_files) > 0)
  all_df <- lapply(seed_files, readr::read_csv, show_col_types = FALSE) |>
    bind_rows()

  #7.1.1.1 Detect which shadow column exists in seed outputs (compat: 'shadow_thr' or 'shadow_max')
  shadow_col <- dplyr::case_when(
    "shadow_thr" %in% names(all_df) ~ "shadow_thr",
    "shadow_max" %in% names(all_df) ~ "shadow_max",
    TRUE ~ NA_character_)

  #7.1.1.2 Helper: combine p-values across seeds with Fisher's method
  combine_fisher <- function(p) {
    p <- p[is.finite(p) & !is.na(p) & p > 0 & p <= 1]
    k <- length(p)
    if (!k) return(NA_real_)
    stat <- -2 * sum(log(p))
    stats::pchisq(stat, df = 2 * k, lower.tail = FALSE)
  }
  
  #7.1.2 Aggregate feature-specific shadow stability (win-rate per feature)
  stabA <- all_df |>
    group_by(feature) |>
    summarise(
      mcr_mean = mean(mcr_mean, na.rm = TRUE),
      mcr_sd = sd(mcr_mean,  na.rm = TRUE),
      thr_feat_mean = mean(shadow_thr_feat, na.rm = TRUE),
      thr_feat_sd = sd(shadow_thr_feat,   na.rm = TRUE),
      win_rate_feat = mean(pass_shadow_feat, na.rm = TRUE),
      delta_vs_thr = mean(mcr_mean - shadow_thr_feat, na.rm = TRUE),
      .groups = "drop") |>
    arrange(desc(mcr_mean))
  
  #7.1.2.1 Write feature-specific shadow stability csv
  write_csv2(stabA, file.path(paths$sum_dir, "feature_importance_summary_feature_spec_mcr.csv"))

  #7.1.3 Aggregate across seeds: mean MCR, SD, win-rate
  stab <- all_df |>
    group_by(feature) |>
    summarise(
      mcr_mean = mean(mcr_mean, na.rm = TRUE),
      mcr_sd = sd(mcr_mean,  na.rm = TRUE),
      win_rate = mean(pass_shadow_feat, na.rm = TRUE),
      .groups = "drop") |>
    arrange(desc(mcr_mean)) |>
    mutate(keep_stability = win_rate >= params$stability_keep)

  #7.1.3.1 Empirical p-values: combine across seeds and apply BH/FDR across features
  if ("p_emp" %in% names(all_df)) {
    p_by_feat <- all_df |>
      group_by(feature) |>
      summarise(p_emp_comb = combine_fisher(p_emp), .groups = "drop") |>
      mutate(p_emp_fdr = ifelse(is.na(p_emp_comb), NA_real_, p.adjust(p_emp_comb, method = "BH")))
    stab <- stab |>
      left_join(p_by_feat, by = "feature")
  } else {
    stab$p_emp_comb <- NA_real_
    stab$p_emp_fdr  <- NA_real_
  }

  #7.1.4 Set path for output MCR ranking figure
  fig_path <- file.path(paths$fig_dir, "mcr_rank_across_seeds.png")

  #7.1.5 Compute a shadow baseline line for plotting (prefers per-seed average)
  shadow_col <- dplyr::case_when(
    "shadow_thr" %in% names(all_df) ~ "shadow_thr",
    "shadow_max" %in% names(all_df) ~ "shadow_max",
    TRUE ~ NA_character_
  )

  shadow_hline <- NA_real_
  if (!is.na(shadow_col)) {
    if ("seed_idx" %in% names(all_df)) {
      thr_by_seed <- all_df |>
        dplyr::group_by(seed_idx) |>
        dplyr::summarise(thr = dplyr::first(.data[[shadow_col]]), .groups = "drop")
      shadow_hline <- mean(thr_by_seed$thr, na.rm = TRUE)
    } else {
      shadow_hline <- mean(all_df[[shadow_col]], na.rm = TRUE)
    }
  }

  #7.1.6 Plot ranked MCR with error bars (+-SD) and dashed shadow reference (if available)
  p_rank <- stab |>
    dplyr::mutate(feature = reorder(feature, mcr_mean)) |>
    ggplot2::ggplot(ggplot2::aes(x = feature, y = mcr_mean)) +
    ggplot2::geom_point() +
    ggplot2::geom_errorbar(
      ggplot2::aes(ymin = pmax(0, mcr_mean - mcr_sd), ymax = mcr_mean + mcr_sd),
      width = 0.2) +
    ggplot2::coord_flip() +
    ggplot2::labs(
      x = NULL,
      y = "Mean MCR (+-SD)",
      title = "Permutation MCR by feature (across seeds)",
      subtitle = if (is.finite(shadow_hline)) "Dashed line: mean shadow baseline across seeds" else NULL) +
    ggplot2::theme_minimal(base_size = 12)

  if (is.finite(shadow_hline)) {
    p_rank <- p_rank + ggplot2::geom_hline(yintercept = shadow_hline, linetype = 2)
  }

  ggplot2::ggsave(fig_path, p_rank, width = 7, height = 8, dpi = 300)
  
  #7.1.7 MCR vs feature-specific thresholds plot (dots vs X's)
  p_feature_spec_mcr <- stabA |>
    mutate(feature = reorder(feature, mcr_mean)) |>
    ggplot2::ggplot(ggplot2::aes(x = feature)) +
    ggplot2::geom_point(ggplot2::aes(y = mcr_mean)) +
    ggplot2::geom_errorbar(ggplot2::aes(ymin = pmax(0, mcr_mean - mcr_sd),
                                        ymax = mcr_mean + mcr_sd), width = 0.2) +
    ggplot2::geom_point(ggplot2::aes(y = thr_feat_mean), shape = 4) +
    ggplot2::coord_flip() +
    ggplot2::labs(x = NULL, y = "MCR / Feature-specific threshold",
                  title = "Permutation MCR vs feature-specific shadow thresholds",
                  subtitle = "Dots = MCR mean (+-SD); X = feature-specific shadow mean") +
    ggplot2::theme_minimal(base_size = 12)

  ggplot2::ggsave(file.path(paths$fig_dir, "mcr_vs_feature_shadow_feature_spec_mcr.png"),
                  p_feature_spec_mcr, width = 7, height = 8, dpi = 300)

  #7.1.7 High-stringency "keep" subset: stability AND (if available) FDR at alpha. This subset is used for sensitivity descriptions; we still interpret feature contributions primarily from the full continuous rankings
  final_keep <- stab |>
    mutate(pass = keep_stability &
             (is.na(p_emp_fdr) | p_emp_fdr <= params$holm_alpha)) |>
    filter(pass) |>
    arrange(desc(mcr_mean))

  #7.1.8 Write the enriched summary and final keep set to CSV
  write_csv2(stab, file.path(paths$sum_dir, "feature_importance_summary.csv"))
  write_csv2(final_keep,file.path(paths$sum_dir, "final_keep_features.csv"))
  .log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FI_AGG_DONE|kept={nrow(final_keep)}")
}

#7.2 Redundancy analysis on kept feature set. Note: this is a mechanical redundancy pruning among high-stringency features, not a full "minimal viable feature set" search
#7.2.1 Run redundancy on the canonical feature frame used by k-proto
red_all <- compute_redundancy(
  dt = risk_dt[, ..features_used],
  rho_cut = params$redundancy_rho,
  v_cut = params$redundancy_v)

#7.2.2 Keep-only pairs: restrict to features that passed the stability/FDR rule
red_keep <- red_all |>
  semi_join(stab |> filter(keep_stability) |> transmute(var1 = feature), by = "var1") |>
  semi_join(stab |> filter(keep_stability) |> transmute(var2 = feature), by = "var2")

#7.2.3 Write redundancy results
write_csv2(red_all, file.path(paths$sum_dir, "redundancy_flags_all_features.csv"))
write_csv2(red_keep, file.path(paths$sum_dir, "redundancy_flags_among_kept.csv"))

#7.2.4 Derive a mechanically pruned keep set (greedy on higher mean MCR)
prune_greedy <- function(keep_tab, stab_tab, red_pairs) {
  keep  <- keep_tab$feature
  score <- tibble(feature = stab_tab$feature, score = stab_tab$mcr_mean)

  #7.2.4.1 Iterate over redundant pairs and drop the lower-scoring feature if both still present
  if (nrow(red_pairs)) {
    for (i in seq_len(nrow(red_pairs))) {
      a <- red_pairs$var1[i]; b <- red_pairs$var2[i]
      if (a %in% keep && b %in% keep) {
        sa <- score$score[match(a, score$feature)]
        sb <- score$score[match(b, score$feature)]
        drop <- ifelse(is.na(sa) || is.na(sb), b, ifelse(sa >= sb, b, a))
        keep <- setdiff(keep, drop)
      }
    }
  }
  tibble(feature = keep)
}

#7.2.5 Execute the pruned (greedy) set
final_keep_pruned <- prune_greedy(final_keep, stab, red_keep)

#7.2.6 Write the pruned (greedy) set results
write_csv2(final_keep_pruned, file.path(paths$sum_dir, "final_keep_pruned_by_redundancy.csv"))

```

### 8. Surrogate Triangulation of Cluster-Relevant Features Using XGBoost + SHAP

**Goal:** Train a regularized XGBoost surrogate to predict cluster labels with stratified v-fold OOF evaluation (balanced accuracy and macro-F1). Fit a final model on all data to compute SHAP global importances for descriptive corroboration of which features contribute most to discriminating the 2 clusters. SHAP is used here exclusively for visualization/triangulation, not as a hard selection criterion

```{r surrogate_and_shap, message = FALSE, warning = FALSE, echo = FALSE}

#8. Surrogate + SHAP (descriptive only), with OOF fidelity via stratified v-folds (macro BA & macro F1)
if (params$mode %in% c("auto", "aggregate")) {

  #8.1 Labels & features (classify original anchor assignments)
  y <- factor(base_assign0)
  X_df <- as.data.frame(risk_dt[, ..features_used])

  #8.1.1 Coerce true binary 0/1 factors to numeric 0/1 (no one-hot for binary)
  bin_fac <- names(Filter(function(x) is.factor(X_df[[x]]) && nlevels(X_df[[x]]) == 2, names(X_df)))
  if (length(bin_fac)) {
    for (cc in bin_fac) {
      levs <- levels(X_df[[cc]])
      if (setequal(levs, c("0","1"))) {
        X_df[[cc]] <- as.numeric(as.character(X_df[[cc]]))
      } else {
        
        #8.1.1.1 Fallback: map first level to 0, second to 1 (document if this ever triggers)
        X_df[[cc]] <- as.integer(X_df[[cc]] == levs[2L])
      }
    }
  }

  #8.1.2 If any >2-level categoricals appear in future, one-hot just those
  multi_fac <- names(Filter(function(x) is.factor(X_df[[x]]) && nlevels(X_df[[x]]) > 2, names(X_df)))
  if (length(multi_fac)) {
    X_oh  <- model.matrix(~ . - 1, data = X_df)
    X_mat <- X_oh
  } else {
    X_mat <- data.matrix(X_df)
  }

  #8.2 Stratified v-folds with project seed
  set.seed(123)
  Xy <- tibble::as_tibble(X_df) |>
    dplyr::mutate(.y = y, .row_id = dplyr::row_number())
  folds <- rsample::vfold_cv(Xy, v = params$xgb_cv_folds, strata = .y)

  #8.3 Class weights (macro-friendly): inverse frequency, mean-normalized
  freq <- table(y)
  w_vec <- as.numeric(1 / freq[as.character(y)])
  w_vec <- w_vec / mean(w_vec)

  #8.4 Compact, regularized xgb params (multiclass-safe)
  num_class <- length(levels(y))
  params_xgb <- list(
    objective = if (num_class > 2) "multi:softprob" else "binary:logistic",
    eval_metric = if (num_class > 2) "mlogloss" else "logloss",
    max_depth = 4,
    eta = 0.1,
    subsample = 0.8,
    colsample_bytree = 0.8,
    nthread = n_workers,
    lambda = 1)
  if (num_class > 2) params_xgb$num_class <- num_class

  #8.5 OOF predictions + best_iteration per fold (early stopping on validation)
  n_folds <- length(folds$splits)
  preds_oof <- vector("list", n_folds)
  truth_oof <- vector("list", n_folds)
  best_iter_vec <- integer(n_folds)

  for (i in seq_len(n_folds)) {
    sp <- folds$splits[[i]]
    tr <- rsample::analysis(sp)
    te <- rsample::assessment(sp)
    idx_tr <- tr$.row_id
    idx_te <- te$.row_id 

    #8.5.1 Train model with early stopping
    dtrain <- xgb.DMatrix(data = X_mat[idx_tr, , drop = FALSE],
                          label = as.integer(y[idx_tr]) - 1L,
                          weight = w_vec[idx_tr])
    dtest <- xgb.DMatrix(data = X_mat[idx_te, , drop = FALSE],
                         label = as.integer(y[idx_te]) - 1L,
                         weight = w_vec[idx_te])

    bst_cv <- xgb.train(params = params_xgb, data = dtrain,
                        nrounds = params$xgb_nrounds,
                        watchlist = list(val = dtest),
                        early_stopping_rounds = 30, verbose = 0)

    bi <- tryCatch(bst_cv$best_iteration, error = function(...) NA_integer_)
    if (is.na(bi) || bi < 1L) bi <- params$xgb_nrounds
    best_iter_vec[i] <- as.integer(bi)

    pr <- predict(bst_cv, dtest)
    preds_oof[[i]] <- if (num_class > 2) {
      max.col(matrix(pr, ncol = num_class, byrow = TRUE))
    } else {
      ifelse(pr > 0.5, 2L, 1L)
    }
    truth_oof[[i]] <- as.integer(y[idx_te])
  }

  #8.6 OOF fidelity (macro BA & macro F1)
  pred_lbl  <- factor(unlist(preds_oof),  levels = seq_len(num_class), labels = levels(y))
  truth_lbl <- factor(unlist(truth_oof), levels = seq_len(num_class), labels = levels(y))
  dfm <- tibble::tibble(truth = truth_lbl, estimate = pred_lbl)
  balacc <- yardstick::bal_accuracy(dfm, truth, estimate, estimator = "macro")
  fmacro <- yardstick::f_meas(dfm, truth, estimate, estimator = "macro")
  fid <- dplyr::bind_rows(balacc, fmacro)
  write_csv2(fid, file.path(paths$sum_dir, "surrogate_fidelity.csv"))

  #8.7 Final compact model on all data for SHAP
  bi_pos <- best_iter_vec[best_iter_vec > 0]
  final_rounds <- if (length(bi_pos)) as.integer(stats::median(bi_pos)) else 50L
  final_rounds <- max(50L, final_rounds)

  if (is.null(colnames(X_mat))) colnames(X_mat) <- paste0("V", seq_len(ncol(X_mat)))

  dmat_all <- xgb.DMatrix(data = X_mat, label = as.integer(y) - 1L, weight = w_vec)
  bst <- xgb.train(params = params_xgb, data = dmat_all,
                   nrounds = final_rounds, verbose = 0)

  #8.7.1 Save final surrogate model
  xgb.save(bst, file.path(paths$shap_dir, "xgb_surrogate.model"))

  #8.8 SHAP global importances (mean |SHAP|) for descriptive triangulation
  sv <- shapviz::shapviz(bst, X_pred = X_mat, X = X_df)

  if (inherits(sv, "shapviz")) {
    S <- sv$S
    stopifnot(ncol(S) == ncol(X_mat))
    g_imp <- tibble::tibble(
      feature = colnames(S),
      mean_abs_shap = colMeans(abs(S), na.rm = TRUE)) |>
      dplyr::arrange(dplyr::desc(mean_abs_shap))
    write_csv2(g_imp, file.path(paths$sum_dir, "shap_global_importance.csv"))

  } else if (inherits(sv, "mshapviz")) {
    
    #8.8.1 Per-class importances
    per_class <- lapply(seq_along(sv), function(i) {
      Si <- sv[[i]]$S
      tibble::tibble(
        class = as.character(i),
        feature = colnames(Si),
        mean_abs_shap = colMeans(abs(Si), na.rm = TRUE))
    }) |> dplyr::bind_rows()
    
    cl_names <- attr(sv, "class_names")
    if (!is.null(cl_names) &&
        length(unique(per_class$class)) == length(cl_names)) {
      per_class$class <- factor(per_class$class,
                                levels = as.character(seq_along(cl_names)),
                                labels = cl_names)
    }

    write_csv2(per_class |> dplyr::arrange(class, dplyr::desc(mean_abs_shap)),
               file.path(paths$sum_dir, "shap_global_importance_per_class.csv"))

    g_imp_macro <- per_class |>
      dplyr::group_by(feature) |>
      dplyr::summarise(mean_abs_shap_macro = mean(mean_abs_shap, na.rm = TRUE), .groups = "drop") |>
      dplyr::arrange(dplyr::desc(mean_abs_shap_macro))
    write_csv2(g_imp_macro,
               file.path(paths$sum_dir, "shap_global_importance_macro.csv"))
  } else {
    warning("Unexpected shapviz object class: ", paste(class(sv), collapse = "/"))
  }

  #8.8.2 Check concordance with high-stringency keep set (if present)
  keep_path <- file.path(paths$sum_dir, "final_keep_features.csv")
  if (file.exists(keep_path)) {
    keep_tab <- readr::read_csv(keep_path, show_col_types = FALSE)
    if (file.exists(file.path(paths$sum_dir, "shap_global_importance_macro.csv"))) {
      gref <- readr::read_csv(file.path(paths$sum_dir, "shap_global_importance_macro.csv"),
                              show_col_types = FALSE) |>
        dplyr::rename(mean_abs_shap = mean_abs_shap_macro)
    } else {
      gref <- readr::read_csv(file.path(paths$sum_dir, "shap_global_importance.csv"),
                              show_col_types = FALSE)
    }
    keep_plus <- keep_tab |>
      dplyr::left_join(gref |>
                         dplyr::mutate(shap_rank = rank(-mean_abs_shap, ties.method = "min")),
                       by = "feature") |>
      dplyr::arrange(shap_rank)
    write_csv2(keep_plus, file.path(paths$sum_dir, "final_keep_with_shap.csv"))
    conc <- sum(!is.na(keep_plus$shap_rank))
    writeLines(glue::glue("Concordance: {conc}/{nrow(keep_plus)} retained features appear in SHAP table"), con = file.path(paths$sum_dir, "shap_concordance.txt"))
  }
  
  #8.8.3 SHAP interaction values (optional multivariate relationships)
  shp_i <- shapviz(
    bst, X_pred = X_mat, X = X_df, interactions = TRUE)

  #8.9 Plot SHAP plots (visual-only; no selection rules)
  #8.9.0 Use a clearer diverging palette for beeswarm-style plots
  options(shapviz.viridis_args = list(begin = 0.1, end = 0.9, option = "inferno"))
  
  #8.9.0.1 Set width and height in inches (unit / resolution)
  width_inches <- 788 / 300 
  height_inches <- 395 / 300 
  
  #8.9.0.2 Scale dimensions for publication-quality plots
  scale_factor <- 3
  width_inches <- width_inches * scale_factor
  height_inches <- height_inches * scale_factor
  
  #8.9.1 Mean SHAP global importance bar chart
  png(file.path(paths$fig_dir, "shap_mean_global_importance.png"), 
      width = width_inches, height = height_inches, units = "in", res = 300)
  print(shapviz::sv_importance(sv, show_numbers = TRUE))
  dev.off()
  
  #8.9.2 SHAP global importance distributions (beeswarm) with improved color scale
  p_bee <- shapviz::sv_importance(sv, kind = "beeswarm") +
    ggplot2::scale_color_viridis_c(option = "inferno")
  png(file.path(paths$fig_dir, "shap_global_importance_distributions.png"), 
      width = width_inches * 1.2, height = height_inches * 1.5, units = "in", res = 300)
  print(p_bee)
  dev.off()
  
  #8.9.3 Example dependence plots for top 3 features (by mean |SHAP|)
  if (exists("g_imp")) {
    for (v in head(g_imp$feature, 3)) {
      png(file.path(paths$fig_dir, paste0("shap_dependence_", v, ".png")), 
          width = width_inches, height = height_inches, units = "in", res = 300)
      print(shapviz::sv_dependence(sv, v = v))
      dev.off()
    }
  }
  
  #8.9.4 Mean SHAP global importance bar chart with interactions included
  png(file.path(paths$fig_dir, "shap_mean_importance_interactions_included.png"), 
      width = width_inches, height = height_inches, units = "in", res = 300)
  print(sv_interaction(shp_i, kind = "bar"))
  dev.off()
}

#8.10 Integrate centroid geometry, MCR, and SHAP into a single summary table
cent_path <- file.path(paths$sum_dir, "centroid_separation_summary.csv")
mcr_path <- file.path(paths$sum_dir, "feature_importance_summary.csv")
shap_macro_path <- file.path(paths$sum_dir, "shap_global_importance_macro.csv")
shap_simple_path <- file.path(paths$sum_dir, "shap_global_importance.csv")

if (file.exists(cent_path) && file.exists(mcr_path) &&
    (file.exists(shap_macro_path) || file.exists(shap_simple_path))) {

  cent_tab <- readr::read_csv(cent_path, show_col_types = FALSE)
  mcr_tab <- readr::read_csv(mcr_path,  show_col_types = FALSE)

  #8.10.1 Pick SHAP table (macro if multiclass, else simple)
  shap_path <- if (file.exists(shap_macro_path)) shap_macro_path else shap_simple_path
  shap_tab <- readr::read_csv(shap_path, show_col_types = FALSE)

  #8.10.2 Harmonize SHAP column name
  if ("mean_abs_shap_macro" %in% names(shap_tab)) {
    shap_tab <- dplyr::rename(shap_tab, mean_abs_shap = mean_abs_shap_macro)
  }

  #8.10.3 Build master summary table
  feat_master <- cent_tab |>
    dplyr::select(feature, delta_z, max_cohens_d, p_anova_fdr) |>
    dplyr::left_join(
      mcr_tab |>
        dplyr::select(feature, mcr_mean, mcr_sd, win_rate, keep_stability, p_emp_fdr),
      by = "feature") |>
    dplyr::left_join(
      shap_tab,
      by = "feature") |>
    dplyr::arrange(dplyr::desc(mcr_mean))

  write_csv2(
    feat_master,
    file.path(paths$sum_dir, "feature_importance_master_summary.csv")
  )
}

```

### 9. Reproducibility Log

**Goal:** Record parameters (n, p, k, lambda, scaling, biter, n_seeds, shadow_B, stability_keep) and container hash to `run_log.json` for traceability of this run

```{r reproducibility_log, echo = FALSE}

#9. Reproducibility log
#9.1 Write run_log.json with key parameters and container info
log <- list(
  timestamp = as.character(Sys.time()),
  n = nrow(risk_dt), p = ncol(risk_dt),
  k = params$k_opt, lambda = lambda_used, scaling = params$scaling,
  biter = params$biter, n_seeds = params$n_seeds,
  shadow_B = params$shadow_B, stability_keep = params$stability_keep,
  container = "abcd-mds-risk-r_0.1.7.sif")

writeLines(jsonlite::toJSON(log, pretty = TRUE),
           con = file.path(paths$sum_dir, "run_log.json"))

#9.2 Mark normal completion in the detailed log
.log("{format(Sys.time(), '%Y-%m-%d %H:%M:%OS3')}|FI_DONE|mode={params$mode}")

```
