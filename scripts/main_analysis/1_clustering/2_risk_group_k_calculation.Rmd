---
title: "Bipolar Disorder & Suicidality Risk Group Clustering k Calculation"
author: "Sam A. Sievertsen"
date: "`r Sys.Date()`"
output:
  html_document:
    self_contained: true
params:
  scaling_method: "none"  # editable options: none, z_score, min_max, percentile, max_absolute, robust
---

```{r global, include = FALSE}

# Set global env variables
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, message = TRUE, warning = TRUE, results = "markup", verbose = TRUE, comment = "")

```

```{r environment, echo = FALSE, include = FALSE, warning = FALSE}

# Load necessary packages + environment
library(knitr)
library(dplyr)
library(tidyr)
library(DescTools)
library(skimr)
library(easystats)
library(cluster)
library(fpc)
library(clustMixType)
library(factoextra)
library(FactoMineR)
library(NbClust)
library(clValid) 
library(ClusterR) 
library(mclust)
library(clusterSim)
library(clustertend)
library(hopkins)
library(tidymodels)
library(tidyclust)
library(tidyquant)
library(FeatureImpCluster)
library(ggplot2)
library(inflection)
library(progressr)
handlers("txtprogressbar")
plan(multisession, workers = as.integer(Sys.getenv("SLURM_CPUS_PER_TASK"), unset = "1"))
options(scipen = 999, digits = 8)
set.seed(123)

# Read in risk variable data to be used in clustering
risk_variable_data <- read.csv("../../data/data_processed/risk_variable_data.csv")

```

## Data Prep for k Value Analysis 

```{r data prep, warning = FALSE}

## Data Prep ## 

#1. Ensure dichotimization of categorical data for clustering
risk_variable_data <- risk_variable_data %>% 
  mutate(across(c("family_history_depression", "family_history_mania", "bullying"), as.factor))

#2. Retain subject IDs as row names while removing variables that will not be clustered 
#2.1 Remove all variables except subject ID from the dataframe for clustering
risk_variable_clustering_data <- risk_variable_data %>%
  dplyr::select(-session_id, -family_id, -site, -sex, -age, -race_ethnicity)

#2.2 Set subject IDs as row names
row.names(risk_variable_clustering_data) <- risk_variable_clustering_data$participant_id

#2.3 Remove subject ID column
risk_variable_clustering_data <- risk_variable_clustering_data %>% 
  dplyr::select(-participant_id)

#3. Identify continuous and categorical variables
continuous_vars <- names(risk_variable_clustering_data)[sapply(risk_variable_clustering_data, is.numeric)]
categorical_vars <- names(risk_variable_clustering_data)[sapply(risk_variable_clustering_data, is.factor)]

#4. Scaling function to be matched with established param
apply_scaling <- function(df, method) {
  out <- df
  if (method != "none") {
    cont <- df[continuous_vars]
    scaled <- switch(method,
      z_score = scale(cont),
      min_max = purrr::map_df(cont, ~ (.x - min(.x, na.rm=TRUE)) / (max(.x, na.rm=TRUE) - min(.x, na.rm=TRUE))),
      percentile = purrr::map_df(cont, ~ rank(.x, na.last="keep") / sum(!is.na(.x)) * 100),
      max_absolute = purrr::map_df(cont, ~ .x / max(abs(.x), na.rm=TRUE)),
      robust = purrr::map_df(cont, ~ (.x - median(.x, na.rm=TRUE)) / (IQR(.x, na.rm=TRUE) %||% 1))
    )
    out[continuous_vars] <- scaled
  }
  out
}

#5. Scale data according to param set in script call
scaled_data <- apply_scaling(risk_variable_clustering_data, params$scaling_method)

```

## Determining Optimal Number of Clusters (*k* Value)

Choosing the appropriate number of clusters (*k*) is critical for uncovering meaningful groupings in mixed‐type data. Here, we combine descriptive elbow analysis with multiple internal validation indices to arrive at a robust, transparent recommendation for *k* between 2 and 8:

1. **Elbow method**
   We plot the within‐cluster sum of squares (WCSS) across *k* = 2:8 and apply the Kneedle algorithm \[Satopaa *et al.*, 2011] via the `inflection` package (Emekes, 2017) to quantitatively identify the “elbow” point. This provides a visual and numeric guide, but is treated as descriptive rather than prescriptive for purposes of our analyses

2. **Internal validation indices**
   Using `validation_kproto()`, we compute six statistical validation indices: Silhouette, C-Index, Dunn, Gamma, Point-biserial, and Tau—for each *k*. Each index captures a different aspect of cluster compactness and separation without requiring true labels

3. **Consensus evaluation**
   We record the optimal *k* returned by each index and examine patterns of agreement or discrepancy. A convergence of multiple indices on the same *k* will strengthen our confidence in that choice

Below, we implement this three‐step procedure. First, we generate the elbow plot and run Kneedle to flag an elbow. Next, we loop through each validation index to extract its preferred *k*. Finally, we summarize all results in a single table for comparison

```{r optimal k, warning = FALSE}

## Determining Optimal Number of Clusters (*k* Value) ## 

#1. Establish parameters for testing cluster k solutions
k_vals <- 2:8
wss_vec <- numeric(length(k_vals))
kp_list <- vector("list", length(k_vals))
names(kp_list) <- paste0("k", k_vals)

#2.2 Compute WSS and kproto objects for k = 2:8
for (i in seq_along(k_vals)) {
  k <- k_vals[i]
  message(sprintf("Training kproto for k = %d", k))
  kp <- kproto(
    x = scaled_data,
    k = k,
    nstart  = 8,
    verbose = TRUE
  )
  kp_list[[i]] <- kp
  wss_vec[i]   <- kp$tot.withinss
  saveRDS(kp, file = sprintf("kp_k%d.rds", k))  # checkpoint each model
}

#2.3 Elbow plot of WSS
elbow_df <- tibble(k = k_vals, WSS = wss_vec)
plt_elbow <- ggplot(elbow_df, aes(k, WSS)) +
  geom_line() + geom_point() +
  labs(title = "Elbow Plot: WSS vs k", x = "k", y = "Total WSS")
print(plt_elbow)

#2.4 Quantitative elbow via Kneedle (UIK)
uik_pt <- inflection::uik(wss_vec)$k
message(sprintf("UIK Elbow at k = %d", uik_pt))
plt_elbow +
  geom_vline(xintercept = uik_pt, linetype = "dashed", color = "red")

## 3. Validation Indices across *k*

#3.1 Set up indices and storage
indices <- c("silhouette","cindex","dunn","gamma","ptbiserial","tau")
val_results <- list()

#3.2 Loop through each index and save full kp_obj results
for (idx in indices) {
  message(sprintf("Validating index: %s", idx))
  vr <- validation_kproto(
    method = idx,
    object = NULL,
    data   = scaled_data,
    k      = k_vals,
    kp_obj = "all",
    nstart = 8,
    verbose= TRUE
  )
  val_results[[idx]] <- vr
  saveRDS(vr, file = sprintf("validation_%s.rds", idx))
}

#3.3 Summarize optimal k for each index
opt_summary <- tibble(
  index   = indices,
  k_opt   = map_int(val_results, "k_opt"),
  values  = map(val_results, function(v) v$indices)
)
knitr::kable(opt_summary, caption = "Optimal k per validation index")

```

**Interpretation:**

- The elbow plot suggests a bend at *k* = X, reinforced by Kneedle’s quantitative estimate

- Among the six validation indices, Y/Y indices also favor *k* = X, while the remainder peak at neighboring values

- Taken together, these results indicate that *k* = X balances cohesion and separation most consistently in our risk‐variable data
