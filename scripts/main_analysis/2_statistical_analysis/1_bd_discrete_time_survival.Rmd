---
title: "1. BD Discrete-Time Survival (First Onset)"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
params:
  repo: !r Sys.getenv("REPO", unset = here::here())
  data_dir: "data/data_processed/analysis_datasets/"
  out_dir: "results/main_analysis/1_bd_survival"
  bd_pp_rds: "bd_person_period_k2_z_score.rds"
  bd_pp_csv: "bd_person_period_k2_z_score.csv"
  k_value: 2
  run_influence: false
  seed: 123
  link_primary: "logit"
  ages_pred: !r c()
  wave_ref: "ses-04A"
---

```{r global, include = FALSE}

# Set global env variables
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, message = TRUE, warning = TRUE, results = "markup", verbose = TRUE, comment = "")

```

## Data Wrangling

First, we will read in necessary packages and use parameters to read in our pre-built analysis dataset; then filter it for complete cases (according to the necessary variables to be used in analyses) and print a brief table outlining the unique number of subjects and total observations we possess in our "complete" analysis ready dataset

```{r environment, echo = FALSE, warning = FALSE}

## Load packages, data, & set env ##

# Quiet & safe package loads
suppressPackageStartupMessages({
  library(dplyr); 
  library(tidyr); 
  library(rlang);
  library(tibble);
  library(lubridate); 
  library(glue); 
  library(forcats)
  library(broom); 
  library(broom.mixed); 
  library(lme4); 
  library(blme);
  library(performance)
  library(emmeans); 
  library(ggeffects); 
  library(pROC); 
  library(yardstick)
  library(clubSandwich); 
  library(patchwork); 
  library(here); 
  library(stringr); 
  library(ggplot2);
  library(kableExtra);
  library(DHARMa);
  library(see);
  library(glmmTMB);
  library(logistf)  
})

# Set seed for reproducibility
set.seed(params$seed)

# Set numerical handling
options(scipen = 999, digits = 8)

# Ensure proper encoding of output
options(encoding = "UTF-8")
knitr::opts_knit$set(encoding = "UTF-8")
knitr::knit_hooks$set(output = function(x, options) enc2utf8(x))
knitr::knit_hooks$set(inline = function(x) enc2utf8(paste(x, collapse = "")))

# Ensure proper storage of emmeans objects
emmeans::emm_options(infer = c(TRUE, TRUE))

# Establish paths to repo and data (I/O)
REPO <- params$repo
DATA_DIR <- file.path(REPO, params$data_dir)
OUT_DIR <- file.path(REPO, params$out_dir)
dir.create(OUT_DIR, recursive = TRUE, showWarnings = FALSE)

# Create a helper function to read in BD person-period data - prefer RDS; fallback to csv
read_pp <- function(rds_path, csv_path) {
  if (file.exists(rds_path)) readRDS(rds_path) else readr::read_csv(csv_path, show_col_types = FALSE)
}

# Load person-period BD data
bd_pp <- read_pp(file.path(DATA_DIR, params$bd_pp_rds),
  file.path(DATA_DIR, params$bd_pp_csv)) %>%
  mutate(
    participant_id = as.character(participant_id),
    family_id = factor(as.character(family_id)),
    site_factor = factor(site_factor),
    cluster = factor(cluster),
    start_wave = factor(start_wave),
    end_wave = factor(end_wave),
    outcome = factor(outcome),
    sex = factor(sex)
  )

# Keep just the BD outcomes we model in this analysis
bd_outcomes <- c("bipolar_I","bipolar_II","bd_nos","any_bsd")
bd_pp <- bd_pp %>% filter(outcome %in% bd_outcomes)

# Refine pre-built data using a model-ready filter that mirrors QC "post" rules
bd_pp_model <- bd_pp %>%
  filter(event %in% c(0L,1L)) %>%
  filter(!is.na(cluster)) %>%
  filter(!is.na(age_mid), !is.na(sex), !is.na(site_factor), !is.na(family_id))

# Conduct a sanity check of the dataset size (unique ID's and number of observations)
sizes_tbl <- tibble(
  Dataset = "BD person-period (model-ready)",
  Rows = nrow(bd_pp_model),
  Unique_IDs  = dplyr::n_distinct(bd_pp_model$participant_id)
)

# Print the dataset size sanity check table
knitr::kable(sizes_tbl, caption = "Dataset size check")  %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

# Ensure cluster, wave, sex, and site reference levels (consistent displays)
cluster_levels <- levels(bd_pp$cluster)
bd_pp_model <- bd_pp_model %>%
  mutate(
    cluster = forcats::fct_relevel(cluster, "C1"),
    end_wave = forcats::fct_relevel(end_wave, "ses-02A", "ses-04A", "ses-06A"),
    sex = forcats::fct_relevel(sex, "Female"),
    site_factor = forcats::fct_relevel(site_factor, "site01"))

# Establish interval length in years (02A~2, 04A~4, 06A~6); handles missed waves
wave_year <- function(w) {
  as.numeric(stringr::str_extract(as.character(w), "\\d+"))
}
bd_pp_model <- bd_pp_model %>%
  mutate(dt_years = pmax(wave_year(end_wave) - wave_year(start_wave), 1),
    log_dt = log(dt_years))

# Guard interval-lengths (offset) before fitting cloglog
bad_dt <- sum(!is.finite(bd_pp_model$dt_years) | !is.finite(bd_pp_model$log_dt))
if (bad_dt > 0) {
  warning("Dropping ", bad_dt, " rows with undefined interval length.")
  bd_pp_model <- bd_pp_model %>% dplyr::filter(is.finite(dt_years), is.finite(log_dt))
}

# Get descriptive event counts (post-filter; by outcome x wave x cluster)
onset_counts <- bd_pp_model %>%
  group_by(outcome, end_wave, cluster) %>%
  summarise(events = sum(event == 1L, na.rm = TRUE),
    intervals = n(), .groups = "drop") %>%
  arrange(outcome, end_wave, cluster)

# Save post-filter counts to disk and show in HTML
readr::write_csv(onset_counts, file.path(OUT_DIR, "bd_dth_onset_counts.csv"))
knitr::kable(onset_counts, caption = "Event counts by outcome x wave x cluster") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

## Do a post-filter missingness summary of the model covariates ##

# Create a list of relevant covariates
covars <- c("cluster","age_mid_between","age_mid_cwc","baseline_status",
            "sex","site_factor","end_wave","participant_id","family_id")

# Create a missingness table for the post-filter covariate data
miss_tbl <- bd_pp_model %>%
  mutate(across(all_of(covars), ~ as.numeric(is.na(.)))) %>%
  group_by(outcome) %>%
  summarise(n = n(),
    across(all_of(covars), ~ sum(.), .names = "n_miss_{col}"),
    across(starts_with("n_miss_"), ~ round(./n, 4), .names = "p_{.col}"),
    .groups = "drop")

# Write the missingness table for the post-filter covariate data as a table in the HTML
knitr::kable(miss_tbl, caption = "Missingness (post-filter) by outcome") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

## Baseline_status QC specific to each outcome ##

# Create a qc table summarizing the baseline status presence for each diagnostic outcome
baseline_qc <- bd_pp_model %>%
  group_by(outcome, baseline_status) %>%
  summarise(n = n(), events = sum(event == 1L), .groups = "drop") %>%
  arrange(outcome, baseline_status)

# Write the qc table summarizing the baseline status presence for each diagnostic outcome in the HTML
knitr::kable(baseline_qc, caption = "Baseline_status QC by outcome") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

## Baseline prevalence at baseline (participants) by outcome x risk cluster ##

# IMPORTANT: do this BEFORE filtering out baseline-positive so the counts are complete - collapse to one row per participant x outcome x cluster, then count baseline-positive IDs
baseline_prev_ids <- bd_pp_model %>%
  dplyr::group_by(outcome, cluster, participant_id) %>%
  dplyr::summarise(
    baseline_pos = as.integer(any(baseline_status == 1, na.rm = TRUE)),
    .groups = "drop"
  )

# Crate a table outlining the distribution of baseline BD dx endorsements
baseline_prev_tbl <- baseline_prev_ids %>%
  dplyr::group_by(outcome, cluster) %>%
  dplyr::summarise(
    n_participants = dplyr::n(),
    n_baseline_positive = sum(baseline_pos == 1L, na.rm = TRUE),
    pct_baseline_positive = n_baseline_positive / n_participants,
    .groups = "drop") %>%
  dplyr::arrange(outcome, cluster)

# Display the distribution of baseline BD dx endorsements in the HTML
knitr::kable(
  baseline_prev_tbl %>%
    dplyr::mutate(pct_baseline_positive = scales::percent(pct_baseline_positive, accuracy = 0.01)),
  caption = "Baseline prevalence at baseline (participants) by outcome - risk cluster") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

## Primary risk set for FIRST ONSET (critical) ##

# Build an ID-level baseline flag using the any_bsd outcome (covers BD-I/II/NOS)
baseline_any_bsd_ids <- bd_pp_model %>% 
  dplyr::filter(outcome == "any_bsd") %>%
  dplyr::group_by(participant_id) %>%
  dplyr::summarise(
    all_na = all(is.na(baseline_status)),
    baseline_any_bsd = dplyr::if_else(
      all_na, NA_integer_, as.integer(any(baseline_status == 1L, na.rm = TRUE))
    ),
    .groups = "drop"
  )

# Join to all outcomes, do not assume 0 for missing data
bd_pp_model <- bd_pp_model %>%
  dplyr::left_join(baseline_any_bsd_ids %>% dplyr::select(participant_id, baseline_any_bsd),
    by = "participant_id")

# Count before/after and filter to baseline-negative-for-any-BSD
n_before <- nrow(bd_pp_model)
ids_before <- dplyr::n_distinct(bd_pp_model$participant_id)

# Filter the dataset to contain participants that had not yet had BD
bd_pp_model <- bd_pp_model %>% dplyr::filter(baseline_any_bsd == 0L)

# Print a message containing the new number of observations without the participants who already endorsed BD at baseline
message(
  "Risk-set conditioning: excluded participants baseline-positive (and baseline-unknown) for ANY BSD; ",
  "rows dropped = ", n_before - nrow(bd_pp_model),
  " (IDs from ", ids_before, " to ", dplyr::n_distinct(bd_pp_model$participant_id), "). ",
  "Models omit a baseline term because only baseline-negative youth remain."
)

# Censor after first onset (per outcome x participant); keep all intervals up to and including the first event==1 row; drop any later rows
bd_pp_model <- bd_pp_model %>%
  arrange(outcome, participant_id,
          if ("interval_index" %in% names(.)) interval_index else as.integer(end_wave)) %>%
  group_by(outcome, participant_id) %>%
  mutate(after_onset = dplyr::lag(cummax(event == 1L), default = FALSE)) %>%
  filter(!after_onset) %>%
  ungroup() %>%
  dplyr::select(-after_onset)

# Check to make sure that censoring was performed correctly
aud <- bd_pp_model %>%
  arrange(outcome, participant_id,
          if ("interval_index" %in% names(.)) interval_index else as.integer(end_wave)) %>%
  group_by(outcome, participant_id) %>%
  mutate(had_onset = cummax(event == 1L)) %>%
  summarise(post_onset_rows = max(0L, sum(had_onset) - 1L), .groups = "drop")
message("Any post-onset rows remain? ", any(aud$post_onset_rows > 0))

# Establish empirical wave-median ages for plotting/prediction
wave_age_medians <- bd_pp_model %>%
  dplyr::group_by(end_wave) %>%
  dplyr::summarise(age_med = median(age_mid, na.rm = TRUE), .groups = "drop") %>%
  dplyr::arrange(match(end_wave, levels(bd_pp_model$end_wave)))
ages_empirical <- wave_age_medians$age_med %>% as.numeric() %>% round(1)

# Save the wave-median ages for later reporting 
readr::write_csv(wave_age_medians, file.path(OUT_DIR, "wave_age_medians.csv"))

# Choose ages to use (robust fallback to guarantee non-empty)
ages_pred_vec <- if (!is.null(params$ages_pred) && length(params$ages_pred) > 0) {
  params$ages_pred
} else if (length(ages_empirical) > 0 && all(is.finite(ages_empirical))) {
  ages_empirical
} else {
  message("ages_empirical empty; falling back to previously determined medians.")
  c(11.004729021633345, 13.116629238715475, 15.2109589041096)
}

```

## Analysis Overview

**Our Goal**

Estimate discrete-time hazards with a logit link for first-onset bipolar outcomes-BD-I, BD-II, BD-NOS, and Any BSD-from 02A onward, using the model-ready person-period datasets built previously

**Why discrete-time hazard (DTH)?**

-   DTH models the probability of an onset within an interval, conditional on no prior onset. With assessments at distinct waves in ABCD, it is good practice here for us to:

    -   Encode each interval as a row (person-period format)
    -   Flexibly estimate the baseline hazard via wave fixed effects (i.e., dummies for 02A, 04A, 06A)
    -   Include static and time-varying predictors alongside the hazard
    -   This matches standard practice for event occurrence with panel waves (e.g., Singer & Willett)
    
- To note, intervals with missed waves contribute longer person-periods; our cloglog + offset(log interval) sensitivity shows results are robust to irregular interval length

**Why discrete-time GLMM instead of a "true" survival model?**

-   ABCD follow-ups occur at distinct waves (02A, 04A, 06A). Event times are interval-censored by design, so a discrete-time hazard is the natural model: each row is an interval with a Bernoulli first-onset indicator given survival up to the start of that interval
-   With discrete time, a logistic link on person-period data and fixed effects for wave provide a flexible baseline hazard (no proportional hazards assumption on calendar time). Our inclusion of within- vs between-person age further disentangles age effects from assessment timepoint/cohort
-   The GLMM formulation lets us model multilevel dependence (participant, family, site) and obtain cluster-robust inferences. This multilevel structure is less straightforward in a vanilla Cox model when time is only known at waves
-   We still check a cloglog link as sensitivity. For small interval hazards, cloglog approximates a continuous-time proportional hazards model; our results can be compared to Cox-style interpretations
-   If needed later, we can also fit a piece-wise exponential model or interval-censored survival for attained-age time scale; however, given ABCD's assessment timepoint structure and our focus on wave-indexed hazards with rich random-effects structure, the discrete-time GLMM is well-aligned with the data-collection process and our scientific questions

**How we handle age (critical for interpretation)**

-   Our build steps created:

    -   `age_mid`: midpoint age for each interval
    -   `age_mid_cwc`: within-person centered age = `age_mid` person_mean(age_mid)` (captures aging within individuals)
    -   `age_mid_between`: between-person age = `person_mean(age_mid)` grand_mean(age_mid)` (captures older vs younger people on average)

-   Best practice in longitudinal models is to include both pieces (within & between) to avoid conflating them. This is the within-between (Mundlak/hybrid) decomposition

    -   Interpretation:

        -   `age_mid_cwc` -> change in hazard as the same person ages across waves (holding their average age constant)
        -   `age_mid_between` -> difference in hazard for people who are on average older vs younger in this sample

    -   We originally interacted cluster x age_mid_between to ask: do cluster differences widen or narrow at older average ages? We evaluated cluster x age_mid_between; it was unstable/non-significant and was dropped for parsimony and better diagnostics

**Model we fit per outcome**

- Fixed effects (core): `cluster + age_mid_between + age_mid_cwc + sex + end_wave`

- Random effects: `(1 | participant_id) + (1 | family_id) + (1 | site_factor)`  
    - (If diagnostics indicate, we drop near-zero or problematic REs in a prespecified order, never removing the participant intercept)
  
- Risk set: We exclude participants who were positive for *any BSD at baseline* across outcomes. Consequently, no baseline-status covariate is included for this analysis because it is not necessary; first-onset hazard is modeled only among baseline-negative youth to capture predictive power of the risk clusters

-   Estimation and inference:
    -   Fit with `lme4::glmer(family = binomial)`, optimizer fallback to bobyqa if needed
    -   Report model-based CIs and cluster-robust (CR2) SEs using `clubSandwich::vcovCR(..., cluster = family_id, type = "CR2")`

-   Diagnostics & reporting:
    -   Convergence checks; predicted hazards by cluster across representative ages; calibration (deciles of risk) and interval AUCs; compact tables via `broom.mixed`/`performance`

> *Note on time scale:* Here we use wave as the time scale with age decomposition (within & between). As a sensitivity, we may later re-express the data on attained age as the time scale; in that case, the baseline hazard would absorb age and we would omit age as a covariate, adjusting instead for cohort/period if needed.

## 1. Create Helper Functions to Use for Conducting Analyses

-   `build_formula()`: Discrete-time hazard GLMM with wave fixed effects (baseline hazard), within/between age decomposition, and random intercepts for site, participant, and family
-   `fit_glmer_safe()`: Robust GLMM fitter with `bobyqa` + fallback; supports logit (primary) and cloglog (sensitivity)
-   `tidy_wald()`: Fixed-effect ORs with Wald CIs
-   `tidy_cr2()`: Cluster-robust (CR2) SEs and CIs, clustered by `family_id` (recommended small/medium cluster correction)
-   `pred_grid_by_age()`: Marginal predicted first-onset hazards by cluster across chosen ages (empirical medians), fixing within-age = 0 and wave = `params$wave_ref`
-   `calibration_df()`: Decile-bin calibration (predicted vs observed)
-   `auc_interval()`: Interval-level ROC AUC (QC indicator; marginal)
-   `diag_report()`: Singularity and overdispersion checks
-   `cluster_contrasts_by_age()`: `emmeans` pairwise cluster ORs at the chosen ages

Multiple others for QC and plotting

```{r helper function, echo = FALSE, warning = FALSE}

## 1. Create helper functions for building, fitting, and summarizing models ##

#1.1 Build DTH formula, where wave FE (end_wave) = flexible baseline hazard; and formula includes within- and between-person age components
#1.1 Build DTH formula
build_formula <- function(link = c("logit","cloglog")) {
  link <- match.arg(link)
  rhs <- paste(
    "cluster",
    "age_mid_between",
    "age_mid_cwc",
    "sex",
    "end_wave",
    "(1 | participant_id)",
    sep = " + "
  )
  stats::as.formula(paste("event ~", rhs))
}

#1.1.1 Decide if we should simplify (drop cluster:age_mid_between) based on diagnostics
needs_simplify <- function(fit, data) {
  di <- try(diag_report(fit), silent = TRUE)
  if (inherits(di, "try-error")) return(FALSE)
  nevents <- sum(data$event == 1L, na.rm = TRUE)
  p_fixed <- try(length(lme4::fixef(fit)), silent = TRUE); if (inherits(p_fixed, "try-error")) p_fixed <- NA_real_
  flag_singular <- isTRUE(di$is_singular)
  flag_vif <- !is.na(di$max_VIF) && di$max_VIF > 10
  flag_events <- is.finite(nevents) && is.finite(p_fixed) && nevents < (p_fixed + 3)
  flag_singular || flag_vif || flag_events
}

#1.2 Create a safe glmer with robust optimizer fallback
fit_glmer_safe <- function(formula, data, link = c("logit","cloglog")) {
  link <- match.arg(link)
  family_fn <- if (link == "logit") binomial(link = "logit") else binomial(link = "cloglog")
  ctrl <- glmerControl(optimizer = "bobyqa",
    optCtrl = list(maxfun = 2e5),
    check.conv.singular = "ignore")
  fit <- tryCatch(
    glmer(formula, data = data, family = family_fn, control = ctrl, nAGQ = 0),
    error = function(e) {
      message("Retrying with nAGQ=0 (", link, ") due to: ", conditionMessage(e))
      glmer(formula, data = data, family = family_fn, control = ctrl, nAGQ = 0)
    }
  )
  fit
}

#1.3 Create a function to extract Wald OR + CI in tidy format
tidy_wald <- function(fit) {
  broom.mixed::tidy(fit, effects = "fixed", conf.int = TRUE, conf.method = "Wald") %>%
    mutate(term = as.character(term),
      OR = exp(estimate),
      CI_lo= exp(conf.low),
      CI_hi= exp(conf.high),
      SE = std.error) %>%
    dplyr::select(term, estimate, SE, OR, CI_lo, CI_hi, p.value)
}

#1.4 Create a function to also extract CR2 robust (clustered by family) in tidy format
tidy_cr2 <- function(fit, cluster_var) {
  test_method <- "Satterthwaite"

  ct <- try(
    clubSandwich::coef_test(fit, vcov = "CR2", cluster = cluster_var, test = test_method),
    silent = TRUE)

  if (inherits(ct, "try-error")) {
    out <- broom.mixed::tidy(fit, effects = "fixed", conf.int = TRUE, conf.method = "Wald") %>%
      dplyr::mutate(
        term = as.character(term),
        OR = exp(estimate),
        CI_lo = exp(conf.low),
        CI_hi = exp(conf.high),
        SE = std.error,
        df = NA_real_,
        p.value = NA_real_,
        note = "CR2_failed") %>%
      dplyr::select(term, estimate, SE, df, OR, CI_lo, CI_hi, p.value, note)
    return(out)
  }

  ctt <- tibble::as_tibble(ct)
  pcol <- intersect(c("p_Satt","p_z","p_Nd","p_t"), names(ctt))[1]
  dfcol <- intersect(c("df_Satt","df"), names(ctt))[1]
  if (is.na(pcol)) ctt$p_any <- NA_real_ else ctt$p_any <- ctt[[pcol]]
  if (is.na(dfcol)) ctt$df <- NA_real_ else ctt$df <- ctt[[dfcol]]

  ctt %>%
    dplyr::mutate(
      term  = as.character(term),
      OR = exp(beta),
      CI_lo = exp(CI_L),
      CI_hi = exp(CI_U)) %>%
    dplyr::select(term, estimate = beta, SE, df, OR, CI_lo, CI_hi, p.value = p_any)
}

#1.5 Create a function to calculate marginal predicted hazard by cluster across ages, with an option to align ages to waves
pred_grid_by_age <- function(fit, data, ages = ages_pred_vec, wave_ref = params$wave_ref, align_waves = FALSE) {
  grand_mean <- mean(data$age_mid, na.rm = TRUE)
  age_between_vals <- ages - grand_mean
  
  #1.5.1 Map empirical ages to waves if requested (assumes ages are wave medians in end_wave order)
  waves <- levels(data$end_wave)
  if (align_waves) {
    
    #1.5.2 use min(lengths) to be robust if ages length differs from number of waves
    k <- min(length(ages), length(waves))
    end_waves_vec <- waves[seq_len(k)]
    ages <- ages[seq_len(k)]
    age_between_vals <- ages - grand_mean
    newdat <- do.call(rbind, lapply(seq_len(k), function(i) {
      expand.grid(cluster = levels(data$cluster),
        age_mid_between = age_between_vals[i],
        age_mid_cwc = 0,
        baseline_status = 0,
        sex = levels(data$sex)[1],
        site_factor = levels(data$site_factor)[1],
        end_wave = factor(end_waves_vec[i], levels = levels(data$end_wave)))
    }))
    newdat$age_years <- rep(ages, each = length(levels(data$cluster)))
  } else {
    newdat <- expand.grid(cluster = levels(data$cluster),
      age_mid_between = age_between_vals,
      age_mid_cwc = 0,
      baseline_status = 0,
      sex = levels(data$sex)[1],
      site_factor = levels(data$site_factor)[1],
      end_wave = factor(wave_ref, levels = levels(data$end_wave)))
    newdat$age_years <- rep(ages, each = length(levels(data$cluster)))
  }
  
  #1.5.3 Predict and store marginal hazards
  newdat$pred <- predict(fit, newdata = newdat, type = "response", re.form = NA)
  newdat
}

#1.6 Create a function to conduct calibration (i.e., deciles of predicted hazard vs observed)
calibration_df <- function(fit, data) {
  pr <- predict(fit, type = "response", re.form = NA)
  df <- data %>% mutate(pred = pr, dec = dplyr::ntile(pred, 10))
  df %>%
    group_by(dec) %>%
    summarise(
      pred_mean = mean(pred, na.rm = TRUE),
      obs_mean = mean(event == 1L, na.rm = TRUE),
      n = n(),
      .groups = "drop")
}

#1.7 Create a function to calculate the AUC (interval-level; QC only, ignores clustering)
auc_interval <- function(fit, data) {
  pr <- predict(fit, type = "response", re.form = NA)
  pROC::roc(response = data$event, predictor = pr, quiet = TRUE)$auc %>% as.numeric()
}

#1.8 Diagnostics: singularity, dispersion, groups, convergence, max VIF
diag_report <- function(fit) {
  is_sing <- tryCatch(lme4::isSingular(fit, tol = 1e-4), error = function(e) NA)
  overK <- tryCatch(performance::check_overdispersion(fit)$dispersion_ratio, error = function(e) NA_real_)
  conv <- tryCatch(performance::check_convergence(fit)$converged, error = function(e) NA)
  vif_max <- tryCatch(max(performance::check_collinearity(fit)$VIF, na.rm = TRUE), error = function(e) NA_real_)
  fl <- tryCatch(lme4::getME(fit, "flist"), error = function(e) NULL)
  n_id <- if (!is.null(fl) && "participant_id" %in% names(fl)) nlevels(fl$participant_id) else NA_integer_
  n_fam <- if (!is.null(fl) && "family_id" %in% names(fl)) nlevels(fl$family_id) else NA_integer_
  n_site <- if (!is.null(fl) && "site_factor" %in% names(fl)) nlevels(fl$site_factor) else NA_integer_
  tibble(is_singular = is_sing,
         converged = conv,
         overdispersion_K = overK,
         max_VIF = vif_max,
         n_groups_participant = n_id,
         n_groups_family = n_fam,
         n_groups_site = n_site)
}

#1.9.1 Build a function to conduct cluster contrasts at representative ages (emmeans on linear predictor). Builds EMMs at: within=0, wave=ref, and between set to represent ages
cluster_contrasts_by_age <- function(fit, data, ages = ages_pred_vec, wave_ref = params$wave_ref) {
  grand_mean <- mean(data$age_mid, na.rm = TRUE)
  age_between_vals <- ages - grand_mean

  #1.9.1.1 Start with both age-within variants and both wave codings; we'll keep only what the model uses.
  ref_list <- list(
    age_mid_between = age_between_vals,
    age_mid_cwc = 0,
    baseline_status = 0,
    end_wave = factor(wave_ref, levels = levels(data$end_wave)),
    wave_num = match(wave_ref, levels(data$end_wave)) - 1L,
    sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1])

  #1.9.1.2 If the fitted model included an offset, supply it (e.g., cloglog sensitivity in other calls)
  mf_names <- try(names(model.frame(fit)), silent = TRUE)
  if (!inherits(mf_names, "try-error") && "log_dt" %in% mf_names) ref_list$log_dt <- 0

  #1.9.1.3 Keep only variables the model actually uses; also drop the unused within-age variant.
  if (!inherits(mf_names, "try-error")) {
    if (!"end_wave" %in% mf_names) ref_list$end_wave <- NULL
    if (!"wave_num" %in% mf_names) ref_list$wave_num <- NULL
    ref_list <- ref_list[names(ref_list) %in% mf_names]
  }

  #1.9.1.4 EMMs on the linear predictor; contrasts -> ORs via exp()
  em <- emmeans::emmeans(fit, ~ cluster | age_mid_between, at = ref_list)
  ct <- emmeans::contrast(em, method = "revpairwise", adjust = "none")
  sm <- summary(ct, infer = c(TRUE, TRUE)) |> tibble::as_tibble()
  ci <- emm_ci_cols(sm)
  sm |>
    dplyr::mutate(
      age_years = round(age_mid_between + grand_mean, 2),
      OR = exp(estimate),
      CI_lo = exp(.data[[ci$lo]]),
      CI_hi = exp(.data[[ci$hi]])) |>
    dplyr::select(age_years, contrast, OR, CI_lo, CI_hi, p.value)
}

#1.9.2 Wave-specific cluster contrasts (OR) at wave-median ages, robust to wave_num
cluster_contrasts_by_wave_aligned <- function(fit, data) {
  waves <- levels(data$end_wave)
  
  #1.9.2.1 Empirical medians per wave
  ages_by_wave <- data %>%
    dplyr::group_by(end_wave) %>%
    dplyr::summarise(age_med = median(age_mid, na.rm = TRUE), .groups = "drop") %>%
    dplyr::arrange(match(end_wave, waves))
  grand_mean <- mean(data$age_mid, na.rm = TRUE)
  mf_names <- try(names(model.frame(fit)), silent = TRUE)
  out_list <- vector("list", length(waves))
  for (i in seq_along(waves)) {
    w <- waves[i]
    a <- ages_by_wave$age_med[i]
    at <- list(
      cluster = levels(data$cluster),
      age_mid_between = a - grand_mean,
      age_mid_cwc = 0,
      baseline_status = 0,
      end_wave = factor(w, levels = waves),
      sex = levels(data$sex)[1],
      site_factor = levels(data$site_factor)[1])
    if (!inherits(mf_names, "try-error")) {
      # supply wave_num if needed; drop unused within-age variant, and unused wave coding
      if ("wave_num" %in% mf_names) at$wave_num <- i - 1L
      if (!"end_wave" %in% mf_names) at$end_wave <- NULL
      if (!"wave_num" %in% mf_names) at$wave_num <- NULL
      if ("log_dt" %in% mf_names) at$log_dt <- 0
      at <- at[names(at) %in% mf_names]
    }
    em <- emmeans::emmeans(fit, ~ cluster, at = at)
    ct <- emmeans::contrast(em, "revpairwise", adjust = "none")
    sm <- summary(ct, infer = c(TRUE, TRUE)) |> tibble::as_tibble()
    ci <- emm_ci_cols(sm)
    out_list[[i]] <- sm |>
      dplyr::transmute(
        end_wave = as.character(w),
        contrast,
        OR = exp(estimate),
        CI_lo = exp(.data[[ci$lo]]),
        CI_hi = exp(.data[[ci$hi]]),
        p.value
      )
  }
  dplyr::bind_rows(out_list)
}


#1.10 Safe evaluation wrapper used to prevent per-outcome failures from aborting the loop
safe_or_null <- function(expr) {
  out <- try(expr, silent = TRUE)
  if (inherits(out, "try-error")) NULL else out
}

#1.11 UI helper for wrapped plot titles to avoid overflow
wrap_title <- function(x, width = 70) {
  stringr::str_wrap(x, width = width)
}

#1.12 Term filter for tables: keep clusters and core covariates; drop wave FEs and intercept
keep_terms <- function(df) {
  if (!"term" %in% names(df)) return(df)
  df %>%
    dplyr::filter(
      !grepl("^(Intercept)$", term),
      grepl("^cluster", term) |
      grepl("^age_mid_between$", term) |
      grepl("^age_mid_cwc$", term) |
      grepl("^baseline_status$", term) |
      grepl("^sex", term) |
      grepl("^cluster.*:age_mid_between$", term)
    )
}

#1.13 Refit if boundary (drop ~0 variance RE) - but NEVER drop participant_id
refit_if_boundary <- function(fit, form, data, link) {
  vc <- tryCatch(lme4::VarCorr(fit), error = function(e) NULL)
  if (is.null(vc)) return(fit)
  vv <- sapply(vc, function(x) attr(x, "stddev")^2)
  tiny <- names(vv)[vv < 1e-3]
  # do not drop the subject intercept even if tiny
  tiny <- tiny[!grepl("^participant_id", tiny)]
  if (length(tiny) == 0) return(fit)
  message("Dropping near-zero RE: ", paste(tiny, collapse = ", "))
  form2 <- update.formula(form, . ~ .)
  if (any(grepl("^family_id", tiny)))   form2 <- update.formula(form2, . ~ . - (1 | family_id))
  if (any(grepl("^site_factor", tiny))) form2 <- update.formula(form2, . ~ . - (1 | site_factor))
  fit_glmer_safe(form2, data, link = link)
}

#1.13.1 Detect whether a random-effect term for a given group is present in a formula
has_re_term <- function(form, grp) {
  bars <- try(lme4::findbars(form), silent = TRUE)
  if (inherits(bars, "try-error") || length(bars) == 0) return(FALSE)
  any(vapply(bars, function(b) {
    grepl(paste0("\\|\\s*", grp, "\\)"), paste(deparse(b), collapse = " "), perl = TRUE)
  }, logical(1)))
}

#1.13.2 Iteratively simplify random-effects if convergence/singularity persists
simplify_random_effects <- function(fit, form, data, link) {
  di <- try(diag_report(fit), silent = TRUE)
  if (inherits(di, "try-error")) return(fit)
  if (isTRUE(di$converged) && !isTRUE(di$is_singular)) return(fit)

  #1.13.2.1 Drop order: family first (we'll use CR2 by family), then site. Never drop participant.
  candidates <- c("family_id", "site_factor")
  best_fit  <- fit
  best_form <- form
  for (grp in candidates) {
    if (has_re_term(best_form, grp)) {
      form_try <- update.formula(best_form, as.formula(paste0(". ~ . - (1 | ", grp, ")")))
      fit_try  <- safe_or_null(fit_glmer_safe(form_try, data, link = link))
      if (!is.null(fit_try)) {
        di_try <- diag_report(fit_try)
        if (isTRUE(di_try$converged) && !isTRUE(di_try$is_singular)) {
          message("Simplified random-effects by dropping (1|", grp, ").")
          return(fit_try)
        } else {
          best_fit <- fit_try
          best_form <- form_try}
      }
    }
  }
  best_fit
}

#1.13.3 Force a participant-only RE structure
force_participant_only <- function(form, data, link) {
  
  #1.13.3.1 Strip out all REs except (1|participant_id)
  f2 <- update.formula(form, . ~ .)
  if (has_re_term(f2, "family_id"))   f2 <- update.formula(f2, . ~ . - (1 | family_id))
  if (has_re_term(f2, "site_factor")) f2 <- update.formula(f2, . ~ . - (1 | site_factor))
  
  #1.13.3.2 Ensure participant term is present
  if (!has_re_term(f2, "participant_id"))
    f2 <- update.formula(f2, . ~ . + (1 | participant_id))
  fit_glmer_safe(f2, data, link = link)
}

#1.14 Compute Brier score (lower is better; calibration-weighted accuracy)
brier_score <- function(obs, pr) {
  obs <- as.numeric(obs)
  mean((obs - pr)^2, na.rm = TRUE)
}

#1.15 Compute log loss (binary cross-entropy)
log_loss <- function(obs, pr, eps = 1e-12) {
  obs <- as.numeric(obs)
  prc <- pmin(pmax(pr, eps), 1 - eps)
  -mean(obs * log(prc) + (1 - obs) * log(1 - prc), na.rm = TRUE)
}

#1.16 Summarize performance per fit (R2, Brier, LogLoss); robust to GLMMs
perf_metrics <- function(fit, data) {
  pr <- try(predict(fit, type = "response", re.form = NA), silent = TRUE)
  R2m <- R2c <- NA_real_
  if (inherits(try(performance::r2_nakagawa, silent = TRUE), "function")) {
    r2 <- try(performance::r2_nakagawa(fit), silent = TRUE)
    if (!inherits(r2, "try-error")) {
      R2m <- as.numeric(r2$R2_marginal)
      R2c <- as.numeric(r2$R2_conditional)
    }
  }
  bs <- if (!inherits(pr, "try-error")) brier_score(data$event, pr) else NA_real_
  ll <- if (!inherits(pr, "try-error")) log_loss(data$event, pr) else NA_real_
  tibble(R2_marginal = R2m, R2_conditional = R2c, Brier = bs, LogLoss = ll)
}

#1.17 Save performance::check_model() panel to file
save_check_model_plots <- function(fit, tag, width = 9, height = 6, dpi = 220) {
  cm <- try(performance::check_model(fit), silent = TRUE)
  if (inherits(cm, "try-error")) return(NULL)
  p <- try(if (requireNamespace("see", quietly = TRUE)) see::plot(cm) else cm, silent = TRUE)
  if (inherits(p, "try-error")) return(NULL)
  fn <- file.path(OUT_DIR, glue::glue("check_model_{tag}.png"))
  if (requireNamespace("ragg", quietly = TRUE)) {
    ggplot2::ggsave(filename = fn, plot = p, device = ragg::agg_png, width = width, height = height, units = "in", dpi = dpi)
  } else {
    ggplot2::ggsave(filename = fn, plot = p, width = width, height = height, units = "in", dpi = dpi)
  }
  tibble(file = fn)
}

#1.18 Save DHARMa residual plots and tests; guarded if DHARMa missing
save_dharma_plots_and_tests <- function(fit, tag) {
  if (!requireNamespace("DHARMa", quietly = TRUE)) return(NULL)
  set.seed(params$seed)
  sr <- try(DHARMa::simulateResiduals(fit, n = 1000, refit = FALSE), silent = TRUE)
  if (inherits(sr, "try-error")) return(NULL)
  fn <- file.path(OUT_DIR, glue::glue("dharma_{tag}.png"))
  try({
    if (requireNamespace("ragg", quietly = TRUE)) {
      ragg::agg_png(filename = fn, width = 1800, height = 1200, units = "px", res = 144)
    } else {
      png(filename = fn, width = 1800, height = 1200, res = 144)
    }
    plot(sr)
    dev.off()
  }, silent = TRUE)
  td <- try(DHARMa::testDispersion(sr), silent = TRUE)
  tz <- try(DHARMa::testZeroInflation(sr), silent = TRUE)
  tibble(file = fn,
    p_dispersion = if (!inherits(td, "try-error")) td$p.value else NA_real_,
    p_zeroinfl = if (!inherits(tz, "try-error")) tz$p.value else NA_real_)
}

#1.19 Compute cumulative risk across waves for a reference profile
cumrisk_by_wave <- function(fit,
  data,
  ref_cluster = levels(data$cluster),
  sex_ref = levels(data$sex)[1],
  site_ref = levels(data$site_factor)[1],
  baseline_ref = 0,
  age_between = 0,
  age_cwc = 0) {
  nd <- expand.grid(
    end_wave = levels(data$end_wave),
    cluster = ref_cluster,
    age_mid_between = age_between,
    age_mid_cwc = age_cwc,
    baseline_status = baseline_ref,
    sex = sex_ref,
    site_factor = site_ref)
  nd <- nd %>% arrange(cluster, end_wave)
  nd$haz <- predict(fit,
    newdata = nd,
    type = "response",
    re.form = NA)
  nd %>%
    group_by(cluster) %>%
    mutate(surv = cumprod(1 - haz), cumrisk = 1 - surv) %>%
    ungroup()
}

#1.20 Fixed-wave predictions with 95% CIs via emmeans (response scale) with safe fallback
pred_fixedwave_with_ci <- function(fit, data, ages = ages_pred_vec, wave_ref = params$wave_ref) {
  if (missing(ages) || is.null(ages) || length(ages) == 0 || all(!is.finite(ages)))
    ages <- c(11.004729021633345, 13.116629238715475, 15.2109589041096)
  grand_mean <- mean(data$age_mid, na.rm = TRUE)
  at_list <- list(
    cluster = levels(data$cluster),
    age_mid_between = ages - grand_mean,
    age_mid_cwc = 0,
    baseline_status = 0,
    end_wave = factor(wave_ref, levels = levels(data$end_wave)),
    sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1])

  #1.20.1 Keep only variables that exist in the fitted model
  mf_names <- try(names(model.frame(fit)), silent = TRUE)
  if (!inherits(mf_names, "try-error")) {
    
    #1.20.1.1 Map wave_ref -> numeric index if model uses wave_num
    if ("wave_num" %in% mf_names) {
      wlev <- levels(data$end_wave)
      at_list$wave_num <- match(wave_ref, wlev) - 1L
    }
  
    #1.20.1.2 Keep only columns the model actually uses
    at_list <- at_list[names(at_list) %in% mf_names]
  }

  #1.20.2 Try emmeans only; if that fails, fallback to predict()
  em <- try(emmeans::emmeans(fit, ~ cluster | age_mid_between, at = at_list, type = "response"), silent = TRUE)
  if (!inherits(em, "try-error")) {
    sm <- tibble::as_tibble(summary(em, infer = c(TRUE, TRUE)))
    resp <- emm_resp_col(sm); ci <- emm_ci_cols(sm)
    lo_col <- if (is.null(ci$lo)) NA_character_ else ci$lo
    hi_col <- if (is.null(ci$hi)) NA_character_ else ci$hi
    return(dplyr::transmute(
      sm,
      cluster,
      age_years = round(age_mid_between + grand_mean, 2),
      pred = if (is.null(resp)) NA_real_ else .data[[resp]],
      lower = if (is.na(lo_col)) NA_real_ else .data[[lo_col]],
      upper = if (is.na(hi_col)) NA_real_ else .data[[hi_col]],
      end_wave = wave_ref
    ))
  }

  #1.20.3 Fallback: point predictions (no CI)
  nd <- expand.grid(
    cluster = levels(data$cluster),
    age_mid_between = ages - grand_mean,
    age_mid_cwc = 0,
    baseline_status = 0,
    end_wave = factor(wave_ref, levels = levels(data$end_wave)),
    sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1])
  if ("wave_num" %in% names(model.frame(fit))) {
    wlev <- levels(data$end_wave)
    nd$wave_num <- match(wave_ref, wlev) - 1L
  }
  nd$age_years <- round(nd$age_mid_between + grand_mean, 2)
  nd$pred <- as.numeric(predict(fit, newdata = nd, type = "response", re.form = NA))
  nd$lower <- NA_real_; nd$upper <- NA_real_
  dplyr::select(nd, cluster, age_years, pred, lower, upper, end_wave)
}

#1.21 Wave-aligned predictions (pair age to wave) with safe fallback
pred_aligned_with_ci <- function(fit, data, ages = ages_pred_vec) {
  if (missing(ages) || is.null(ages) || length(ages) == 0 || all(!is.finite(ages)))
    ages <- c(11.004729021633345, 13.116629238715475, 15.2109589041096)
  waves <- levels(data$end_wave)
  grand_mean <- mean(data$age_mid, na.rm = TRUE)
  k <- min(length(ages), length(waves))
  outs <- vector("list", k)
  for (i in seq_len(k)) {
    at_list <- list(
      cluster = levels(data$cluster),
      age_mid_between = ages[i] - grand_mean,
      age_mid_cwc = 0,
      baseline_status = 0,
      end_wave = factor(waves[i], levels = levels(data$end_wave)),
      sex = levels(data$sex)[1],
      site_factor = levels(data$site_factor)[1])
    mf_names <- try(names(model.frame(fit)), silent = TRUE)
    if (!inherits(mf_names, "try-error")) {
      if ("wave_num" %in% mf_names) at_list$wave_num <- i - 1L
      at_list <- at_list[names(at_list) %in% mf_names]
}    
    em <- try(emmeans::emmeans(fit, ~ cluster, at = at_list, type = "response"), silent = TRUE)
    if (!inherits(em, "try-error")) {
      sm <- tibble::as_tibble(summary(em, infer = c(TRUE, TRUE)))
      resp <- emm_resp_col(sm); ci <- emm_ci_cols(sm)
      lo_col <- if (is.null(ci$lo)) NA_character_ else ci$lo
      hi_col <- if (is.null(ci$hi)) NA_character_ else ci$hi
      outs[[i]] <- dplyr::transmute(
        sm,
        cluster,
        end_wave = waves[i],
        age_years = round(ages[i], 2),
        pred = if (is.null(resp)) NA_real_ else .data[[resp]],
        lower = if (is.na(lo_col)) NA_real_ else .data[[lo_col]],
        upper = if (is.na(hi_col)) NA_real_ else .data[[hi_col]])
    } else {

      #1.21.1 Fallback: point predictions (no CI)
      nd <- expand.grid(
        cluster = levels(data$cluster),
        age_mid_between = ages[i] - grand_mean,
        age_mid_cwc = 0,
        baseline_status = 0,
        end_wave = factor(waves[i], levels = levels(data$end_wave)),
        sex = levels(data$sex)[1],
        site_factor = levels(data$site_factor)[1])
      if ("wave_num" %in% names(model.frame(fit))) nd$wave_num <- i - 1L
      outs[[i]] <- tibble::tibble(
        cluster = nd$cluster,
        end_wave = waves[i],
        age_years = round(ages[i], 2),
        pred = as.numeric(predict(fit, newdata = nd, type = "response", re.form = NA)),
        lower = NA_real_, upper = NA_real_)}
  }
  dplyr::bind_rows(outs)
}

#1.22 Per-interval hazard table by cluster x wave (95% CI via emmeans) with safe fallback
hazard_by_wave_ci <- function(fit, data) {
  at_list <- list(
    cluster = levels(data$cluster),
    age_mid_between = 0, age_mid_cwc = 0,
    baseline_status = 0,
    end_wave = levels(data$end_wave),
    wave_num = seq_along(levels(data$end_wave)) - 1L,  # handy if needed
    sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1])
  mf_names <- try(names(model.frame(fit)), silent = TRUE)

  #1.22.1 Choose which "wave" variable to condition on
  cond_var <- if (!inherits(mf_names, "try-error") && "end_wave" %in% mf_names) "end_wave"
    else if (!inherits(mf_names, "try-error") && "wave_num" %in% mf_names) "wave_num"
    else NULL
  if (!is.null(cond_var)) {
    at_use <- at_list[names(at_list) %in% mf_names]
    spec <- stats::as.formula(paste0("~ cluster | ", cond_var))
    em <- try(emmeans::emmeans(fit, spec, at = at_use, type = "response"), silent = TRUE)
    if (!inherits(em, "try-error")) {
      sm <- tibble::as_tibble(summary(em, infer = c(TRUE, TRUE)))
      resp <- emm_resp_col(sm); ci <- emm_ci_cols(sm)
      out <- dplyr::transmute(
        sm,
        end_wave = if (cond_var == "end_wave")
          as.character(.data$end_wave)
        else
          levels(data$end_wave)[.data$wave_num + 1L],
        cluster,
        hazard = if (is.null(resp)) NA_real_ else .data[[resp]],
        lo = if (is.null(ci$lo)) NA_real_ else .data[[ci$lo]],
        hi = if (is.null(ci$hi)) NA_real_ else .data[[ci$hi]])
      return(out)
    }
  }

  #1.22.2 Fallback: point preds; include wave_num if present so predict() is happy
  nd <- expand.grid(
    end_wave = levels(data$end_wave),
    cluster = levels(data$cluster),
    age_mid_between = 0, age_mid_cwc = 0,
    baseline_status = 0,
    sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1]) %>% 
  dplyr::arrange(end_wave, cluster)
  if (!inherits(mf_names, "try-error") && "wave_num" %in% mf_names)
    nd$wave_num <- match(nd$end_wave, levels(data$end_wave)) - 1L
  tibble::tibble(
    end_wave = nd$end_wave,
    cluster = nd$cluster,
    hazard = as.numeric(predict(fit, newdata = nd, type = "response", re.form = NA)),
    lo = NA_real_, hi = NA_real_
  )
}

#1.23 Cumulative risk by wave with bootstrap CIs (parametric via bootMer)
cumrisk_by_wave_ci <- function(fit, data, B = 500) {
  #1.23.1 Build reference newdata
  nd <- expand.grid(
    end_wave = levels(data$end_wave),
    cluster = levels(data$cluster),
    age_mid_between = 0, age_mid_cwc = 0,
    baseline_status = 0, sex = levels(data$sex)[1],
    site_factor = levels(data$site_factor)[1]
  ) %>% dplyr::arrange(cluster, end_wave)

  #1.23.2 If the fitted model used an offset(log_dt) (cloglog sensitivity), supply it
  mf_names <- try(names(model.frame(fit)), silent = TRUE)
  if (!inherits(mf_names, "try-error") && "log_dt" %in% mf_names) nd$log_dt <- 0

  #1.23.3 Point predictions on response scale
  haz_hat <- as.numeric(predict(fit, newdata = nd, type = "response", re.form = NA))

  #1.23.4 Helper: hazards -> cumulative risk by wave
  to_cum <- function(h) {
    df <- nd
    df$haz <- h
    df %>%
      dplyr::group_by(cluster) %>%
      dplyr::mutate(surv = cumprod(1 - haz), cumrisk = 1 - surv) %>%
      dplyr::ungroup() %>%
      dplyr::select(end_wave, cluster, cumrisk)
  }

  #1.23.5 Try parametric bootstrap for CIs; fall back cleanly on any error
  can_boot <- isTRUE("bootMer" %in% getNamespaceExports("lme4"))
  if (can_boot) {
    sim <- try(
      lme4::bootMer(
        fit,
        FUN = function(fm) as.numeric(predict(fm, newdata = nd, type = "response", re.form = NA)),
        nsim = B, use.u = FALSE, type = "parametric", seed = params$seed),
      silent = TRUE)
    if (!inherits(sim, "try-error")) {
      sims <- as_tibble(sim$t)
      cis <- lapply(seq_len(nrow(nd)), function(j) {
        qs <- quantile(sims[[j]], probs = c(0.025, 0.975), na.rm = TRUE)
        tibble(row = j, lohaz = qs[[1]], hihaz = qs[[2]])
      }) %>% bind_rows()
      nd2 <- nd %>% dplyr::mutate(row = dplyr::row_number(), haz = haz_hat) %>% dplyr::left_join(cis, by = "row")
      lo <- to_cum(nd2$lohaz) %>% dplyr::rename(cumrisk_lo = cumrisk)
      hi <- to_cum(nd2$hihaz) %>% dplyr::rename(cumrisk_hi = cumrisk)
      pt <- to_cum(nd2$haz)   %>% dplyr::rename(cumrisk    = cumrisk)
      return(pt %>% dplyr::left_join(lo, by = c("end_wave","cluster")) %>% dplyr::left_join(hi, by = c("end_wave","cluster")))
    } else {
      warning("bootMer failed; returning point estimates only.")
    }
  } else {
    warning("bootMer not available; returning point estimates only.")
  }

  #1.23.6 Fallback: point estimates, NA CIs
  to_cum(haz_hat) %>% dplyr::mutate(cumrisk_lo = NA_real_, cumrisk_hi = NA_real_)
}

#1.24 Calibration summary (intercept, slope, ECE, MCE)
calibration_summary <- function(fit, data) {
  pr <- as.numeric(predict(fit, type = "response", re.form = NA))
  dat <- data.frame(event = as.numeric(data$event), pr = pr)
  dat$lp <- qlogis(pmin(pmax(dat$pr, 1e-9), 1-1e-9))

  #1.24.1 Intercept-only with offset => calibration-in-the-large (target 0)
  cil_fit <- glm(event ~ 1 + offset(lp), family = binomial(), data = dat)
  cil <- coef(cil_fit)[1]

  #1.24.2 Slope model (target slope ~1, intercept ~0)
  sl_fit <- glm(event ~ lp, family = binomial(), data = dat)
  slope <- coef(sl_fit)[2]; intercept <- coef(sl_fit)[1]

  #1.24.3 Deciles ECE/MCE
  dd <- dplyr::tibble(event = dat$event, pr = dat$pr) |>
    dplyr::mutate(dec = dplyr::ntile(pr, 10)) |>
    dplyr::group_by(dec) |>
    dplyr::summarise(pred = mean(pr), obs = mean(event), n = dplyr::n(), .groups="drop") |>
    dplyr::mutate(abs_err = abs(obs - pred))
  ece <- with(dd, sum(n / sum(n) * abs_err))
  mce <- max(dd$abs_err)
  tibble(cali_intercept = unname(cil), slope = unname(slope), intercept = unname(intercept), ECE = ece, MCE = mce)
}

#1.25 Extract clean emmeans results
#1.25.1 Pick the CI column names that exist in an emmeans summary
emm_ci_cols <- function(sm) {
  lo <- intersect(c("asymp.LCL","lower.CL","LCL"), names(sm))[1]
  hi <- intersect(c("asymp.UCL","upper.CL","UCL"), names(sm))[1]
  list(lo = lo, hi = hi)
}

#1.25.2 Pick the response-scale column from an emmeans summary
emm_resp_col <- function(sm) {
  # common names across families; last two are safe fallbacks
  out <- intersect(c("response","prob","rate","emmean"), names(sm))
  if (length(out)) out[[1]] else NULL
}

#1.26 Deep fixed-effect design diagnostics
design_diag <- function(form, data, out_name = "unknown") {

  #1.26.1 Build fixed-effect design matrix (no random effects)
  rhs <- lme4::nobars(form)
  X <- model.matrix(rhs, data = data)
  # drop intercept for kappa/VIF calcs
  Xi <- X[, colnames(X) != "(Intercept)", drop = FALSE]
  p <- ncol(Xi); n <- nrow(Xi)
  rk <- tryCatch(qr(Xi)$rank, error = function(e) NA_integer_)

  #1.26.2 Condition numbers (raw & scaled)
  kappa_raw <- tryCatch(kappa(Xi), error = function(e) NA_real_)
  kappa_scaled <- tryCatch(kappa(scale(Xi, center = TRUE, scale = TRUE)), error = function(e) NA_real_)
  
  #1.26.3 Per-term VIF (via performance::check_collinearity)
  vif_tbl <- tryCatch({
    cc <- performance::check_collinearity(stats::glm(form, data = data, family = binomial()))
    tibble::as_tibble(cc)
  }, error = function(e) {
    tryCatch({
      cc <- performance::check_collinearity(lme4::glmer(form, data = data, family = binomial(), nAGQ = 0))
      tibble::as_tibble(cc)
    }, error = function(e2) tibble())
  })
  
  #1.26.4 Top pairwise correlations among design columns (helps pinpoint culprits)
  cor_pairs <- tibble()
  if (p >= 2) {
    C <- tryCatch(cor(scale(Xi), use = "pairwise.complete.obs"), error = function(e) NULL)
    if (!is.null(C)) {
      C[lower.tri(C, diag = TRUE)] <- NA
      cor_pairs <- as.data.frame(as.table(C)) |>
        dplyr::rename(var1 = Var1, var2 = Var2, r = Freq) |>
        dplyr::filter(is.finite(r)) |>
        dplyr::arrange(dplyr::desc(abs(r))) |>
        dplyr::slice(1:min(20, dplyr::n())) |>
        tibble::as_tibble()
    }
  }
  
  #1.26.5Linear-combo detection if caret is present
  lc <- tryCatch({
    if (requireNamespace("caret", quietly = TRUE)) {
      z <- caret::findLinearCombos(Xi)
      tibble::tibble(linear_combos = if (length(z$combos)) sapply(z$combos, paste, collapse = " + ") else character())
    } else tibble()
  }, error = function(e) tibble())
  list(
    meta = tibble::tibble(outcome = out_name, n = n, p = p, rank = rk, kappa_raw = kappa_raw, kappa_scaled = kappa_scaled),
    vif = dplyr::mutate(vif_tbl, outcome = out_name, .before = 1),
    cors = dplyr::mutate(cor_pairs, outcome = out_name, .before = 1),
    lincomb = dplyr::mutate(lc, outcome = out_name, .before = 1)
  )
}

#1.27 Sparse/empty cell scan (common root cause for singularity/separation)
sparse_cells <- function(data, vars = c("end_wave","cluster","sex"), y = "event", min_n = 5) {
  df <- data |>
    dplyr::group_by(dplyr::across(dplyr::all_of(vars))) |>
    dplyr::summarise(
      n = dplyr::n(),
      n_events = sum(.data[[y]] == 1L, na.rm = TRUE),
      n_nonev  = sum(.data[[y]] == 0L, na.rm = TRUE),
      .groups = "drop") |>
    dplyr::mutate(flag_zero_event = n_events == 0,
      flag_zero_nonev = n_nonev == 0,
      flag_small = n < min_n)
  df
}

#1.28 Fixed-part separation screen (quick GLM-only)
sep_screen <- function(form, data) {
  if (!requireNamespace("brglm2", quietly = TRUE)) return(tibble::tibble(note = "brglm2 not installed"))
  out <- tryCatch(brglm2::detect_separation(form, data = data, family = binomial()), error = function(e) NULL)
  if (is.null(out)) return(tibble::tibble(note = "detect_separation failed"))
  tibble::tibble(separation = out$separation, note = if (isTRUE(out$separation)) "Possible separation in fixed part" else "No separation detected")
}

#1.29 Random-effects boundary report
re_boundary <- function(fit, out_name = "unknown") {
  vc <- tryCatch(lme4::VarCorr(fit), error = function(e) NULL)
  if (is.null(vc)) return(tibble())
  tibble::tibble(outcome = out_name,
    grp = names(vc),
    var = sapply(vc, function(x) attr(x, "stddev")^2),
    sd = sapply(vc, function(x) attr(x, "stddev"))) |>
    dplyr::mutate(flag_tiny = var < 1e-4)
}

#1.30 Collinearity + fit quality checks (used to pick a BD-II candidate)
max_vif <- function(fit) {
  co <- try(performance::check_collinearity(fit, component = "conditional"), silent = TRUE)
  if (inherits(co, "try-error")) return(Inf)
  suppressWarnings(max(co$VIF, na.rm = TRUE))
}

#1.30.1 Check convergence (robust across performance versions)
ok_convergence <- function(fit) {
  cv <- try(performance::check_convergence(fit), silent = TRUE)
  if (inherits(cv, "try-error")) return(TRUE)   # don't block candidate selection on a check error

  #1.30.1.1 Try several possible return shapes from performance::check_convergence()
  val <- tryCatch({
    if (!is.null(cv$converged)) {
      cv$converged
    } else if (is.data.frame(cv) && "converged" %in% names(cv)) {
      cv[["converged"]]
    } else if (!is.null(attr(cv, "converged"))) {
      attr(cv, "converged")
    } else if (is.list(cv) && length(cv) == 1 && is.logical(cv[[1]])) {
      cv[[1]]
    } else if (is.logical(cv) && length(cv) == 1) {
      cv
    } else {

      #1.30.1.2 Fallback on lme4 optinfo: consider "OK" if there are no convergence messages
      oi <- try(fit@optinfo, silent = TRUE)
      if (!inherits(oi, "try-error")) {
        msgs <- c(oi$conv$lme4$messages, oi$conv$lme4$message, oi$conv$messages)
        length(unlist(msgs)) == 0
      } else TRUE
    }
  }, error = function(e) NA)
  isTRUE(val)
}
 
#1.30.2 Residualize a numeric x on a factor f -> removes linear dependence on f levels.
resid_on_factor <- function(x, f) {

  #1.30.2.1 NA-robust residuals from x ~ f
  out <- rep(NA_real_, length(x))
  ok <- is.finite(x) & !is.na(f)
  if (any(ok)) out[ok] <- resid(lm(x ~ f, na.action = na.exclude))
  out
}

#1.31 Create a safe CSV writer that skips empties
write_if_any <- function(df, path) {
  if (is.data.frame(df) && nrow(df) > 0 && ncol(df) > 0) {
    readr::write_csv(df, path)
  } else {
    message("Skipping write for ", basename(path), " (empty).")
  }
}

```

## 2. Fit Discrete-Time Hazard Models

-   Iterate over BD outcomes and fit the GLMM once per outcome (primary logit link)
-   Extract Wald and CR2 summaries; compute predicted hazards across ages; calibration; AUC; diagnostics; and `emmeans` cluster contrasts
-   Fit a cloglog model for each outcome as a discrete-hazard sensitivity check and export parallel summaries
-   Persist all results to CSVs (effects, predictions, calibration, AUC, diagnostics, contrasts) and save model objects (`fit_primary_*`, `fit_cloglog_*`) to `OUT_DIR`

```{r fit dth models, warning = FALSE}

## 2. Fit models (primary link + sensitivity), summarize, and save ##

#2.1 Outcomes to iterate on for this analysis
OUTCOMES <- c("bipolar_I","bipolar_II","bd_nos","any_bsd")

#2.2 Create containers for results
fits_primary <- list(); wald_primary <- list(); cr2_primary <- list()
preds_primary_aligned <- list(); preds_primary_fixedwave <- list()
cal_primary <- list(); auc_primary <- list(); diag_primary <- list()
emm_primary <- list(); perf_primary <- list()
fits_sens <- list(); wald_sens <- list(); cr2_sens <- list()
dharma_tests_primary <- list()
cal_summaries <- list()
hazard_tables <- list()
cumrisk_tables <- list()

#2.3 Ensure the model formula is optimized
#2.3.1 Establish and implement the base formula
form_full <- build_formula(link = params$link_primary)

#2.3.2 Create a helper to drop cluster:age_mid_between only (keep main effects)
strip_interaction <- function(f) update.formula(f, . ~ . - cluster:age_mid_between)

#2.3.3 Outcomes where we always drop the interaction (stability; non-sig elsewhere)
DROP_INTERACTION_ALWAYS <- character(0)

#2.3.4 Outcomes where we include cluster by wave intx in the primary model
ADD_CLUSTER_WAVE <- character(0)

#2.4 Loop per outcome
for (out in OUTCOMES) {
  message("Fitting primary (", params$link_primary, "): ", out)
  dat_o <- bd_pp_model %>% filter(outcome == out) %>% droplevels()
  fit_o <- NULL
  if (nlevels(dat_o$cluster) < nlevels(bd_pp_model$cluster))
    message("Note: some clusters absent in outcome = ", out, "; predictions to absent clusters would be extrapolations.")

    #2.4.0 BD-II targeted stabilization branch
  if (identical(out, "bipolar_II")) {
    message("BD-II: applying staged stabilization (participant-only RE; simple age/wave candidates; no orthogonalization).")
  
    #2.4.0.1 Empirical wave index (0,1,2) in case we need a 1-df baseline trend
    dat_o <- dat_o %>% dplyr::mutate(wave_num = as.integer(end_wave) - 1L)
  
    #2.4.0.2 (Removed: age_mid_cwc orthogonalization; no longer needed with nAGQ = 0.)
    # dat_o <- dat_o %>%
    #   dplyr::mutate(age_mid_cwc_orth = resid_on_factor(age_mid_cwc, end_wave))
  
    #2.4.0.3 Candidate formulas (all keep the required (1|participant_id))
    f_RE1 <- event ~ cluster + age_mid_between + age_mid_cwc + sex + end_wave + (1 | participant_id)
    f_WAVENUM <- event ~ cluster + age_mid_between + age_mid_cwc + sex + wave_num + (1 | participant_id)
    f_DROPcwc <- event ~ cluster + age_mid_between + sex + end_wave + (1 | participant_id)
  
    #2.4.0.4 Try candidates in order; keep the first that converges AND has adj. VIF <= threshold
    VIF_THRESH <- 10
    try_one <- function(form, dat = dat_o) {
      fit <- safe_or_null(fit_glmer_safe(form, dat, link = params$link_primary))
      if (is.null(fit)) return(NULL)
      list(
        fit = fit,
        ok = ok_convergence(fit) && (max_vif(fit) <= VIF_THRESH),
        adj_vif = max_vif(fit)
      )
    }
    cand_order <- list(
      RE1 = list(form = f_RE1,     dat = dat_o, note = "Participant-only RE"),
      WAVENUM = list(form = f_WAVENUM, dat = dat_o, note = "end_wave -> wave_num linear (1 df)"),
      DROPcwc = list(form = f_DROPcwc, dat = dat_o, note = "drop age_mid_cwc; keep between-age + end_wave")
    )
    chosen <- NULL
    tried  <- list()
    for (nm in names(cand_order)) {
      res <- try_one(cand_order[[nm]]$form, cand_order[[nm]]$dat)
      if (is.null(res)) next
      tried[[nm]] <- res$adj_vif
      message(
        "BD-II candidate ", nm,
        " adj.VIF=", sprintf("%.2f", res$adj_vif),
        " | converged=", ok_convergence(res$fit),
        " (", cand_order[[nm]]$note, ")"
      )
      if (isTRUE(res$ok)) {
        chosen <- res$fit
        break
      }
    }
  
    #2.4.0.5 If none met both criteria, try weakly-informative priors on the most principled spec (RE1; no orthogonalization)
    if (is.null(chosen)) {
      if (requireNamespace("blme", quietly = TRUE)) {
        message("BD-II: trying bglmer with weak priors on RE1 spec (no orthogonalization).")
        chosen <- safe_or_null(
          blme::bglmer(
            f_RE1, data = dat_o, family = binomial(),
            fixef.prior = blme::normal(scale = 2.5),
            control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))
          )
        )
        if (!is.null(chosen)) {
          message(
            "BD-II bglmer adj.VIF=", sprintf("%.2f", max_vif(chosen)),
            " | converged=", ok_convergence(chosen)
          )
        }
      } else {
        message("BD-II: blme not installed; keeping the best of attempted fits so far.")
      }
    }
  
    #2.4.0.6 As a final fallback, if still NULL, keep the best attempted (lowest adj.VIF) even if it just missed the threshold
    if (is.null(chosen) && length(tried)) {
      best_nm <- names(which.min(unlist(tried)))
      message("BD-II: selecting best attempted candidate: ", best_nm)
      
      #2.4.0.6.1 Refit that candidate to retrieve the object
      ff <- switch(
        best_nm,
        RE1 = f_RE1,
        WAVENUM = f_WAVENUM,
        DROPcwc = f_DROPcwc)
      chosen <- fit_glmer_safe(ff, dat_o, link = params$link_primary)
    }
  
    #2.4.0.7 Replace the per-outcome data and fit to flow through the rest of your pipeline
    if (!is.null(chosen)) {
      fit_o  <- chosen
      form_o <- formula(chosen)
      
      #2.4.0.8 Print a one-line summary into the HTML to document the chosen spec
      cat("\n\n**BD-II chosen spec:**", deparse(form_o), "\n\n")
    } else {
      warning("BD-II: no candidate fit could be stabilized; leaving original behavior in place.")
    }
  }

  #2.4.1 Start with full interaction - only run if BD-II branch did NOT set a fit
  if (is.null(fit_o)) {
    form_o <- form_full

    #2.4.1.1 Add cluster x wave for selected outcomes
    #if (out %in% ADD_CLUSTER_WAVE) {
      #form_o <- update.formula(form_o, . ~ . + cluster:end_wave)
      #message(out, ": adding cluster x wave to primary (evidence of time-varying cluster effect).")
    #}

    #2.4.1.2 Drop the cluster:age_mid_between interaction by design for bd_nos / any_bsd as testing revealed it is NS
    if (out %in% DROP_INTERACTION_ALWAYS) {
      form_o <- strip_interaction(form_o)
      message(out, ": dropping cluster:age_mid_between by design (stability; non-significant elsewhere).")
    }
  
    #2.4.1.3 Fit the remainder of the model terms
    fit_o <- fit_glmer_safe(form_o, dat_o, link = params$link_primary)
    fit_o <- refit_if_boundary(fit_o, form_o, dat_o, link = params$link_primary)
    fit_o <- simplify_random_effects(fit_o, form_o, dat_o, link = params$link_primary)
    form_o <- formula(fit_o)
  
    #2.4.1.4 If still singular, force participant-only RE structure
    di_tmp2 <- diag_report(fit_o)
    if (isTRUE(di_tmp2$is_singular)) {
      message(out, ": singular after simplification -> forcing participant-only RE.")
      fit_o <- force_participant_only(form_o, dat_o, link = params$link_primary)
      form_o <- formula(fit_o)
    }
  
    #2.4.1.5 If BD-II shows big collinearity, drop the interaction
    di_tmp <- diag_report(fit_o)
    if (identical(out, "bipolar_II") && !is.na(di_tmp$max_VIF) && di_tmp$max_VIF > 25) {
      message("BD-II: high VIF -> dropping cluster:age_mid_between.")
      form_bd2 <- update.formula(form_o, . ~ . - cluster:age_mid_between)
      fit_bd2 <- fit_glmer_safe(form_bd2, dat_o, link = params$link_primary)
      fit_bd2 <- simplify_random_effects(fit_bd2, form_bd2, dat_o, link = params$link_primary)
      fit_o <- fit_bd2
      form_o <- formula(fit_o)
    }
  
      #2.4.1.6 (TEMP ON; flip true -> false if needed). For bd_nos / any_bsd, do NOT change RE structure yet. We want to see the effect of dropping the interaction first
      di_tmp2 <- diag_report(fit_o)
      if (identical(out, "bd_nos") || identical(out, "any_bsd")) {
      if (isTRUE(di_tmp2$is_singular)) {
        message(out, ": still singular -> forcing participant-only RE.")
        fit_o <- force_participant_only(form_o, dat_o, link = params$link_primary)
        form_o <- formula(fit_o)
      }
    }

    #2.4.2 Only allow the diagnostic-driven simplification for other outcomes
    if (!(out %in% DROP_INTERACTION_ALWAYS) && needs_simplify(fit_o, dat_o)) {    
      message("Simplifying fixed effects for ", out, " (dropping cluster:age_mid_between due to diagnostics).")
      form_o_s <- strip_interaction(form_o)
      fit_o_s <- fit_glmer_safe(form_o_s, dat_o, link = params$link_primary)
      fit_o_s <- refit_if_boundary(fit_o_s, form_o_s, dat_o, link = params$link_primary)
      fit_o_s <- simplify_random_effects(fit_o_s, form_o_s, dat_o, link = params$link_primary)
      form_o_s <- formula(fit_o_s)

      #2.4.2.1 Keep the simplified fit only if it improves diagnostics (not singular + lower VIF or more events per param)
      di0 <- diag_report(fit_o); di1 <- diag_report(fit_o_s)
      less_sing <- isTRUE(di0$is_singular) && !isTRUE(di1$is_singular)
      vif_better <- is.finite(di1$max_VIF) && is.finite(di0$max_VIF) && di1$max_VIF < di0$max_VIF
      keep_simple <- less_sing || vif_better    
      if (keep_simple) {
        fit_o <- fit_o_s
        form_o <- form_o_s
        message("Using simplified model for ", out, ".")
      } else {
        message("Retaining full model for ", out, " (simplification did not improve diagnostics).")
      }
    }
  }

  #2.4.2.2 Fit the primary model
  fits_primary[[out]] <- fit_o

  #2.4.2.3 Deep design diagnostics
  dd <- design_diag(form_o, dat_o, out_name = out)
  sc <- sparse_cells(dat_o, vars = c("end_wave","cluster","sex"), y = "event", min_n = 5)
  ss <- sep_screen(form_o, dat_o)
  rb <- re_boundary(fit_o, out_name = out)

  #2.4.2.4 Show quick HTML snippets
  if (is.list(dd) && is.data.frame(dd$meta) && nrow(dd$meta)) knitr::kable(dd$meta, caption = glue::glue("Design meta - {out}"))
  if (is.list(dd) && is.data.frame(dd$vif)  && nrow(dd$vif)) knitr::kable(dd$vif |> dplyr::arrange(dplyr::desc(VIF)), digits = 2, caption = glue::glue("Per-term VIF - {out}"))
  if (is.data.frame(sc) && nrow(sc)) knitr::kable(sc |> dplyr::arrange(dplyr::desc(flag_zero_event), dplyr::desc(flag_zero_nonev), dplyr::desc(flag_small)), caption = glue::glue("Sparse cells - {out}"))
  if (is.data.frame(rb) && nrow(rb)) knitr::kable(rb, digits = 4, caption = glue::glue("Random effect variances - {out}"))
  if (is.data.frame(ss) && nrow(ss)) knitr::kable(ss, caption = glue::glue("Separation screen - {out}"))

  #2.4.2.5 Print the final fixed+random structure we actually used
  cat("\n\n### Final model for", out, "\n")
  cat("**Formula:**\n\n")
  print(formula(fit_o))
  cat("\n\n**VarCorr (RE std dev^2):**\n\n")
  print(lme4::VarCorr(fit_o))
  cat("\n\n")

  #2.4.3 Summaries and predictions
  wald_primary[[out]] <- safe_or_null(tidy_wald(fit_o) %>% mutate(outcome = out, model = params$link_primary, .before = 1))
  cr2_primary[[out]] <- safe_or_null(
  tidy_cr2(fit_o, cluster_var = dat_o$family_id) %>%
    mutate(outcome = out, model = params$link_primary, .before = 1))

  #2.4.3.1 Two prediction frames: (A) wave-aligned, (B) fixed-wave (wave_ref)
  preds_primary_aligned[[out]] <- safe_or_null(
    pred_aligned_with_ci(fit_o, dat_o, ages = ages_pred_vec) %>%
      dplyr::mutate(outcome = out, model = params$link_primary, pred_mode = "aligned", .before = 1))
  preds_primary_fixedwave[[out]] <- safe_or_null(
    pred_fixedwave_with_ci(fit_o, dat_o, ages = ages_pred_vec, wave_ref = params$wave_ref) %>%
      dplyr::mutate(outcome = out, model = params$link_primary, pred_mode = "fixed_wave", wave_ref = params$wave_ref, .before = 1))
  
  #2.4.3.2 Store primary fit out results
  cal_primary[[out]] <- safe_or_null(calibration_df(fit_o, dat_o) %>% mutate(outcome = out, model = params$link_primary, .before = 1))
  auc_primary[[out]] <- safe_or_null(tibble(outcome = out, model = params$link_primary, AUC = auc_interval(fit_o, dat_o)))
  diag_primary[[out]] <- safe_or_null(diag_report(fit_o) %>% mutate(outcome = out, model = params$link_primary, .before = 1))
  perf_primary[[out]] <- safe_or_null(perf_metrics(fit_o, dat_o) %>% mutate(outcome = out, model = params$link_primary, .before = 1))
  
  #2.4.3.3 Calibration summary
  cal_sum <- safe_or_null(calibration_summary(fit_o, dat_o))
  if (!is.null(cal_sum)) cal_sum <- dplyr::mutate(cal_sum, outcome = out, model = params$link_primary, .before = 1)
  if (!exists("cal_summaries")) cal_summaries <- list()
  cal_summaries[[out]] <- cal_sum

  #2.4.3.4 Absolute risk tables (per-interval hazard by wave + cumulative risk by wave, with CIs)
  haz_tbl <- safe_or_null(hazard_by_wave_ci(fit_o, dat_o))
  if (!is.null(haz_tbl)) {
    haz_tbl <- haz_tbl %>% mutate(outcome = out, model = params$link_primary, .before = 1)
    if (!exists("hazard_tables")) hazard_tables <- list()
    hazard_tables[[out]] <- haz_tbl
  }
  
  #2.4.3.5 Cumulative risk by wave
  cum_tbl <- safe_or_null(cumrisk_by_wave_ci(fit_o, dat_o, B = 500))
  if (!is.null(cum_tbl)) {
    cum_tbl <- cum_tbl %>% mutate(outcome = out, model = params$link_primary, .before = 1)
    if (!exists("cumrisk_tables")) cumrisk_tables <- list()
    cumrisk_tables[[out]] <- cum_tbl
  }

  #2.4.3.6 Emmeans cluster contrasts: allow singular if converged
  di_emm <- diag_report(fit_o)
  ok_emm <- (isTRUE(di_emm$converged) || is.na(di_emm$converged)) && nlevels(dat_o$cluster) >= 2
  ages_pred_contrasts <- if (!is.null(params$ages_pred) && length(params$ages_pred) > 0) params$ages_pred else c(12, 14, 16)
  emm_primary[[out]] <- if (ok_emm)
    safe_or_null(cluster_contrasts_by_age(fit_o, dat_o, ages = ages_pred_contrasts) %>% dplyr::mutate(outcome = out, model = params$link_primary, .before = 1))
  else NULL

  #2.4.4 Diagnostics panels
  cm_tag <- glue::glue("primary_{out}")
  safe_or_null(save_check_model_plots(fit_o, cm_tag))
  dh_tag <- glue::glue("primary_{out}")
  dh_info <- safe_or_null(save_dharma_plots_and_tests(fit_o, dh_tag))
  if (!is.null(dh_info)) dharma_tests_primary[[out]] <- dh_info

  #2.4.5 Sensitivity: complementary log-log + offset(log_dt) with same fixed effects as final form_o
  message("Fitting sensitivity (cloglog + offset log_dt): ", out)
  form_sens <- update.formula(form_o, . ~ . + offset(log_dt))
  fit_s <- fit_glmer_safe(form_sens, dat_o, link = "cloglog")
  fits_sens[[out]] <- fit_s
  wald_sens[[out]] <- safe_or_null(tidy_wald(fit_s) %>% mutate(outcome = out, model = "cloglog", .before = 1))
  cr2_sens[[out]] <- safe_or_null(
  tidy_cr2(fit_s, cluster_var = dat_o$family_id) %>%
    mutate(outcome = out, model = "cloglog", .before = 1))
}

#2.4.6 Evidence-based check for cluster:end_wave (only where we considered it)
#OUT_TO_CHECK <- c("any_bsd","bipolar_I")
#int_results <- list()

#2.4.6.1 Check for each of the outcomes specified
#for (out in OUT_TO_CHECK) {
  #fit_p <- fits_primary[[out]]
  #if (is.null(fit_p)) next
  #dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)

  #2.4.6.2 Use the final RE structure you already settled on:
  #base_form <- update.formula(formula(fit_p), . ~ . - cluster:end_wave)
  #big_form <- update.formula(base_form, . ~ . + cluster:end_wave)
  #res <- compare_models(base_form, big_form, dat_o, link = params$link_primary, B = 500, kfold = 5)
  #int_results[[out]] <- tibble::tibble(
    #outcome = out,
    #dAIC = res$dAIC, dBIC = res$dBIC, D_obs = res$D_obs, p_boot = res$p_boot,
    #cv_logloss_delta = res$cv_big$logloss - res$cv_small$logloss,
    #cv_brier_delta = res$cv_big$brier - res$cv_small$brier,
    #cv_rmse_delta = res$cv_big$rmse_wave - res$cv_small$rmse_wave,
    #VIF_big = res$diag_big$max_VIF,
    #singular_big = res$diag_big$is_singular)
  #print(int_results[[out]])
#}

#2.4.6.3 Store and save the interaction checks for each outcome specified
#interaction_checks <- dplyr::bind_rows(int_results)
#readr::write_csv(interaction_checks, file.path(OUT_DIR, "bd_dth_cluster_by_wave_modelcheck.csv"))

#2.5 Bind results of modeling
wald_all_raw <- dplyr::bind_rows(purrr::compact(c(wald_primary, wald_sens)))
cr2_all_raw <- dplyr::bind_rows(purrr::compact(c(cr2_primary, cr2_sens)))
pred_all_aligned <- dplyr::bind_rows(purrr::compact(preds_primary_aligned))
pred_all_fixedwave <- dplyr::bind_rows(purrr::compact(preds_primary_fixedwave))
cal_all <- dplyr::bind_rows(purrr::compact(cal_primary))
auc_all <- dplyr::bind_rows(purrr::compact(auc_primary))
diag_all <- dplyr::bind_rows(purrr::compact(diag_primary))
emm_all <- dplyr::bind_rows(purrr::compact(emm_primary))
perf_all <- dplyr::bind_rows(purrr::compact(perf_primary))
dharma_tests_all <- dplyr::bind_rows(purrr::compact(dharma_tests_primary))
message("Pred rows - aligned: ", nrow(pred_all_aligned), " | fixed-wave: ", nrow(pred_all_fixedwave))

#2.5.1 PH-style check: does the cluster effect vary by wave under cloglog?
#ph_tests <- list()
#for (out in OUTCOMES) {
  #fit_s <- fits_sens[[out]]
  #if (is.null(fit_s)) next
  #dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)

  #2.5.1.1 Extract the original formula from the fitted model and create the new one
  #base_form <- formula(fit_s)
  #form_ph <- update.formula(base_form, . ~ . + cluster:end_wave)

  #2.5.1.2 Fit new model with necessary terms using cloglog link, with error handling
  #fit_ph <- safe_or_null(fit_glmer_safe(form_ph, dat_o, link = "cloglog"))
  #a <- try(anova(fit_s, fit_ph, test = "Chisq"), silent = TRUE)
  #if (!inherits(a, "try-error") && nrow(a) == 2) {
    #ph_tests[[out]] <- tibble::tibble(
      #outcome = out,
      #added = "cluster:end_wave",
      #df = a$`Chi Df`[2],
      #Chisq = a$Chisq[2],
      #p_value  = a$`Pr(>Chisq)`[2]
    #)
  #}
#}

#2.5.1.3 Combine all test results into single dataframe, removing NULL entries
#ph_tests_all <- dplyr::bind_rows(purrr::compact(ph_tests))

#2.5.1.4 Display results if any tests were completed
#if (nrow(ph_tests_all) > 0) {
  #knitr::kable(ph_tests_all, digits = 3,
    #caption = "PH-style check under cloglog: LRT for cluster x wave") %>%
    #kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
#} else {
  #message("No PH-style tests computed.")
#}

#2.5.1.5 Primary logit: LRT for adding cluster:end_wave
#int_tests_logit <- list()
#has_term <- function(formula, pattern, fixed = TRUE) {
  #trms <- try(attr(terms(formula), "term.labels"), silent = TRUE)
  #if (inherits(trms, "try-error")) return(FALSE)
  #any(grepl(pattern, trms, fixed = fixed))
#}
#for (out in ADD_CLUSTER_WAVE) {
  #fit_p <- fits_primary[[out]]
  #if (is.null(fit_p)) next
  #dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)
  #base_form <- formula(fit_p)

  #2.5.1.5.1 Only run if the interaction is actually in the fitted model
  #if (!has_term(base_form, "cluster:end_wave")) next
  #form_no <- update.formula(base_form, . ~ . - cluster:end_wave)
  #fit_no <- safe_or_null(fit_glmer_safe(form_no, dat_o, link = params$link_primary))
  #if (is.null(fit_no)) next
  #a <- try(anova(fit_no, fit_p, test = "Chisq"), silent = TRUE)
  #if (!inherits(a, "try-error") && nrow(a) == 2) {
    #int_tests_logit[[out]] <- tibble::tibble(
      #outcome = out, model = params$link_primary,
      #added = "cluster:end_wave", df = a$`Chi Df`[2],
      #Chisq = a$Chisq[2], p_value = a$`Pr(>Chisq)`[2])
  #}
#}
#int_tests_logit_all <- dplyr::bind_rows(purrr::compact(int_tests_logit))
#write_if_any(int_tests_logit_all, file.path(OUT_DIR, "bd_dth_logit_cluster_by_wave_LRT.csv"))
#if (nrow(int_tests_logit_all) > 0) {
  #knitr::kable(int_tests_logit_all, digits = 3,
    #caption = "Primary logit: LRT for cluster x wave") %>%
    #kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
#}

#2.5.2 Cluster contrasts at representative ages for cloglog (HR scale)
emm_sens <- list()
for (out in OUTCOMES) {
  fit_s <- fits_sens[[out]]
  if (is.null(fit_s)) next
  dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)
  ages_use <- if (!is.null(params$ages_pred) && length(params$ages_pred) > 0) params$ages_pred else c(12, 14, 16)

  #2.5.2.1 Generate the emm
  em <- safe_or_null(
    cluster_contrasts_by_age(fit_s, dat_o, ages = ages_use) %>%
      dplyr::rename(HR = OR) %>%
      dplyr::mutate(outcome = out, model = "cloglog", .before = 1))
  if (!is.null(em)) emm_sens[[out]] <- em
}

#2.5.2.2 Save the cloglog emm
emm_cloglog_all <- dplyr::bind_rows(purrr::compact(emm_sens))

#2.5.2.3 Show an HTML table outlining the cloglog emm results
if (exists("emm_cloglog_all") && is.data.frame(emm_cloglog_all) && nrow(emm_cloglog_all) > 0) {
  knitr::kable(
    emm_cloglog_all %>% dplyr::arrange(outcome, age_years, contrast),
    digits = 3,
    caption = "Cluster contrasts (HR) at representative ages - cloglog"
  ) %>% kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
}

#2.5.2.4 Primary (logit): wave-specific cluster contrasts aligned to wave-median ages
emm_wave_primary <- list()
for (out in OUTCOMES) {
  fit_p <- fits_primary[[out]]
  if (is.null(fit_p)) next
  dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)
  emw <- safe_or_null(
    cluster_contrasts_by_wave_aligned(fit_p, dat_o) %>%
      dplyr::mutate(outcome = out, model = params$link_primary, .before = 1)
  )
  if (!is.null(emw)) emm_wave_primary[[out]] <- emw
}
emm_wave_primary_all <- dplyr::bind_rows(purrr::compact(emm_wave_primary))

#2.5.3 Per-year first-onset rates from cloglog fits (reference profile)
rates_tbls <- list()
for (out in OUTCOMES) {
  fit_s <- fits_sens[[out]]
  if (is.null(fit_s)) next
  dat_o <- bd_pp_model %>% dplyr::filter(outcome == out)

    #2.5.3.1 Reference profile that matches the other absolute-risk helpers
    nd <- expand.grid(
    end_wave = levels(dat_o$end_wave),
    cluster = levels(dat_o$cluster),
    age_mid_between = 0,
    age_mid_cwc = 0,
    baseline_status = 0,
    sex = levels(dat_o$sex)[1],
    site_factor = levels(dat_o$site_factor)[1]) %>%
    dplyr::arrange(cluster, end_wave) %>%
    dplyr::mutate(
      
      #2.5.3.1.1 Ensure end_wave is a factor with the same levels as in the model
      end_wave = factor(end_wave, levels = levels(dat_o$end_wave)),
      
      #2.5.3.1.2 Provide wave_num for models that use it (e.g., BD-II)
      wave_num = as.integer(end_wave) - 1L
    )

  #2.5.3.2 Unit-interval offset for rate-per-year predictions
  nd$log_dt <- 0

  #2.5.3.3 Under cloglog + offset(log_dt): link = log(rate) => exp(link) = rate per YEAR
  eta <- as.numeric(predict(fit_s, newdata = nd, type = "link", re.form = NA))
  rates_tbls[[out]] <- dplyr::as_tibble(nd) %>%
    dplyr::mutate(rate_per_year = exp(eta), outcome = out, .before = 1)

}

#2.5.3.3 Save rates by wave under cloglog framework
rates_by_wave <- dplyr::bind_rows(purrr::compact(rates_tbls))

#2.5.3.4 Show an HTML table of the rates by wave under cloglog framework
if (exists("rates_by_wave") && is.data.frame(rates_by_wave) && nrow(rates_by_wave) > 0) {
  knitr::kable(
    rates_by_wave %>% dplyr::arrange(outcome, end_wave, cluster),
    digits = 4,
    caption = "Per-year first-onset rates at reference profile (cloglog)"
  ) %>% kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
}

#2.5.4 Filter tables to terms of interest
wald_all <- keep_terms(wald_all_raw)
cr2_all <- keep_terms(cr2_all_raw)

#2.5.5 Save additional outputs (robust to empties)
bind_compact <- function(x) if (length(x) == 0) tibble() else dplyr::bind_rows(purrr::compact(x))
cal_summ_all <- bind_compact(cal_summaries)
haz_tables_all <- bind_compact(hazard_tables)
cumrisk_tables_all  <- bind_compact(cumrisk_tables)
if (nrow(cal_summ_all) > 0) {
  readr::write_csv(cal_summ_all, file.path(OUT_DIR, "bd_dth_calibration_summary.csv"))
} else message("No calibration summaries to save.")
if (nrow(haz_tables_all) > 0) {
  readr::write_csv(haz_tables_all, file.path(OUT_DIR, "bd_dth_abs_hazard_by_wave.csv"))
} else message("No absolute hazard-by-wave tables to save.")
if (nrow(cumrisk_tables_all) > 0) {
  readr::write_csv(cumrisk_tables_all, file.path(OUT_DIR, "bd_dth_cumrisk_by_wave.csv"))
} else message("No cumulative-risk-by-wave tables to save.")

#2.5.6 Create a helper function to label effects by link: OR for logit, HR for cloglog
add_scale_label <- function(df) {
  df %>%
    mutate(
      effect_scale = if_else(model == "cloglog", "HR (rate ratio)", "OR"),
      effect = OR) %>%
    select(model, effect_scale, outcome, term, effect, CI_lo, CI_hi, p.value)
}

#2.5.7 Label the wald and cr2 results
tbl_wald_labeled <- add_scale_label(wald_all)
tbl_cr2_labeled  <- add_scale_label(cr2_all)

#2.5.8 Print the correctly labeled results nicely, with the scale column
knitr::kable(tbl_wald_labeled %>% arrange(outcome, model),
  digits = 3,
  caption = "Fixed effects (Wald). OR for logit; HR for cloglog.") %>%
  kableExtra::kable_styling(full_width = FALSE,
    bootstrap_options = c("striped","hover","condensed","responsive"))
knitr::kable(tbl_cr2_labeled %>% arrange(outcome, model),
  digits = 3,
  caption = "Fixed effects (CR2 by family). OR for logit; HR for cloglog.") %>%
  kableExtra::kable_styling(full_width = FALSE,
    bootstrap_options = c("striped","hover","condensed","responsive"))

#2.9 Save results of modeling
#2.9.1 Write files
readr::write_csv(wald_all, file.path(OUT_DIR, "bd_dth_wald.csv"))
readr::write_csv(cr2_all, file.path(OUT_DIR, "bd_dth_cr2.csv"))
readr::write_csv(wald_all_raw, file.path(OUT_DIR, "bd_dth_wald_full.csv"))
readr::write_csv(cr2_all_raw, file.path(OUT_DIR, "bd_dth_cr2_full.csv"))
write_if_any(pred_all_aligned, file.path(OUT_DIR, "bd_dth_preds_by_age_aligned.csv"))
write_if_any(pred_all_fixedwave, file.path(OUT_DIR, "bd_dth_preds_by_age_fixed_wave.csv"))
readr::write_csv(cal_all, file.path(OUT_DIR, "bd_dth_calibration.csv"))
readr::write_csv(auc_all, file.path(OUT_DIR, "bd_dth_auc.csv"))
readr::write_csv(diag_all, file.path(OUT_DIR, "bd_dth_diagnostics.csv"))
write_if_any(emm_all, file.path(OUT_DIR, "bd_dth_cluster_contrasts_by_age.csv"))
readr::write_csv(perf_all, file.path(OUT_DIR, "bd_dth_performance.csv"))
readr::write_csv(dharma_tests_all, file.path(OUT_DIR, "bd_dth_dharma_tests.csv"))
write_if_any(emm_cloglog_all, file.path(OUT_DIR, "bd_dth_cluster_contrasts_by_age_cloglog.csv"))
write_if_any(rates_by_wave, file.path(OUT_DIR, "bd_dth_rates_per_year_cloglog.csv"))
#write_if_any(ph_tests_all, file.path(OUT_DIR, "bd_dth_phstyle_cluster_by_wave.csv"))
write_if_any(emm_wave_primary_all, file.path(OUT_DIR, "bd_dth_cluster_contrasts_by_wave.csv"))

#2.9.2 Save models
purrr::iwalk(fits_primary, ~ saveRDS(.x, file.path(OUT_DIR, glue("fit_primary_{.y}.rds"))))
purrr::iwalk(fits_sens, ~ saveRDS(.x, file.path(OUT_DIR, glue("fit_cloglog_{.y}.rds"))))

#2.10 Generate a quick AUC table in the HTML
if (nrow(auc_all) > 0) {
  knitr::kable(auc_all, digits = 3, caption = "Interval-level ROC/AUC (marginal; QC only)") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("AUC table empty.")
}

#2.11 Output model diagnostics (singularity / dispersion) in the HTML
if (nrow(diag_all) > 0) {
  knitr::kable(diag_all, digits = 3, caption = "Model diagnostics (singularity and dispersion)") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("Diagnostics table empty.")
}

#2.12 Output model performance diagnostics in the HTML
if (nrow(perf_all) > 0) {
  knitr::kable(perf_all, digits = 3, caption = "Model performance (R2 Nakagawa, Brier, LogLoss) - primary link") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("Performance table empty.")
}

#2.13 Output model DHARMa tests in the HTML
if (nrow(dharma_tests_all) > 0) {
  knitr::kable(dharma_tests_all, digits = 3, caption = "DHARMa tests (dispersion, zero-inflation) - primary link") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("DHARMa tests table empty.")
}

```

## 3. Determine Marginal Effects: Hazard by Cluster Across Age

Generates visualizations of predicted first-onset hazard vs age for each outcome and cluster, pairing each empirical age with its corresponding wave (02A/04A/06A) and within-person age deviation at 0. These visualize risk separation and trajectories across the median ages in the data at each timepoint

### How to read the hazard plots (interpretation guide)

- **Fixed-wave age curves** (first panel): We hold the wave constant at `r params$wave_ref` and vary age.  
  This isolates how the hazard changes with age within a given wave. Lines show model-predicted first-onset
  hazard per interval; higher lines = higher risk. Compare clusters at the same age to see separation

- **Wave-aligned curves** (second panel): Each point/age is paired with its actual wave (e.g., median ages at 02A, 04A, 06A).  
  This shows how the baseline hazard changes across waves while also reflecting the typical age at each wave.  
  A downward slope here does *not* contradict rising age risk - it reflects how the *wave baseline* (calendar-time
  hazard) moves across assessments

- **QC overlay (model vs empirical)**: Hollow points are empirical per-wave hazards; solid lines are the model predictions
  on the same x-axis (wave). Close agreement indicates good calibration by wave

- **Cumulative first-onset risk** (third panel): Converts per-interval hazards into the probability of having had a first onset by each wave
  
  - This is the "when do onsets happen" view most would expect - rising curves that separate by cluster indicate earlier and/or more frequent onsets in the higher-risk cluster

```{r marginal effects, echo = FALSE, warning = FALSE, fig.height=11, fig.width=8.5}

## 3. Marginal hazard by cluster across age ##

#3.0.1 ROBUST SCHEMAS so filters/plots don't error if preds are empty
empty_pred_df <- function() {
  tibble(
    outcome = character(),
    model = character(),
    pred_mode = character(),
    end_wave = factor(character(), levels = levels(bd_pp_model$end_wave)),
    cluster = factor(character(), levels = levels(bd_pp_model$cluster)),
    age_years = double(),
    pred = double(),
    lower = double(),
    upper = double()
  )
}

#3.0.2 Ensure the df's exist for plotting, create if not
if (!exists("pred_all_aligned") || !"model" %in% names(pred_all_aligned)) pred_all_aligned <- empty_pred_df()
if (!exists("pred_all_fixedwave") || !"model" %in% names(pred_all_fixedwave)) pred_all_fixedwave <- empty_pred_df()

#3.0.3 Split predicted frames
pred_aligned <- pred_all_aligned %>% filter(model == params$link_primary)
pred_fixedwave <- pred_all_fixedwave %>% filter(model == params$link_primary)

#3.1 Plot helpers
#3.1.1 Fixed age predictions
plot_pred_fixed <- function(df, title) {
  has_ci <- all(c("lower","upper") %in% names(df)) && any(is.finite(df$lower) & is.finite(df$upper))
  ggplot(df, aes(x = age_years, y = pred, color = cluster, group = cluster)) +
    { if (has_ci) geom_ribbon(aes(ymin = lower, ymax = upper, fill = cluster), alpha = 0.15, color = NA) } +
    geom_line(size = 1.0) +
    geom_point(size = 1.8) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +
    labs(title = wrap_title(title, 70),
      x = "Age (years)", y = "Predicted first-onset hazard (per interval)",
      color = "Cluster", fill = "Cluster") +
    theme_minimal(base_size = 9) +
    theme(legend.position = "bottom", legend.box = "horizontal", plot.title = element_text(lineheight = 0.95)) +
    guides(color = guide_legend(nrow = 1), fill = guide_legend(nrow = 1))
}

#3.1.2 Wave-aligned predictions (discrete x -> use error bars)
plot_pred_aligned <- function(df, title) {
  has_ci <- all(c("lower","upper") %in% names(df)) && any(is.finite(df$lower) & is.finite(df$upper))
  ggplot(df, aes(x = end_wave, y = pred, color = cluster, group = cluster)) +
    { if (has_ci) geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.15, alpha = 0.7) } +
    geom_line(size = 1.0) +
    geom_point(size = 1.8) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +
    labs(title = wrap_title(title, 70),
      x = "Wave (interval end)", y = "Predicted first-onset hazard (per interval)",
      color = "Cluster") +
    theme_minimal(base_size = 9) +
    theme(legend.position = "bottom", legend.box = "horizontal", plot.title = element_text(lineheight = 0.95)) +
    guides(color = guide_legend(nrow = 1))
}

#3.2 Fixed-wave age curves (pure age effect at wave_ref)
plots_fixed <- lapply(OUTCOMES, function(out) {
  df <- pred_fixedwave %>% filter(outcome == out)
  ttl <- glue("Predicted hazard by cluster across age (FIXED wave={params$wave_ref}; link={params$link_primary}) - {out}")  
  plot_pred_fixed(df, ttl)
})

#3.2.1 Wrap and print the fixed wave age curves
wrap_plots(plots_fixed, ncol = 2)

#3.3 Wave-aligned curves (age paired to wave)
plots_aligned <- lapply(OUTCOMES, function(out) {
  df <- pred_aligned %>% filter(outcome == out)
  ttl <- glue("Predicted hazard by cluster across wave (age paired to wave; link={params$link_primary}) - {out}")
  plot_pred_aligned(df, ttl)
})

#3.3.1 Wrap and print the wave aligned hazard plots
wrap_plots(plots_aligned, ncol = 2)

#3.4 QC overlay: model vs empirical per-wave hazards (aligned scale on the x-axis)
empirical_haz <- function(df) {
  df %>% group_by(outcome, end_wave, cluster) %>% summarise(emp = mean(event == 1L), .groups = "drop")
}
qc_plots <- lapply(OUTCOMES, function(out) {
  dfm <- pred_aligned %>% filter(outcome == out)
  dfe <- bd_pp_model %>% filter(outcome == out) %>% empirical_haz()
  ggplot() +
    geom_line(data = dfm, aes(x = end_wave, y = pred, color = cluster, group = cluster)) +
    geom_point(data = dfe, aes(x = end_wave, y = emp, color = cluster), shape = 1, size = 2) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +
    labs(title = wrap_title(glue("Model vs empirical per-wave hazards - {out}"), 70),
    x = "Wave (interval end)", y = "Hazard (per interval)") +
    theme_minimal(base_size = 9) + theme(legend.position = "bottom")
})

#3.4.1 Wrap and print the QC plots
wrap_plots(qc_plots, ncol = 2)

#3.5 Cumulative incidence by wave (reference profile)
cum_plots <- lapply(OUTCOMES, function(out) {
  fit <- fits_primary[[out]]
  dat <- bd_pp_model %>% filter(outcome == out)

  #3.5.1 Use the CI version
  cr <- cumrisk_by_wave_ci(fit, dat, B = 500) 
  has_ci <- "cumrisk_lo" %in% names(cr) && "cumrisk_hi" %in% names(cr) &&
            any(is.finite(cr$cumrisk_lo) & is.finite(cr$cumrisk_hi))
  ggplot(cr, aes(x = end_wave, y = cumrisk, color = cluster, group = cluster)) +
    { if (has_ci) geom_ribbon(aes(ymin = cumrisk_lo, ymax = cumrisk_hi, fill = cluster),
      alpha = 0.15, color = NA) } +
    geom_line() + geom_point(size = 1.8) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.1), limits = c(0, 1)) +
    labs(title = wrap_title(glue("Cumulative first-onset risk by wave (ref profile) - {out}"), 70),
      x = "Wave (interval end)", y = "Cumulative risk") +
    theme_minimal(base_size = 9) +
    theme(legend.position = "bottom", plot.title = element_text(lineheight = 0.95)) +
    guides(color = guide_legend(nrow = 1), fill = guide_legend(nrow = 1))
})

#3.5.2 Wrap and print the cumulative plots
wrap_plots(cum_plots, ncol = 2)

```

## 4. Baseline Hazard (Wave Effects) - Interpretability QC

Uses the fitted model to compute marginal baseline hazards by wave (sessions 02A, 04A, 06A) while holding other covariates at reference. Bar plots provide a quick sanity check that interval risks align with expected cohort timing

```{r baseline hazard wave effects, warning = FALSE, fig.height=11, fig.width=8.5}

## 4. Baseline hazard (wave FE -> marginal hazard by wave) ##

#4.1 Create a helper function to plot marginal hazard effects by assessment timepoint (wave)
plot_wave_hazard <- function(fit, data, title) {
  nd <- expand.grid(end_wave = levels(data$end_wave), cluster = levels(data$cluster)[1], age_mid_between = 0, age_mid_cwc = 0, baseline_status = 0, sex = levels(data$sex)[1], site_factor = levels(data$site_factor)[1])
  nd$pred <- predict(fit, newdata = nd, type = "response", re.form = NA)
  ggplot(nd, aes(x = end_wave, y = pred)) +
    geom_col() +
    scale_y_continuous(labels = scales::percent_format(accuracy = 0.001)) +
    labs(title = wrap_title(title, 70), x = "Wave (interval end)", y = "Baseline hazard (marginal)") +
    theme_minimal(base_size = 9) +
    theme(plot.title = element_text(lineheight = 0.95))
}

#4.2 Use the helper function to generate marginal hazard effects by wave plots
wave_plots <- lapply(OUTCOMES, function(out) {
  fit <- fits_primary[[out]]
  dat <- bd_pp_model %>% filter(outcome == out)
  plot_wave_hazard(fit, dat, glue("Baseline (wave) hazard - {out} (link={params$link_primary})"))
})

#4.3 Facet wrap the plots
wrap_plots(wave_plots, ncol = 2)

```

## 5. Perform Calibration (Using Decile Bins) for the Primary Link

Creates decile-bin calibration plots (mean predicted vs observed event rate). This checks probability calibration of the discrete-time models and helps flag miscalculation across the risk spectrum

```{r calibration, warning = FALSE, echo = FALSE, fig.height=11, fig.width=8.5}

## 5. Calibration (decile bins) - primary link ##

#5.1 Calibration helper: connect points and wrap title
plot_cal <- function(df, title) {
  df <- dplyr::arrange(df, pred_mean)
  xmax <- max(df$pred_mean, na.rm = TRUE)
  ymax <- max(df$obs_mean,  na.rm = TRUE)
  lim  <- max(0.05, xmax, ymax)
  ggplot(df, aes(x = pred_mean, y = obs_mean)) +
    geom_point(size = 2) +
    geom_line() +
    geom_abline(slope = 1, intercept = 0, linetype = 2) +
    scale_x_continuous(limits = c(0, lim), labels = scales::percent_format(accuracy = 0.001)) +
    scale_y_continuous(limits = c(0, lim), labels = scales::percent_format(accuracy = 0.001)) +
    coord_equal() +
    labs(title = wrap_title(title, 70),
      x = "Mean predicted hazard",
      y = "Observed event rate") +
    theme_minimal(base_size = 11) +
    theme(plot.title = element_text(lineheight = 0.95))
}

#5.2 Guard cal_all so filter() never errors when nothing to show
if (!exists("cal_all") || !"model" %in% names(cal_all)) {
  cal_all <- tibble(outcome = character(), model = character(),
    pred_mean = double(), obs_mean = double(), n = integer())
}

#5.3 Execute the helper function for decile calibration on each primary link 
plots_cal <- lapply(OUTCOMES, function(out) {
  df <- cal_all %>% filter(outcome == out, model == params$link_primary)
  ttl <- glue("Calibration by decile - {out} (link={params$link_primary})")
  plot_cal(df, ttl)
})

#5.4 Facet wrap the plots
wrap_plots(plots_cal, ncol = 2)

```

## 6. Generate Inference Tables (Wald vs CR2) Primary vs Sensitivity

Produces tidy, labeled tables of odds ratios with 95% CIs for both Wald and CR2 estimators (primary + cloglog). We report model-based (Wald) SEs as primary because the model includes (1|family_id); CR2 (clustered by family) is provided as a robustness check

To note, odds ratios are per-interval hazard ratios on the logit scale; cluster main effects represent the average cluster gap across the modeled age range unless a cluster*x*age interaction is present (in which case interpret the interaction at the reported ages)

```{r inference tables, warning = FALSE, echo = FALSE, fig.height=11, fig.width=8.5}

## 6. Inference tables (ORs with 95% CI) ##

#6.1 Create a function to create readable, formatted labels for inference tables
pretty_term <- function(x) {
  x %>%
    stringr::str_replace_all(":", " x ") %>%
    stringr::str_replace("^cluster", "Cluster: ") %>%
    stringr::str_replace("^age_mid_between$", "Age (between-person)") %>%
    stringr::str_replace("^age_mid_cwc$", "Age (within-person)") %>%
    stringr::str_replace("^baseline_status$", "Baseline positive") %>%
    stringr::str_replace("^sex", "Sex: ") %>%
    stringr::str_replace("^end_wave", "Wave: ")
}

#6.2 Generate the wald results tables (filtered) using the pretty_term helper function
tbl_wald <- wald_all %>%
  mutate(term = pretty_term(term)) %>%
  dplyr::select(model, outcome, term, OR, CI_lo, CI_hi, p.value)

#6.3 Generate the cr2 results tables (filtered) using the pretty_term helper function
tbl_cr2 <- cr2_all %>%
  mutate(term = pretty_term(term)) %>%
  dplyr::select(model, outcome, term, OR, CI_lo, CI_hi, p.value)

#6.4 Print the formatted wald and cr2 results tables (filtered)
knitr::kable(tbl_wald %>% arrange(outcome, model), digits = 3, caption = "Fixed effects (Wald) Odds ratios with 95% CI (filtered)") %>%
  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = c("striped","hover","condensed","responsive"))
knitr::kable(tbl_cr2 %>% arrange(outcome, model), digits = 3, caption = "Fixed effects (CR2 cluster-robust by family) Odds ratios with 95% CI (filtered)") %>%
  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = c("striped","hover","condensed","responsive"))

```

## 7. Cluster Contrasts at Representative Ages (Primary Link)

Reports `emmeans` pairwise cluster contrasts (odds-ratio scale) at `wave_ref` with within-person age = 0 and baseline/sex/site at reference. This isolates how cluster differences manifest at clinically interpretable age points

```{r cluster contrasts, echo = FALSE, warning = FALSE}

## 7. Cluster contrasts (emmeans) at ages = {params$ages_pred} years (primary link) ##

#7.1 Determine which ages were used for contrasts
used_ages <- if (!is.null(params$ages_pred) && length(params$ages_pred) > 0) params$ages_pred else ages_pred_vec

#7.2 Safely display contrasts table (handle empty or missing columns)
if (exists("emm_all") && is.data.frame(emm_all) && nrow(emm_all) > 0) {
  emm_disp <- emm_all
  if (!"model" %in% names(emm_disp)) emm_disp <- dplyr::mutate(emm_disp, model = params$link_primary)
  if (!"outcome" %in% names(emm_disp)) emm_disp <- dplyr::mutate(emm_disp, outcome = NA_character_)
  knitr::kable(
    emm_disp %>% dplyr::filter(model == params$link_primary) %>% dplyr::arrange(outcome, age_years, contrast),
    digits = 3,
    caption = glue::glue("Cluster contrasts (OR) at ages {paste(used_ages, collapse=', ')} - primary link = {params$link_primary}")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("No emmeans contrasts to display (likely singular fits); skipping table.")
}

#7.3 Safely display wave-specific cluster contrasts (primary link; aligned to wave-median ages)
if (exists("emm_wave_primary_all") && is.data.frame(emm_wave_primary_all) && nrow(emm_wave_primary_all) > 0) {
  knitr::kable(
    emm_wave_primary_all %>% dplyr::arrange(outcome, end_wave, contrast),
    digits = 3,
    caption = glue::glue("Cluster contrasts (OR) by wave at each wave's median age - primary link = {params$link_primary}")
  ) %>% kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
}

```

## Age Notes & Sensitivity

**Why decompose age?**

-   In longitudinal hazards, naive "age" conflates two distinct things:
    -   Aging within the same youth (time passing)
    -   Older vs younger youths on average (between families/ids)
-   Including age_mid_cwc + age_mid_between separates these. Interpretation:
    -   age_mid_cwc: per-person change in hazard as they age (holding their own mean age fixed)
    -   age_mid_between: difference in hazard for a child whose typical age is higher vs lower than the cohort mean

An optional parsimonious alternative would be to use a single centered age. If we end up needing a simpler reporting model, we could fit: `event ~ cluster * age_mid_gmc + baseline_status + sex + site_factor + end_wave + (1|id) + (1|family)`; and keep the decomposed model as a sensitivity analysis (this is currently not run here though, to keep runtime minimal)

## "Final Story"" Template

In the interest of summarizing the many and complex analyses that were ran in service of answering the "when" of BD onset by risk cluster, the following is an attempt to summarize the most pertinent and meaningful analysis results.

```{r final story template, warning = FALSE, echo = FALSE}

has_cols <- function(df, cols) is.data.frame(df) && nrow(df) > 0 && all(cols %in% names(df))

# Absolute hazards by wave (primary link; reference age profile)
haz_story <- if (exists("hazard_tables_all") &&
                 has_cols(hazard_tables_all, c("outcome","end_wave","cluster","hazard","lo","hi"))) {
  hazard_tables_all %>%
    dplyr::transmute(outcome, end_wave, cluster,
      metric = "hazard_per_interval",
      estimate = hazard, lo = lo, hi = hi)
} else tibble()

# Cumulative risk by wave (primary; reference profile)
cum_story <- if (exists("cumrisk_tables_all") &&
                 has_cols(cumrisk_tables_all, c("outcome","end_wave","cluster","cumrisk","cumrisk_lo","cumrisk_hi"))) {
  cumrisk_tables_all %>%
    dplyr::transmute(outcome, end_wave, cluster,
      metric = "cumulative_risk",
      estimate = cumrisk, lo = cumrisk_lo, hi = cumrisk_hi)
} else tibble()

# Cluster contrasts at ages (primary OR)
contr_or_story <- if (exists("emm_all") &&
                      has_cols(emm_all, c("model","outcome","age_years","contrast","OR","CI_lo","CI_hi","p.value"))) {
  emm_all %>%
    dplyr::filter(model == params$link_primary) %>%
    dplyr::transmute(outcome, age_years, contrast,
      effect_scale = "OR",
      estimate = OR, lo = CI_lo, hi = CI_hi, p.value)
} else tibble()

# Cluster contrasts at ages (cloglog HR)
contr_hr_story <- if (exists("emm_cloglog_all") &&
                      has_cols(emm_cloglog_all, c("outcome","age_years","contrast","HR","CI_lo","CI_hi","p.value"))) {
  emm_cloglog_all %>%
    dplyr::transmute(outcome, age_years, contrast,
      effect_scale = "HR",
      estimate = HR, lo = CI_lo, hi = CI_hi, p.value)
} else tibble()

# Per-year first-onset rates from cloglog (reference profile)
rates_story <- if (exists("rates_by_wave") &&
                   has_cols(rates_by_wave, c("outcome","end_wave","cluster","rate_per_year"))) {
  rates_by_wave %>%
    dplyr::transmute(outcome, end_wave, cluster,
      metric = "rate_per_year",
      estimate = rate_per_year, lo = NA_real_, hi = NA_real_)
} else tibble()

# Combine, guarantee sort keys, and print
story <- dplyr::bind_rows(haz_story, cum_story, contr_or_story, contr_hr_story, rates_story)

# If story exists, print in full
if (nrow(story) > 0) {

  # Ensure the columns used for sorting/printing exist & are consistent types
  if (!"age_years" %in% names(story)) story$age_years <- NA_real_
  if (!"end_wave"  %in% names(story)) story$end_wave  <- NA_character_
  story <- story %>%
    dplyr::mutate(
      end_wave = as.character(end_wave),
      
      # Prefer 'metric' if present; otherwise use 'effect_scale' (OR/HR)
      metric_display = dplyr::coalesce(metric, effect_scale))
  knitr::kable(
    story %>%
      dplyr::arrange(outcome, metric_display, age_years, end_wave) %>%
      dplyr::select(
        outcome,
        metric = metric_display,
        dplyr::any_of(c("end_wave","age_years","cluster","contrast","effect_scale", "estimate","lo","hi","p.value"))),
    digits = 3,
    caption = "Final story: key absolute risks & contrasts") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
} else {
  message("No 'final story' rows to display.")
}

```